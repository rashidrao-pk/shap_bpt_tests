{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# print('np',np.__version__)\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')  # Set a non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "# import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "import chime\n",
    "chime.theme('chime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "\n",
    "rc('text',usetex=True)\n",
    "rc('text.latex', preamble='\\\\usepackage{color}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "import torchvision\n",
    "use_mps = ('mps' in dir(torch.backends)) and torch.backends.mps.is_available()\n",
    "\n",
    "if   use_cuda:    device = torch.device(\"cuda\")\n",
    "elif use_mps:     device = torch.device(\"mps\")\n",
    "else:             device = torch.device(\"cpu\")\n",
    "\n",
    "print(f'{\"Torch CUDA\":<25} {torch.cuda.is_available()}')\n",
    "print(f'{\"device:\":<25} {device}')\n",
    "print(f'{\"Device Name:\":<25} {torch.cuda.get_device_name()}')\n",
    "\n",
    "# params.device = device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Parameters:\n",
    "    dummy                   : bool  =   False\n",
    "    exp_no                  : str   =   ''\n",
    "    model_name              : str   =   'yolov8s'\n",
    "    model_type              : str   =   'real'\n",
    "    background_type         : str   =   'gray'\n",
    "    top_classes_n           : int   =   3\n",
    "    batch_size              : int   =   16\n",
    "    seed                    : int   =   12345\n",
    "    device                  : str   =   device\n",
    "    submission_version      : bool  =   False\n",
    "    data_subset             : int   =   300\n",
    "params = Parameters()\n",
    "\n",
    "@dataclass\n",
    "class Paths:\n",
    "    dummy           : bool  = False\n",
    "    path_datasets   : str  =   ''\n",
    "    DS_name_img : str = ''\n",
    "    DS_name_annotation : str = ''\n",
    "    codes_local : str  = ''\n",
    "    path_ds_main : str = ''\n",
    "    path_repos : str = ''\n",
    "    path_codes : str = os.getcwd()#'E:/PHD/datacloud_data/repos/paper_suppl/ShapBPT_ICCV_25/notebooks/E8_MS_COCO'\n",
    "    path_utils : str = ''\n",
    "    results_path : str = ''\n",
    "    results_path_single : str = ''\n",
    "    results_path_selected : str = ''\n",
    "    plotsIoU_path       : str =''\n",
    "    plots_path : str =''\n",
    "    image_dir : str = ''\n",
    "    annotation_file : str = ''\n",
    "    total_imgs : str =  ''\n",
    "    csv_filename : str = ''\n",
    "    \n",
    "\n",
    "paths = Paths()\n",
    "\n",
    "torch.manual_seed(params.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black-Box Model\n",
    "-   https://docs.ultralytics.com/models/yolov8/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLOv8-cls -> Classification\n",
    "# YOLOv8-seg -> Instance Segmentation\n",
    "\n",
    "# params.model_name = 'yolov8s'\n",
    "params.model_name = 'yolo11s'\n",
    "# params.model_name = 'yolo11n-cls'\n",
    "\n",
    "model = YOLO(f'{params.model_name}.pt')\n",
    "class_names = model.names\n",
    "\n",
    "print(f'{\"Model Name\":<15}{params.model_name}')\n",
    "print(f'{\"Num_Classes\":<15}{len(class_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.info()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths Setting\n",
    "This cell contains the setting of paths being used to load dataset, codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the dataset\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "paths.path_ds_main = 'D:\\\\DS\\\\MS_COCO'\n",
    "# image_dir = os.path.join(main_path,\"unlabeled2017\")  # Replace with the path to your images\n",
    "# annotation_file = f\"{main_path}/annotations/image_info_unlabeled2017.json\"  # Update for your annotation file\n",
    "paths.image_dir = os.path.join(paths.path_ds_main,\"val2017\")  # Replace with the path to your images\n",
    "paths.annotation_file = f\"{paths.path_ds_main}//annotations//annotations_trainval2017//annotations//instances_val2017.json\"  # Update for your annotation file\n",
    "\n",
    "# Load COCO dataset\n",
    "coco = COCO(paths.annotation_file)\n",
    "\n",
    "# Get all image IDs\n",
    "image_ids = coco.getImgIds()\n",
    "\n",
    "paths.total_imgs = len(image_ids)\n",
    "\n",
    "print('total images:\\t', paths.total_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_modify_time(filepath=None):\n",
    "    if os.path.exists(filepath):\n",
    "        datestamp  = datetime.fromtimestamp(os.path.getmtime(filepath))\n",
    "        print('Modified Date/Time:', datestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subpaths(main_path=None,suffix=None, create_dirs =True, verbose_print=True):\n",
    "    results_ = os.path.join(main_path,'results')\n",
    "    results_path = os.path.join(results_,suffix)\n",
    "    results_path_selected    = os.path.join(results_path    ,'selected')\n",
    "    results_path_single      = os.path.join(results_path      ,'single')\n",
    "    plots_path               = os.path.join(results_path,       'plots')\n",
    "    plotsIoU_path            = os.path.join(results_path,   'plots_IoU')\n",
    "    path_csv                 = os.path.join(main_path,         'csv')\n",
    "    if create_dirs:\n",
    "        os.makedirs(results_path,              exist_ok=True)\n",
    "        os.makedirs(plots_path,                exist_ok=True)\n",
    "        os.makedirs(plotsIoU_path,             exist_ok=True)\n",
    "        os.makedirs(results_path_single,       exist_ok=True)\n",
    "        os.makedirs(results_path_selected,     exist_ok=True)\n",
    "        os.makedirs(path_csv,                  exist_ok=True)\n",
    "    if verbose_print:\n",
    "        print('-'*120)\n",
    "        print('results_path\\t\\t',results_path)\n",
    "        print('results_path_single\\t',results_path_single)\n",
    "        print('results_path_selected\\t',results_path_selected)\n",
    "        print('paths for CSV file\\t',path_csv)\n",
    "        print('-'*120)\n",
    "    return results_path,results_path_selected,results_path_single,plots_path,plotsIoU_path,path_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix                     = f'{params.model_name}_{params.background_type}'\n",
    "\n",
    "path_current = os.getcwd()\n",
    "paths.results_path,paths.results_path_selected,paths.results_path_single,paths.plots_path,paths.plotsIoU_path,paths.path_csv \\\n",
    "    = get_subpaths(main_path=path_current, suffix=suffix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Class Distribution for Valid Set in MS COCO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Get all category IDs and names\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "category_names = [cat['name'] for cat in categories]\n",
    "category_ids = [cat['id'] for cat in categories]\n",
    "\n",
    "category_counts = defaultdict(int)\n",
    "\n",
    "# Get all annotations\n",
    "for ann_id in coco.getAnnIds():\n",
    "    ann = coco.loadAnns(ann_id)\n",
    "    for annotation in ann:\n",
    "        category_counts[annotation['category_id']] += 1\n",
    "\n",
    "# Map category IDs to names for plotting\n",
    "category_counts_named = {coco.loadCats(cat_id)[0]['name']: count for cat_id, count in category_counts.items()}\n",
    "\n",
    "# Sort by counts for better visualization\n",
    "sorted_counts = dict(sorted(category_counts_named.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(20, 8))\n",
    "bars = plt.bar(sorted_counts.keys(), sorted_counts.values(), color='skyblue')\n",
    "\n",
    "# Annotate bars with counts\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()  # Height of the bar (count value)\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,  # X-coordinate: center of the bar\n",
    "        yval + 10,  # Y-coordinate: slightly above the bar\n",
    "        str(yval),  # Text (count value)\n",
    "        ha='center',  # Center align\n",
    "        va='bottom',  # Align to the bottom of the text\n",
    "        rotation=90,\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "plt.xlabel('Categories', fontsize=12)\n",
    "plt.ylabel('Number of Annotations', fontsize=12)\n",
    "plt.title('Class-wise Distribution of Annotations in MS COCO Validation Set', fontsize=15)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST IMAGE INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_choice = 139\n",
    "fixed_choice = 113235\n",
    "\n",
    "image_info = coco.loadImgs(fixed_choice)[0]\n",
    "print(image_info)\n",
    "\n",
    "image_path = os.path.join(paths.image_dir, image_info['file_name'])\n",
    "print(image_path,image_info['file_name'])\n",
    "print(image_path, os.path.exists(image_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_stats = []\n",
    "\n",
    "for im_id,image_no in enumerate(tqdm(coco.getImgIds())):\n",
    "    image_info = coco.loadImgs(image_no)[0]\n",
    "    # print(image_no,image_info['width'], image_info['height'])\n",
    "    # print(image_info)\n",
    "    img_size_stats.append({'image_no':image_no,\n",
    "                           'width':image_info['width'],\n",
    "                           'height':image_info['height']})\n",
    "    # break\n",
    "df_stats_size = pd.DataFrame(img_size_stats)\n",
    "df_stats_size.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_size.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Segmentation Map Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_no = 139\n",
    "image_no = 113235\n",
    "\n",
    "image_info = coco.loadImgs(image_no)[0]\n",
    "\n",
    "ann_ids = coco.getAnnIds(imgIds=image_info['id'])\n",
    "annotations = coco.loadAnns(ann_ids)\n",
    "has_segmentation = any('segmentation' in ann for ann in annotations)\n",
    "print(f\"Segmentation annotations present: {has_segmentation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Annotation Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = coco.loadCats(coco.getCatIds())\n",
    "coco_categories = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "# Get annotations for the selected image\n",
    "ann_ids = coco.getAnnIds(imgIds=image_info['id'])\n",
    "annotations = coco.loadAnns(ann_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if segmentation annotations are present\n",
    "has_segmentation = any('segmentation' in ann for ann in annotations)\n",
    "print(f\"Segmentation annotations present: {has_segmentation}\")\n",
    "\n",
    "# Print one segmentation annotation (if available)\n",
    "if has_segmentation:\n",
    "    for ann in annotations:\n",
    "        if 'segmentation' in ann:\n",
    "            print(f\"Segmentation Annotation: {ann['segmentation']}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def get_\n",
    "# category_name = \"person\"  # Replace with the desired category name\n",
    "# category_ids = coco.getCatIds(catNms=[category_name])\n",
    "# # annotation_ids = coco.getAnnIds(imgIds=image_info['id'])\n",
    "# annotation_ids = coco.getAnnIds(imgIds=image_info['id'], catIds=category_ids)\n",
    "\n",
    "# annotations = coco.loadAnns(annotation_ids)\n",
    "# print(f\"Image:{image_info['id']} has {len(annotations)} annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "model_preprocess = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FN: Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def load_image(fname,params,im_size=None,bg_type='black'):\n",
    "    global path_img_val\n",
    "    global image_to_explain, image_to_explain_preproc, image_to_explain_tensor\n",
    "    global predicted_fS, predicted_f0, predicted_cls, sorted_classes, f_S, f_0\n",
    "    global model_type\n",
    "    global background_tensors, background_image_set, background_image_preproc_set\n",
    "    \n",
    "\n",
    "    # file_n = fname.split('//')[-1].split('.')[0]\n",
    "    # im_size = [224,224]\n",
    "    # Foreground image to be explained\n",
    "    # image = cv2.imread(image_path)\n",
    "    img_ = cv2.imread(f'{fname}')\n",
    "    image_to_explain = cv2.cvtColor(img_, cv2.COLOR_BGR2RGB) #.astype(np.float32)\n",
    "    if im_size is not None:\n",
    "        image_to_explain         = cv2.resize(image_to_explain,im_size)# [:,:,::-1]\n",
    "    \n",
    "    \n",
    "    if params.model_type=='ideal':\n",
    "        image_to_explain_preproc  = torch.ones(tuple(reversed(image_to_explain.shape)))\n",
    "    else:\n",
    "        image_to_explain_preproc  = image_to_explain.copy()#torch.tensor(image_to_explain).to(device)# .astype(np.float32)/255.0\n",
    "    # print(image_to_explain_preproc.shape, image_to_explain_preproc.dtype)\n",
    "    \n",
    "    # image_to_explain_tensor = model_preprocess(image_to_explain_preproc).to(device)\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    bkgnd0 = np.full_like(image_to_explain, 0)\n",
    "    bkgnd1 = np.full_like(image_to_explain, 127)\n",
    "    bkgnd2 = np.full_like(image_to_explain, 255)\n",
    "    bkgnd3 = gaussian(image_to_explain, 8, channel_axis=-1)*255\n",
    "    bkgnd4 = np.clip(np.random.normal(128, 128, size=image_to_explain.shape), 0, 255).astype(np.uint8)\n",
    "    bkgnd4 = (gaussian(bkgnd4, 2.0, channel_axis=-1) * 255).astype(np.uint8)\n",
    "    if bg_type=='black':\n",
    "        background_image_set = np.array([bkgnd0])\n",
    "    elif bg_type=='gray':\n",
    "        background_image_set = np.array([bkgnd1])\n",
    "    elif bg_type=='white':\n",
    "        background_image_set = np.array([bkgnd2])\n",
    "    elif bg_type=='blurred':\n",
    "        background_image_set = np.array([bkgnd3])\n",
    "    elif bg_type=='noise':\n",
    "        background_image_set = np.array([bkgnd4])\n",
    "    elif bg_type=='full':\n",
    "        background_image_set = np.array([bkgnd0, bkgnd1, bkgnd2, bkgnd3, bkgnd4])\n",
    "    if params.model_type=='ideal':\n",
    "        background_image_preproc_set = [torch.zeros(tuple(reversed(bkgnd.shape)))\n",
    "                                        for bkgnd in background_image_set]\n",
    "    else:\n",
    "        background_image_preproc_set = [model_preprocess(bkgnd.astype(np.float32)/255.0)\n",
    "                                        for bkgnd in background_image_set]\n",
    "\n",
    "    background_tensors = torch.cat([torch.unsqueeze(bk_p, dim=0) \n",
    "                                    for bk_p in background_image_preproc_set]).to(device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GroundTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation(coco,image_no,category_name=None):\n",
    "    if isinstance(image_no, str):\n",
    "        image_no = int(image_no.split('\\\\')[-1].split('.')[0])\n",
    "    \n",
    "    image_info = coco.loadImgs(image_no)[0]\n",
    "    if category_name is None:\n",
    "        annotation_ids = coco.getAnnIds(imgIds=image_info['id'])\n",
    "    else:\n",
    "        category_ids = coco.getCatIds(catNms=[category_name])\n",
    "        annotation_ids = coco.getAnnIds(imgIds=image_info['id'], catIds=category_ids)\n",
    "    annotations = coco.loadAnns(annotation_ids)\n",
    "    return annotations\n",
    "\n",
    "def create_gt(coco,image_no,category_name=None, verbose=False):\n",
    "    annotations = get_annotation(coco,image_no,category_name=category_name)\n",
    "    if verbose:\n",
    "        if len(annotations)>0:\n",
    "            print(f\"Image:{image_info['id']} has {len(annotations)} annotations\")\n",
    "    \n",
    "    # ann_ids = coco.getAnnIds(imgIds=image_info['id'])\n",
    "    # annotations = coco.loadAnns(ann_ids)\n",
    "    \n",
    "    mask = np.zeros((image_info['height'], image_info['width']), dtype=np.uint8)\n",
    "    category_mask = np.zeros((image_info['height'], image_info['width']), dtype=np.uint8)\n",
    "\n",
    "    # Combine all masks for this image\n",
    "    for ann in annotations:\n",
    "        if 'segmentation' in ann:\n",
    "            category_id = ann['category_id']  # Unique ID for object category\n",
    "            # Decode the segmentation mask\n",
    "            if isinstance(ann['segmentation'], list):  # Polygon format\n",
    "                for seg in ann['segmentation']:\n",
    "                    pts = np.array(seg).reshape(-1, 2).astype(np.int32)\n",
    "                    cv2.fillPoly(mask, [pts], color=1)  # Fill the mask polygon\n",
    "                    cv2.fillPoly(category_mask, [pts], color=category_id)\n",
    "            elif isinstance(ann['segmentation'], dict):  # RLE format\n",
    "                rle = ann['segmentation']\n",
    "                decoded_mask = coco.annToMask(ann)\n",
    "                mask += decoded_mask  # Add binary mask\n",
    "                category_mask[decoded_mask > 0] = category_id  # Assign category ID\n",
    "    \n",
    "    # Resize masks to match actual image dimensions\n",
    "    if mask.shape[:2] != image_to_explain.shape[:2]:\n",
    "        # print(f\"Resizing masks: Annotated={mask.shape}, Actual={image_to_explain.shape[:2]}\")\n",
    "        mask = cv2.resize(mask, (image_to_explain.shape[1], image_to_explain.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        category_mask = cv2.resize(category_mask, (image_to_explain.shape[1], image_to_explain.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    return mask,category_mask,annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_groundtruth(coco,image_no,fixed_category=None):\n",
    "    global ground_truth,weighted_ground_truth,annotations\n",
    "    \n",
    "    mask,ground_truth,annotations = create_gt(coco,image_no,category_name = fixed_category)\n",
    "    weighted_ground_truth = gaussian_filter(ground_truth.astype(float), 16) * ground_truth\n",
    "    ground_truth.dtype = 'bool'\n",
    "    # ground_truth = ground_truth.dtype('bool')\n",
    "    # ground_truth = cv2.imread(f'{fname}', cv2.IMREAD_COLOR)[:,:,::-1]\n",
    "    # return ground_truth,weighted_ground_truth,annotations\n",
    "    # ground_truth = cv2.resize(ground_truth, [224,224], interpolation=cv2.INTER_NEAREST)\n",
    "    # ground_truth = ground_truth[:,:,0].astype(int) + 256*ground_truth[:,:,1].astype(int)\n",
    "    # ground_truth[ ground_truth==1000 ] = 0\n",
    "    \n",
    "    \n",
    "\n",
    "#     # mask, category_mask,annotations = create_gt(coco,fixed_choice)\n",
    "# # plot_gt(image_to_explain,annotations)\n",
    "\n",
    "# # plot_mask(category_mask,category_name = fixed_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mask, category_mask,annotations = create_gt(coco,fixed_choice,category_name = None)\n",
    "# mask, category_mask,annotations = create_gt(coco,fixed_choice,category_name = 'tv')\n",
    "\n",
    "# plot_mask(category_mask,category_name = fixed_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT NOTEBOOK\n",
    "- https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoDemo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoDemo.ipynb\n",
    "# load and display instance annotations\n",
    "# plt.imshow(I); plt.axis('off')\n",
    "# annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
    "# anns = coco.loadAnns(annIds)\n",
    "# coco.showAnns(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get all images containing given categories, select one at random\n",
    "# catIds = coco.getCatIds(catNms=['person','dog','skateboard']);\n",
    "# imgIds = coco.getImgIds(catIds=catIds );\n",
    "# imgIds = coco.getImgIds(imgIds = [324158])\n",
    "# img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load and display caption annotations\n",
    "# annIds = coco_caps.getAnnIds(imgIds=img['id']);\n",
    "# anns = coco_caps.loadAnns(annIds)\n",
    "# coco_caps.showAnns(anns)\n",
    "# plt.imshow(I); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking Fucntion\n",
    "Two Masking Function being used to generate Shapely values\n",
    "- predict_yolo\n",
    "- predict_yolo_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_yolo(x,verbose=False):\n",
    "    # predict_yolo_masked\n",
    "    # res = model(x)[0]\n",
    "    res = model.predict(source=x, verbose=verbose)[0]\n",
    "    # probs = []\n",
    "    # for res in results_:\n",
    "    p = np.zeros(80)\n",
    "    for cls,prob in zip(res.boxes.cls.cpu().numpy(), res.boxes.conf.cpu().numpy()):\n",
    "        p[int(cls)] = prob\n",
    "\n",
    "            # print(cls,prob)\n",
    "        # probs.append(p)\n",
    "    return np.array(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_yolo_masked(masks,verbose=False):\n",
    "    imglst_preds = []\n",
    "    for mask in masks:\n",
    "        preds = []\n",
    "        for repl in background_image_set:\n",
    "            # print(mask.shape, repl.shape)\n",
    "            if len(mask.shape)!=3:\n",
    "                mask3 = np.stack([mask,mask,mask], axis=2)\n",
    "            else:\n",
    "                print(mask.shape)\n",
    "                mask3 = mask.copy()\n",
    "            masked_image = np.where(mask3, image_to_explain, repl)\n",
    "            preds.append(predict_yolo(masked_image,verbose=verbose))\n",
    "\n",
    "        preds = np.mean(preds, axis=0)\n",
    "        imglst_preds.append(preds)       \n",
    "    \n",
    "    return np.array(imglst_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_bg_values(predict_yolo, ground_truth, predicted_cls, class_names, verbose=False):\n",
    "#     if verbose:\n",
    "#         print(f'Input shape: {ground_truth.shape}, dtype: {ground_truth.dtype}, '\n",
    "#               f'type: {type(ground_truth)}, max value: {np.max(ground_truth)}')\n",
    "    \n",
    "#     # Convert 2D mask to 3D if needed\n",
    "#     if len(ground_truth.shape) == 2:\n",
    "#         ground_truth = np.stack([ground_truth.astype(np.uint8) * 255]*3, axis=-1)\n",
    "#         if verbose:\n",
    "#             print(f'Converted to 3D: {ground_truth.shape}')\n",
    "    \n",
    "#     # Process ground truth\n",
    "#     predicted_fG = predict_yolo(ground_truth)\n",
    "#     if isinstance(predicted_fG, list):  # Handle batch prediction\n",
    "#         predicted_fG = predicted_fG[0]\n",
    "    \n",
    "#     # Extract score for ground truth\n",
    "#     if hasattr(predicted_fG, 'probs'):  # Classification model\n",
    "#         f_G = float(predicted_fG.probs[predicted_cls])\n",
    "#     else:  # Detection model\n",
    "#         boxes = getattr(predicted_fG, 'boxes', None)\n",
    "#         if boxes is not None:\n",
    "#             cls_mask = boxes.cls == predicted_cls\n",
    "#             f_G = float(boxes.conf[cls_mask].mean()) if any(cls_mask) else 0.0\n",
    "#         else:\n",
    "#             f_G = 0.0\n",
    "    \n",
    "#     # Process background mask (inverse of ground truth)\n",
    "#     background_mask = np.logical_not(ground_truth if ground_truth.dtype == bool else ground_truth > 0)\n",
    "#     background_mask = background_mask.astype(np.uint8) * 255\n",
    "#     if len(background_mask.shape) == 2:\n",
    "#         background_mask = np.stack([background_mask]*3, axis=-1)\n",
    "    \n",
    "#     predicted_fB = predict_yolo(background_mask)\n",
    "#     if isinstance(predicted_fB, list):\n",
    "#         predicted_fB = predicted_fB[0]\n",
    "    \n",
    "#     # Extract score for background\n",
    "#     if hasattr(predicted_fB, 'probs'):  # Classification model\n",
    "#         f_B = float(predicted_fB.probs[predicted_cls])\n",
    "#     else:  # Detection model\n",
    "#         boxes = getattr(predicted_fB, 'boxes', None)\n",
    "#         if boxes is not None:\n",
    "#             cls_mask = boxes.cls == predicted_cls\n",
    "#             f_B = float(boxes.conf[cls_mask].mean()) if any(cls_mask) else 0.0\n",
    "#         else:\n",
    "#             f_B = 0.0\n",
    "    \n",
    "#     if verbose:\n",
    "#         print(f'Class: {class_names[predicted_cls]} ({predicted_cls})')\n",
    "#         print(f'Ground Truth Score (f_G): {f_G:.4f}')\n",
    "#         print(f'Background Score (f_B): {f_B:.4f}')\n",
    "#         print('-' * 50)\n",
    "    \n",
    "#     return f_G, f_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bg_values_yolo(f_masked, ground_truth, predicted_cls, class_names, verbose=False):\n",
    "    \"\"\"\n",
    "    YOLOv8 version of get_bg_values\n",
    "    \"\"\"\n",
    "    # Evaluate ground truth mask\n",
    "    predicted_fG = f_masked(np.expand_dims(ground_truth, axis=0))[0]\n",
    "    f_G = float(predicted_fG[predicted_cls])\n",
    "    \n",
    "    # Evaluate background mask\n",
    "    background_mask = np.logical_not(ground_truth)\n",
    "    predicted_fB = f_masked(np.expand_dims(background_mask, axis=0))[0]\n",
    "    f_B = float(predicted_fB[predicted_cls])\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Class: {class_names[predicted_cls]} ({predicted_cls})')\n",
    "        print(f'Ground Truth Score (f_G): {f_G:.5f}')\n",
    "        print(f'Background Score (f_B): {f_B:.5f}')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    return f_G, f_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_to_explain(fname,params,bg_type='gray', load_gt=True):\n",
    "    global predicted_fS, predicted_f0, predicted_cls, sorted_classes, f_S, f_0,sorted_probs\n",
    "    global model_type,pretrained_model_type\n",
    "\n",
    "    load_image(fname,params=params,bg_type=bg_type)\n",
    "    h,w,_ = image_to_explain.shape\n",
    "    # Foreground image to be explained  \n",
    "    predicted_fS = predict_yolo(image_to_explain) \n",
    "    # predicted_fS = f(torch.unsqueeze(resnet50_preprocess(image_to_explain.astype(np.float32)/255.0).to(device), dim=0))[0]\n",
    "    sorted_classes = np.flip(np.argsort(predicted_fS))\n",
    "    sorted_probs   = predicted_fS[sorted_classes]\n",
    "    predicted_cls = sorted_classes[0]\n",
    "    f_S = float(predicted_fS[predicted_cls])\n",
    "    #####################\n",
    "    \n",
    "    predicted_f0 = [predict_yolo(bkgnd.astype(np.float32)/255.0) for bkgnd in background_image_set]\n",
    "    predicted_f0 = np.mean(predicted_f0,axis=0)\n",
    "    f_0          = float(predicted_f0[predicted_cls])\n",
    "    # if load_gt:\n",
    "        # image_no = int(image_path.split('\\\\')[-1].split('.')[0])\n",
    "\n",
    "        # load_groundtruth(coco,image_path,fixed_category=fixed_category)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST ANNOTATION AVAILABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_image_to_explain(image_path,params, bg_type='gray')\n",
    "# fixed_category = 'tv'\n",
    "fixed_category = class_names[predicted_cls]\n",
    "print('fixed_category: ',fixed_category)\n",
    "\n",
    "# class_names[predicted_cls]\n",
    "\n",
    "load_groundtruth(coco,image_path,fixed_category=fixed_category)\n",
    "# load_groundtruth(coco,image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_gt_bg(save_fig=False, selected_ext='png',title=None,destroy_fig=False):\n",
    "    fig,ax = plt.subplots(1,2+len(background_image_set))\n",
    "    ax[0].imshow(image_to_explain)\n",
    "    ax[0].set_title('Input')\n",
    "    # ax[0].set_axis_off()\n",
    "    ax[1].imshow(ground_truth, cmap='Reds')\n",
    "    ax[1].set_title('Ground\\ntruth')\n",
    "    # ax[1].set_axis_off()\n",
    "    for i,img in enumerate(background_image_set):\n",
    "        ax[i+2].imshow(img.astype(np.uint8))\n",
    "        ax[i+2].set_title(f'Repl {i}')\n",
    "    \n",
    "    for axx in ax:\n",
    "        axx.set_axis_off()\n",
    "    if save_fig:\n",
    "        if title is None:\n",
    "            suffix = f'{image_no}_{params.background_type}_bg_gt.{selected_ext}'\n",
    "        else:\n",
    "            suffix = f'{image_no}_{params.background_type}_heatmap_{title}.{selected_ext}'\n",
    "                                                   \n",
    "        plt.savefig(f'{paths.results_path_single}//{suffix}',dpi=200,transparent=True,bbox_inches='tight', pad_inches=0.02)\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img_gt_bg(save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predicted_fS shape:\\t', predicted_fS.shape)\n",
    "print('predicted_cls:\\t\\t',    predicted_cls, class_names[predicted_cls])\n",
    "print('f_S:\\t\\t\\t', f_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(image_to_explain)\n",
    "# results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funct: Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gt(image_,annotation,fixed_category,save_fig=False,fig_size = (3,3),title=None,selected_ext='png',destroy_fig=False):\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    plt.imshow(image_)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Add annotations as overlays\n",
    "    for annotation in annotations:\n",
    "        bbox = annotation['bbox']  # [x, y, width, height]\n",
    "        category = coco.loadCats(annotation['category_id'])[0]['name']\n",
    "        # Draw bounding boxes\n",
    "        x, y, width, height = bbox\n",
    "        plt.gca().add_patch(plt.Rectangle((x, y), width, height, edgecolor='green', facecolor='none', linewidth=2))\n",
    "        # Add category labels\n",
    "        plt.text(x, y - 5, category, color='white', fontsize=12, bbox=dict(facecolor='green', alpha=0.5))\n",
    "    if save_fig:\n",
    "        if title is None:\n",
    "            suffix = f'{image_no}_bb_{fixed_category}.{selected_ext}'\n",
    "        else:\n",
    "            suffix = f'{image_no}_{params.background_type}_heatmap_{title}.{selected_ext}'\n",
    "                                                        \n",
    "        plt.savefig(f'{paths.results_path_single}//{suffix}',dpi=200,transparent=True,bbox_inches='tight', pad_inches=0.02)\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mask(category_mask,category_name=None,save_fig=False,fig_size = (3,3),title=None,selected_ext='png',destroy_fig=False):\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "    # plt.imshow(category_mask, cmap='gray')\n",
    "    \n",
    "    if category_name is None:\n",
    "        cax = plt.imshow(category_mask, cmap='tab20', interpolation='nearest')\n",
    "        plt.colorbar(cax,ax = ax, orientation='vertical')  # Add color bar for clarity\n",
    "        \n",
    "    else:\n",
    "        plt.imshow(category_mask, cmap='gray', interpolation='nearest')\n",
    "    ax.axis('off')\n",
    "    if save_fig:\n",
    "        if title is None:\n",
    "            suffix = f'{image_no}_mask_{fixed_category}.{selected_ext}'\n",
    "        else:\n",
    "            suffix = f'{image_no}_{params.background_type}_heatmap_{title}.{selected_ext}'\n",
    "                                                        \n",
    "        plt.savefig(f'{paths.results_path_single}//{suffix}',dpi=200,transparent=True,bbox_inches='tight', pad_inches=0.02)\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on an image\n",
    "def plot_predictions(image, results, category_name=None, filter_preds=True, line_thickness=2, exp_type='demo', save_fig=False, fig_size=(3, 3), title=None, selected_ext='png', destroy_fig=False):\n",
    "    image_ = image.copy()\n",
    "    save_path = paths.results_path_single if exp_type == 'demo' else paths.plots_path\n",
    "\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    plt.imshow(image_)\n",
    "    plt.axis('off')\n",
    "\n",
    "    for result in results:\n",
    "        # Access detected classes, confidences, and boxes\n",
    "        class_ids = result.boxes.cls.cpu().numpy()  # Class IDs\n",
    "        scores = result.boxes.conf.cpu().numpy()   # Confidence scores\n",
    "        boxes = result.boxes.xyxy.cpu().numpy()    # Bounding boxes in xyxy format\n",
    "        labels = model.names                       # Class labels (MS COCO classes)\n",
    "\n",
    "        # Draw bounding boxes and labels on the image\n",
    "        for box, class_id, score in zip(boxes, class_ids, scores):\n",
    "            label = labels[int(class_id)]\n",
    "            confidence = f\"{score:.2f}\"\n",
    "            x1, y1, x2, y2 = map(int, box)  # Bounding box coordinates\n",
    "\n",
    "            if filter_preds and category_name and label != category_name:\n",
    "                continue\n",
    "\n",
    "            # Draw bounding boxes\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            plt.gca().add_patch(plt.Rectangle((x1, y1), width, height, edgecolor='darkred', facecolor='none', linewidth=line_thickness))\n",
    "\n",
    "            # Add labels with transparency\n",
    "            text = f\"{label} {confidence}\"\n",
    "            plt.text(x1, y1 - 5, text, color='white', fontsize=12, bbox=dict(facecolor='darkred', alpha=0.5))\n",
    "\n",
    "    if save_fig:\n",
    "        suffix = title or \"yolo_predictions\"\n",
    "        save_filename = f\"{save_path}//{image_no}_{suffix}.{selected_ext}\"\n",
    "        plt.savefig(save_filename, dpi=200, transparent=True, bbox_inches='tight', pad_inches=0.02)\n",
    "\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_plot_heatmaps(methods_,heatmaps,exp_type=None,draw_gt_contour=True,title = None,plot_title=False,ttl=None,fontsize=14,plot_colorbar=False,save_fig=True,selected_ext='png',dpi=100,transparent=True,destroy_fig=False):\n",
    "    fig,axes = plt.subplots(1, len(methods_)+2, figsize=(2*(len(methods_)), 2))\n",
    "    \n",
    "    # save_path = paths.results_path_single if exp_type == 'demo' else paths.plots_path\n",
    "    # save_path    = paths.results_path_selected if exp_type == 'selected' else paths.plotsIoU_path\n",
    "    if exp_type == 'demo':\n",
    "        save_path = paths.results_path_single\n",
    "    elif exp_type == 'selected':\n",
    "        save_path    = paths.results_path_selected\n",
    "    else:\n",
    "        save_path    = paths.plots_path\n",
    "\n",
    "    selected_ext = 'svg' if exp_type == 'selected' else 'png'\n",
    "\n",
    "    axes[0].imshow(image_to_explain)\n",
    "    axes[0].set_xticks([]) ; axes[0].set_yticks([])\n",
    "    axes[1].imshow(ground_truth, cmap='binary')\n",
    "    axes[1].set_xticks([]) ; axes[1].set_yticks([])\n",
    "    \n",
    "    for ii, (n,c,_) in enumerate(methods_):\n",
    "        ax = axes[ii+2]\n",
    "        vmax = np.quantile(np.abs(heatmaps[n][0]), 0.99)\n",
    "        ax.imshow(heatmaps[n][0], cmap=shap_bpt.shapley_values_colormap, vmin=-vmax, vmax=vmax)\n",
    "        if draw_gt_contour:\n",
    "            marked_h = mark_boundaries(np.tile((255,255,255,0), (heatmaps[n][0].shape[0],heatmaps[n][0].shape[1],1)), ground_truth, \n",
    "                             mode='thick', color=(0,0,0,1))\n",
    "            ax.imshow(marked_h)\n",
    "        ax.set_xticks([]) ; ax.set_yticks([])\n",
    "        \n",
    "    if ttl is not None:\n",
    "        axes[0].set_yticklabels(str(ttl), fontsize=fontsize)\n",
    "    plt.subplots_adjust(wspace=0.05,hspace=0.05)\n",
    "    # plt.tight_layout(pad = 0.1)\n",
    "    \n",
    "    if save_fig:\n",
    "        if title is None:\n",
    "            suffix = f'{image_no}_{params.background_type}_heatmap.{selected_ext}'\n",
    "        else:\n",
    "            suffix = f'{image_no}_{params.background_type}_heatmap_{title}.{selected_ext}'\n",
    "        # print('save_path',save_path)                                           \n",
    "        plt.savefig(f'{save_path}//{suffix}',dpi=dpi,transparent=True,bbox_inches='tight', pad_inches=0.02)\n",
    "    ##########################################\n",
    "    for ii, (n,c,_) in enumerate(methods_):\n",
    "        ax = axes[ii+2]\n",
    "        if plot_title:\n",
    "            ax.set_title(n, fontsize=fontsize)\n",
    "    ##########################################\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "    plt.show()\n",
    "    del vmax,marked_h\n",
    "###################################################################################################################\n",
    "props         = dict(boxstyle='round', facecolor='white', alpha=0.6, pad=0.2)\n",
    "###################################################################################################################\n",
    "def fun_plot_IoU(methods_,heatmaps,exp_type='demo',title = None,draw_gt_contour=False,plot_title=False,\n",
    "                 fontsize=14,save_fig=True,selected_ext='png',dpi=100,transparent=True,destroy_fig=False,\n",
    "                 text_x=11,text_y=47):\n",
    "    # save_path    = paths.results_path_single if exp_type == 'demo' else paths.plotsIoU_path\n",
    "    # save_path    = paths.results_path_selected if exp_type == 'selected' else paths.plotsIoU_path\n",
    "    if exp_type == 'demo':\n",
    "        save_path = paths.results_path_single\n",
    "    elif exp_type == 'selected':\n",
    "        save_path    = paths.results_path_selected\n",
    "    else:\n",
    "        save_path    = paths.plotsIoU_path\n",
    "\n",
    "    selected_ext = 'svg' if exp_type == 'selected' else 'png'\n",
    "\n",
    "    # {'X': array([          0,  3.2552e-06,  6.5104e-06, ...,     0.99999,     0.99999,           1]),\n",
    "    #  'Y': array([ 0.00019069,  0.00038139,  0.00057208, ...,    0.017074,    0.017074,    0.017074]),\n",
    "    #  'max_IoU': 2.4450657292618416e-05,\n",
    "    #  'x_best': 0.018225911458333334,\n",
    "    #  'auc_IoU': 0.06164667252339603}\n",
    "    fig,axs = plt.subplots(1,  len(methods_)+2, figsize=(2*(len(methods_)), 2))\n",
    "    axs[0].imshow(image_to_explain)\n",
    "    axs[0].set_xticks([]) ; axs[0].set_yticks([])\n",
    "    axs[1].imshow(ground_truth, cmap='binary')\n",
    "    axs[1].set_xticks([]) ; axs[1].set_yticks([])\n",
    "    \n",
    "    for ii, (n,_,_) in tqdm(enumerate(methods_), desc='IoU',leave=False):\n",
    "        ax = axs[ii+2]\n",
    "        auc_IoU =  IoU[n]\n",
    "        img, max_IoU = vis_IoU(heatmaps[n][0], auc_IoU['max_IoU_heatmap_threshold'], ground_truth), np.max(auc_IoU['Y'])\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        if draw_gt_contour:\n",
    "            marked_h = mark_boundaries(np.tile((255,255,255,0), (heatmaps[n][0].shape[0],heatmaps[n][0].shape[1],1)), ground_truth, \n",
    "                             mode='thick', color=(0,0,0,1))\n",
    "            ax.imshow(marked_h)\n",
    "        ax.text(text_x,text_y, f'IoU:{max_IoU:.3}', fontsize=fontsize, bbox=props,weight='bold')\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        if plot_title:\n",
    "            ax.set_title(n, fontsize=fontsize)\n",
    "    plt.subplots_adjust(wspace=0.05,hspace=0.05)\n",
    "    # plt.tight_layout(pad = 0.1)\n",
    "    if save_fig:\n",
    "        if title is None:\n",
    "            suffix = f'{image_no}_{params.background_type}_IoU.{selected_ext}'\n",
    "        else:\n",
    "            suffix = f'{image_no}_{params.background_type}_IoU_{title}.{selected_ext}'\n",
    "\n",
    "        plt.savefig(f'{save_path}//{suffix}',dpi=dpi,transparent=transparent,bbox_inches='tight', pad_inches=0.02)\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "    plt.show()\n",
    "    del img,max_IoU\n",
    "###################################################################################################################\n",
    "# def fun_plot_performance(aa_= 'AA-100',bpt_='BPT-100',save_fig=True,exp_type = 'demo',fontsize=14,selected_ext='png', dpi =150,transparent=True):\n",
    "#     save_path = paths.results_path_single if exp_type == 'demo' else paths.plotsIoU_path\n",
    "    \n",
    "#     fig,axes = plt.subplots(1,5, figsize=(10,2), sharex=True, sharey=True) #3,3  figsize=(8,2.2)\n",
    "#     if len(background_tensors)==1:\n",
    "#         # if model_type=='ideal':    \n",
    "#         aucI_aa =  aucI[aa_]\n",
    "#         aucD_aa =  aucD[aa_]\n",
    "#         auc_IoU_aa =  IoU[aa_]\n",
    "#         ttl = 'PE'\n",
    "#         # else:\n",
    "#         #     aucI_aa =  aucI['Partition-100']\n",
    "#         #     aucD_aa =  aucD['Partition-100']\n",
    "#         #     auc_IoU_aa =  IoU['Partition-100']\n",
    "#     else:\n",
    "#         aucI_aa =  aucI[aa_]\n",
    "#         aucD_aa =  aucD[aa_]\n",
    "#         auc_IoU_aa =  IoU[aa_]\n",
    "#         ttl = 'AA'\n",
    "#     aucI_bpt =  aucI[bpt_]\n",
    "#     aucD_bpt =  aucD[bpt_]\n",
    "#     auc_IoU_bpt =  IoU[bpt_]\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         ax = axes.flat[i]\n",
    "#         if i==0: # insertion/regression\n",
    "#             # Xa,Ya,Ma,La      = aucI_aa['xs'],aucI_aa['ys'],aucI_aa['ms'],aucI_aa['auc_reg']\n",
    "#             title='$\\\\mathit{AUC}^{+}$'\n",
    "#             Xa,Ya,Ma,La      = aucI_aa ['xs'],aucI_aa ['ys'],aucI_aa ['ms'],aucI_aa ['auc_reg']\n",
    "#             Xb,Yb,Mb,Lb      = aucI_bpt['xs'],aucI_bpt['ys'],aucI_bpt['ms'],aucI_bpt['auc_reg']\n",
    "#             # Xb,Yb,Mb,Lb = aucI_bpt[0], aucI_bpt[1], aucI_bpt[2], aucI_bpt[3]\n",
    "#         elif i==1: # deletion/regression\n",
    "#             title='$\\\\mathit{AUC}^{-}$'\n",
    "#             Xa,Ya,Ma,La      = aucD_aa ['xs'],aucD_aa ['ys'],aucD_aa ['ms'],aucD_aa ['auc_reg']\n",
    "#             Xb,Yb,Mb,Lb      = aucD_bpt['xs'],aucD_bpt['ys'],aucD_bpt['ms'],aucD_bpt['auc_reg']\n",
    "            \n",
    "#             # Xa,Ya,Ma,La = aucD_aa[0], aucD_aa[1], aucD_aa[2], aucD_aa[3]\n",
    "#             # Xb,Yb,Mb,Lb = aucD_bpt[0], aucD_bpt[1], aucD_bpt[2], aucD_bpt[3]\n",
    "#     #     elif i==2: # insertion/efficiency\n",
    "#     #         title='$\\\\mathit{AUC}^{+}_\\\\mathrm{eff}$'\n",
    "#     #         Xa,Ya,Ma,La = aucI_aa[0]*100, aucI_aa[1]-aucI_aa[2], aucI_aa[2], aucI_aa[4]\n",
    "#     #         Xb,Yb,Mb,Lb = aucI_bpt[0]*100, aucI_bpt[1]-aucI_bpt[2], aucI_bpt[2], aucI_bpt[4]\n",
    "#     #     elif i==3: # deletion/efficiency\n",
    "#     #         title='$\\\\mathit{AUC}^{-}_\\\\mathrm{eff}$'\n",
    "#     #         Xa,Ya,Ma,La = aucD_aa[0]*100, aucD_aa[1]-aucD_aa[2], aucD_aa[2], aucD_aa[4]\n",
    "#     #         Xb,Yb,Mb,Lb = aucD_bpt[0]*100, aucD_bpt[1]-aucD_bpt[2], aucD_bpt[2], aucD_bpt[4]\n",
    "#         elif i==2: # insertion/error\n",
    "#             title='$\\\\mathit{MSE}^{+}$'\n",
    "#             Xa,Ya,Ma,La      = aucI_aa ['xs'],aucI_aa ['ys'],aucI_aa ['ms'],aucI_aa ['auc_reg']\n",
    "#             Xb,Yb,Mb,Lb      = aucI_bpt['xs'],aucI_bpt['ys'],aucI_bpt['ms'],aucI_bpt['auc_reg']\n",
    "\n",
    "#             Xa,Ya,Ma,La = aucI_aa ['xs'], (aucI_aa ['ys']- aucI_aa  ['ms'])**2, aucI_aa  ['ms'], aucI_aa  ['auc_mse']\n",
    "#             Xb,Yb,Mb,Lb = aucI_bpt ['xs'],(aucI_bpt ['ys']-aucI_bpt ['ms'])**2, aucI_bpt ['ms'], aucI_bpt ['auc_mse']\n",
    "            \n",
    "#             # Xa,Ya,Ma,La = aucI_aa[0], (aucI_aa[1]-aucI_aa[2])**2, aucI_aa[2], aucI_aa[5]\n",
    "#             # Xb,Yb,Mb,Lb = aucI_bpt[0], (aucI_bpt[1]-aucI_bpt[2])**2, aucI_bpt[2], aucI_bpt[5]\n",
    "#         elif i==3: # deletion/error\n",
    "#             title='$\\\\mathit{MSE}^{-}$'\n",
    "#             Xa,Ya,Ma,La = aucI_aa ['xs'], (aucI_aa  ['ys']-aucI_aa  ['ms'])**2, aucI_aa  ['ms'], aucI_aa  ['auc_mse']\n",
    "#             Xb,Yb,Mb,Lb = aucI_bpt ['xs'],(aucI_bpt ['ys']-aucI_bpt ['ms'])**2, aucI_bpt ['ms'], aucI_bpt ['auc_mse']\n",
    "            \n",
    "#             # Xa,Ya,Ma,La = aucD_aa[0], (aucD_aa[1]-aucD_aa[2])**2, aucD_aa[2], aucD_aa[5]\n",
    "#             # Xb,Yb,Mb,Lb = aucD_bpt[0], (aucD_bpt[1]-aucD_bpt[2])**2, aucD_bpt[2], aucD_bpt[5]\n",
    "#         elif i==4: # IoU\n",
    "#             title='$\\\\mathit{AU}{\\!-\\!}\\\\mathit{IoU}$'\n",
    "#             Xa,Ya,Ma,La = auc_IoU_aa['X'], auc_IoU_aa['Y'], None, auc_IoU_aa['auc_IoU']     #[4]\n",
    "#             Xb,Yb,Mb,Lb = auc_IoU_bpt['X'], auc_IoU_bpt['Y'], None, auc_IoU_bpt['auc_IoU']  #[4]\n",
    "#             xma, yma = auc_IoU_aa['x_best'], np.max(auc_IoU_aa['Y'])\n",
    "#             xmb, ymb = auc_IoU_bpt['x_best'], np.max(auc_IoU_bpt['Y'])\n",
    "            \n",
    "#     #     ymax = max(np.max(Ya), np.max(Yb))\n",
    "        \n",
    "#         Sa, Sb = ('\\\\textbf', '') if La<Lb else ('', '\\\\textbf')\n",
    "#         if i in [0,4]:   Sa,Sb=Sb,Sa\n",
    "#         ax.plot(Xa, Ya, c='#2465a6', label=f'{Sa}{{AA}} {La:.4}')\n",
    "#         ax.fill_between(Xa, Ya, color='#2465a6', alpha=0.15, hatch='///')\n",
    "#         # ax.scatter(Xa, Ya, c='black', s=5)\n",
    "#         ax.plot(Xb, Yb, c='#9d2f4d', label=f'{Sb}{{BPT}} {Lb:.4}', alpha=0.80)\n",
    "#         ax.fill_between(Xb, Yb, color='#9d2f4d', alpha=0.15, hatch='\\\\\\\\\\\\')\n",
    "        \n",
    "#         if i==4:\n",
    "#             ax.scatter(xma, yma, s=40, color='blue')\n",
    "#             ax.scatter(xmb, ymb, s=40, color='red')\n",
    "#     #     ax.set_ylim(-0.05, round(ymax+0.1, 1))\n",
    "#         # ax.scatter(Xb, Yb, c='black', s=5)\n",
    "    \n",
    "#     #     if i < 2:\n",
    "#     #         ax.plot(Xa, Ma, c='blue', lw=1, ls=':')\n",
    "#     #         ax.plot(Xb, Mb, c='red', lw=1, ls=':')\n",
    "    \n",
    "#         # if i in [0,1]:\n",
    "#         if i < 2:\n",
    "#             ax.axhline(f_S, ls='--', c='grey', zorder=0)\n",
    "            \n",
    "#         ax.axhline(0, c='lightgrey', zorder=0)\n",
    "#         ax.legend(borderpad=0.2, labelspacing=0.1, loc='upper right' if i>=1 else 'lower right')#, bbox_to_anchor=(1,0))\n",
    "#         ax.set_title(title, fontsize=fontsize)\n",
    "    \n",
    "#     # axes[0].set_xlabel('\\% pixels inserted', fontsize=14)\n",
    "#     # axes[1].set_xlabel('\\% pixels deleted', fontsize=14)\n",
    "#     # axes[2].set_xlabel('\\% pixels inserted', fontsize=14)\n",
    "#     # axes[3].set_xlabel('\\% pixels deleted', fontsize=14)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     suffix = f'{image_no}_{params.background_type}_PM.{selected_ext}'\n",
    "#     if save_fig:\n",
    "#         plt.savefig(f'{save_path}//{suffix}',dpi=dpi,transparent=transparent,bbox_inches='tight', pad_inches=0.02)\n",
    "#         # plt.savefig(f'{paths.results_path_single}/five_metrics_{params.background_type}_2.png', dpi=150, bbox_inches='tight', pad_inches=0.02)\n",
    "#     # plt.savefig(f'{results_path_single}/five_metrics_{background_type}_2.svg', dpi=150, bbox_inches='tight', pad_inches=0.02)\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fun_plot_performance(aucI,aucD,IoU,budget_set='100',path=None,save_fig=True,fontsize=14):\n",
    "\n",
    "#     fig,axes = plt.subplots(1,9, figsize=(20,2.5), sharex=True)#, sharey=True) #3,3  figsize=(8,2.2)\n",
    "#     if len(background_tensors)==1:\n",
    "#         if params.model_type=='ideal':    \n",
    "#             aucI_aa =  aucI['AA-100']\n",
    "#             aucD_aa =  aucD['AA-100']\n",
    "#             auc_IoU_aa =  IoU['AA-100']\n",
    "#             ttl = 'PE'\n",
    "#         else:\n",
    "#             aucI_aa =  aucI['AA-100']\n",
    "#             aucD_aa =  aucD['AA-100']\n",
    "#             auc_IoU_aa =  IoU['AA-100']\n",
    "#     else:\n",
    "#         aucI_aa =  aucI['AA-100']\n",
    "#         aucD_aa =  aucD['AA-100']\n",
    "#         auc_IoU_aa =  IoU['AA-100']\n",
    "#         ttl = 'AA'\n",
    "#     aucI_bpt =  aucI['BPT-100']\n",
    "#     aucD_bpt =  aucD['BPT-100']\n",
    "#     auc_IoU_bpt =  IoU['BPT-100']\n",
    "    \n",
    "#     for i in range(9):\n",
    "#         ax = axes.flat[i]\n",
    "#         ############  AUC\n",
    "#         if i==0: # insertion/regression\n",
    "#             # Xa,Ya,Ma,La      = aucI_aa['xs'],aucI_aa['ys'],aucI_aa['ms'],aucI_aa['auc_reg']\n",
    "#             title='$\\\\mathit{AUC}^{+}$'\n",
    "#             Xa,Ya,Ma,La      = aucI_aa ['xs'],aucI_aa ['ys'],aucI_aa ['ms'],aucI_aa ['auc']\n",
    "#             Xb,Yb,Mb,Lb      = aucI_bpt['xs'],aucI_bpt['ys'],aucI_bpt['ms'],aucI_bpt['auc']\n",
    "#             # Xb,Yb,Mb,Lb = aucI_bpt[0], aucI_bpt[1], aucI_bpt[2], aucI_bpt[3]\n",
    "#         elif i==1: # deletion/regression\n",
    "#             title='$\\\\mathit{AUC}^{-}$'\n",
    "#             Xa,Ya,Ma,La      = aucD_aa ['xs'],aucD_aa ['ys'],aucD_aa ['ms'],aucD_aa ['auc']\n",
    "#             Xb,Yb,Mb,Lb      = aucD_bpt['xs'],aucD_bpt['ys'],aucD_bpt['ms'],aucD_bpt['auc']\n",
    "\n",
    "\n",
    "#         ############  AUC_Adj\n",
    "#         elif i==2: # insertion/error\n",
    "#             title='$\\\\mathit{AUC-Adj}^{+}$'\n",
    "#             Xa,Ya,Ma,La      = aucI_aa ['xs'],aucI_aa ['y_adj'],aucI_aa ['ms'],aucI_aa ['auc_adj']\n",
    "#             Xb,Yb,Mb,Lb      = aucI_bpt['xs'],aucI_bpt['y_adj'],aucI_bpt['ms'],aucI_bpt['auc_adj']\n",
    "#         elif i==3: # deletion/error\n",
    "#             title='$\\\\mathit{AUC-Adj}^{-}$'\n",
    "#             Xa,Ya,Ma,La      = aucD_aa ['xs'],aucD_aa ['y_adj'],aucD_aa ['ms'],aucD_aa ['auc_adj']\n",
    "#             Xb,Yb,Mb,Lb      = aucD_bpt['xs'],aucD_bpt['y_adj'],aucD_bpt['ms'],aucD_bpt['auc_adj']\n",
    "\n",
    "\n",
    "\n",
    "#         ############  AUC_r\n",
    "#         elif i==4: # insertion/error\n",
    "#             title='$\\\\mathit{AUC-r}^{+}$'\n",
    "#             Xa,Ya,Ma,La      = aucI_aa ['xs'],aucI_aa ['ysr'],aucI_aa ['ms'],aucI_aa ['auc_r']\n",
    "#             Xb,Yb,Mb,Lb      = aucI_bpt['xs'],aucI_bpt['ysr'],aucI_bpt['ms'],aucI_bpt['auc_r']            \n",
    "        \n",
    "#         elif i==5: # deletion/error\n",
    "#             title='$\\\\mathit{AUC-r}^{-}$'\n",
    "#             Xa,Ya,Ma,La      = aucD_aa ['xs'],aucD_aa ['ysr'],aucD_aa ['ms'],aucD_aa ['auc_r']\n",
    "#             Xb,Yb,Mb,Lb      = aucD_bpt['xs'],aucD_bpt['ysr'],aucD_bpt['ms'],aucD_bpt['auc_r']\n",
    "\n",
    "        \n",
    "\n",
    "#         ############  AUC_Adj_r\n",
    "\n",
    "\n",
    "#         elif i==6: # insertion/error\n",
    "#             title='$\\\\mathit{AUC-Adj-r}^{+}$'\n",
    "#             Xa,Ya,Ma,La      = aucI_aa ['xs'],aucI_aa ['y_adjr'],aucI_aa ['ms'],aucI_aa ['auc_adjr']\n",
    "#             Xb,Yb,Mb,Lb      = aucI_bpt['xs'],aucI_bpt['y_adjr'],aucI_bpt['ms'],aucI_bpt['auc_adjr']\n",
    "#         elif i==7: # deletion/error\n",
    "#             title='$\\\\mathit{AUC-Adj-r}^{-}$'\n",
    "#             Xa,Ya,Ma,La      = aucD_aa ['xs'],aucD_aa ['y_adjr'],aucD_aa ['ms'],aucD_aa ['auc_adjr']\n",
    "#             Xb,Yb,Mb,Lb      = aucD_bpt['xs'],aucD_bpt['y_adjr'],aucD_bpt['ms'],aucD_bpt['auc_adjr']\n",
    "            \n",
    "#         elif i==8: # IoU\n",
    "#             # return {'X':X2, 'Y':IoU2,\n",
    "#             #  'max_IoU_heatmap_threshold':Th[best_pt], \n",
    "#             # 'max_IoU_score':IoU2[best_pt], 'x_best':X2[best_pt], 'auc_IoU':auc_IoU}\n",
    "#             title='$\\\\mathit{AU}{\\!-\\!}\\\\mathit{IoU}$'\n",
    "#             Xa,Ya,Ma,La = auc_IoU_aa['X'], auc_IoU_aa['Y'], None, auc_IoU_aa['x_best']\n",
    "#             Xb,Yb,Mb,Lb = auc_IoU_bpt['X'], auc_IoU_bpt['Y'], None, auc_IoU_bpt['x_best']\n",
    "\n",
    "#             xma, yma = auc_IoU_aa['max_IoU_score'], np.max(auc_IoU_aa['Y'])\n",
    "#             xmb, ymb = auc_IoU_bpt['max_IoU_score'], np.max(auc_IoU_bpt['Y'])\n",
    "            \n",
    "#         # print(i,'  len(Xb): ',len(Xb),'  len(Yb): ', len(Yb), len(Xb)==len(Yb), '  len(Xa): ',len(Xa),'  len(Ya): ', len(Ya), len(Xa)==len(Ya))\n",
    "#     #     ymax = max(np.max(Ya), np.max(Yb))\n",
    "        \n",
    "#         Sa, Sb = ('\\\\textbf', '') if La<Lb else ('', '\\\\textbf')\n",
    "#         if i in [0,2,4,6, 8]:   Sa,Sb=Sb,Sa\n",
    "#         ax.plot(Xa, Ya, c='#2465a6', label=f'{Sa}{{AA}} {La:.4}')\n",
    "#         ax.fill_between(Xa, Ya, color='#2465a6', alpha=0.15, hatch='///')\n",
    "#         # ax.scatter(Xa, Ya, c='black', s=5)\n",
    "#         ax.plot(Xb, Yb, c='#9d2f4d', label=f'{Sb}{{BPT}} {Lb:.4}', alpha=0.80)\n",
    "#         ax.fill_between(Xb, Yb, color='#9d2f4d', alpha=0.15, hatch='\\\\\\\\\\\\')\n",
    "        \n",
    "#         if i==8:\n",
    "#             ax.scatter(xma, yma, s=40, color='blue')\n",
    "#             ax.scatter(xmb, ymb, s=40, color='red')\n",
    "\n",
    "#         if i < 4:\n",
    "#             ax.axhline(f_S, ls='--', c='grey', zorder=0)\n",
    "            \n",
    "#         ax.axhline(0, c='lightgrey', zorder=0)\n",
    "#         ax.legend(borderpad=0.2, labelspacing=0.1, loc='upper right' if i>=1 else 'lower right')#, bbox_to_anchor=(1,0))\n",
    "#         ax.set_title(title, fontsize=fontsize)\n",
    "    \n",
    "#     # axes[0].set_xlabel('\\% pixels inserted', fontsize=14)\n",
    "#     # axes[1].set_xlabel('\\% pixels deleted', fontsize=14)\n",
    "#     # axes[2].set_xlabel('\\% pixels inserted', fontsize=14)\n",
    "#     # axes[3].set_xlabel('\\% pixels deleted', fontsize=14)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     if save_fig:\n",
    "#         if path is not None:\n",
    "#             plt.savefig(f'{path}/{image_n}_five_metrics_{params.background_type}_2.png', dpi=150, bbox_inches='tight', pad_inches=0.02)\n",
    "#         else:\n",
    "#             print('path is None')\n",
    "#     # plt.savefig(f'{path}/five_metrics_{background_type}_2.svg', dpi=150, bbox_inches='tight', pad_inches=0.02)\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('text',usetex=True)\n",
    "rc('text.latex', preamble='\\\\usepackage{color}')\n",
    "\n",
    "def fun_plot_performance(aucI, aucD, IoU,\n",
    "                         list_variants=['BPT-100', 'AA-100', 'LIME-100'],\n",
    "                         budget_set='100',\n",
    "                         path=None,\n",
    "                         file_name='',\n",
    "                         save_fig=True,\n",
    "                         fontsize=14,\n",
    "                         set_title=False,\n",
    "                         plot_lime=False,\n",
    "                         ttl=None,\n",
    "                         layout='row'  # 'row' or '2rows'\n",
    "                         ):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Order of plots (grouped by column for 2-row layout)\n",
    "    plot_defs = [\n",
    "        {'title': '$\\\\mathit{AUC}^{+}$',         'typee': 'auc',        'from': 'aucI'}, # 0\n",
    "        {'title': '$\\\\mathit{AUC}^{-}$',         'typee': 'auc',        'from': 'aucD'}, # 1\n",
    "        {'title': '$\\\\mathit{AUC}^{+}-clip$',     'typee': 'auc_clip',   'from': 'aucI'}, # 2\n",
    "        {'title': '$\\\\mathit{AUC}^{-}-clip$',     'typee': 'auc_clip',   'from': 'aucD'}, # 3\n",
    "        {'title': '$\\\\mathit{AUC^{+}-Adj}$',     'typee': 'auc_adj',    'from': 'aucI'}, # 4\n",
    "        {'title': '$\\\\mathit{AUC^{-}-Adj}$',     'typee': 'auc_adj',    'from': 'aucD'}, # 5\n",
    "        \n",
    "        {'title': '$\\\\mathit{AU}{\\!-\\!}\\\\mathit{IoU}$', 'typee': 'auc_iou', 'from': 'iou'}, # 6 \n",
    "        #####################################################################\n",
    "\n",
    "        {'title': '$\\\\mathit{AUC}^{+}-r$',       'typee': 'auc_r',      'from': 'aucI'}, # 7\n",
    "        {'title': '$\\\\mathit{AUC}^{-}-r$',       'typee': 'auc_r',      'from': 'aucD'}, # 8\n",
    "        {'title': '$\\\\mathit{AUC}^{+}-clip-r$', 'typee': 'auc_clip_r', 'from': 'aucI'}, # 9\n",
    "        {'title': '$\\\\mathit{AUC}^{-}-clip-r$', 'typee': 'auc_clip_r', 'from': 'aucD'}, # 10\n",
    "        {'title': '$\\\\mathit{AUC^{+}-Adj-r}$',   'typee': 'auc_adj_r',  'from': 'aucI'}, # 11\n",
    "        {'title': '$\\\\mathit{AUC^{-}-Adj-r}$',   'typee': 'auc_adj_r',  'from': 'aucD'}, # 12 \n",
    "        \n",
    "    ]\n",
    "    save_version = list_variants[0].split('-')[-1]\n",
    "    # Reorder plot_defs for 2-row layout: interleaved columns\n",
    "    if layout == '2rows':\n",
    "        top = plot_defs[0::2]\n",
    "        bottom = plot_defs[1::2]\n",
    "        plot_defs = [None]*(len(top)+len(bottom))\n",
    "        plot_defs[::2] = top\n",
    "        plot_defs[1::2] = bottom\n",
    "\n",
    "    total_variant = len(plot_defs)\n",
    "\n",
    "    # Layout config\n",
    "    if layout == 'row':\n",
    "        nrows, ncols = 1, total_variant\n",
    "        fig_width, fig_height = 25, 2.5\n",
    "    elif layout == '2rows':\n",
    "        nrows, ncols = 2, int(np.ceil(total_variant / 2))\n",
    "        fig_width, fig_height = 16, 5\n",
    "    else:\n",
    "        raise ValueError(\"layout must be either 'row' or '2rows'\")\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(fig_width, fig_height))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Alias\n",
    "    aucI_aa = aucI[list_variants[0]]\n",
    "    aucD_aa = aucD[list_variants[0]]\n",
    "    auc_IoU_aa = IoU[list_variants[0]]\n",
    "\n",
    "    aucI_bpt = aucI[list_variants[1]]\n",
    "    aucD_bpt = aucD[list_variants[1]]\n",
    "    auc_IoU_bpt = IoU[list_variants[1]]\n",
    "\n",
    "    aucI_lime = aucI[list_variants[2]]\n",
    "    aucD_lime = aucD[list_variants[2]]\n",
    "    auc_IoU_lime = IoU[list_variants[2]]\n",
    "\n",
    "    def get_params_auc(auc_, typee):\n",
    "        return {\n",
    "            'auc':        (auc_['xs'], auc_['ys'],     auc_['ms'], auc_['auc']),\n",
    "            'auc_r':      (auc_['xs'], auc_['ysr'],    auc_['ms'], auc_['auc_r']),\n",
    "            'auc_adj':    (auc_['xs'], auc_['y_adj'],  auc_['ms'], auc_['auc_adj']),\n",
    "            'auc_adj_r':  (auc_['xs'], auc_['y_adjr'], auc_['ms'], auc_['auc_adjr']),\n",
    "            'auc_clip':   (auc_['xs'], auc_['y_clip'], auc_['ms'], auc_['auc_clip']),\n",
    "            'auc_clip_r': (auc_['xs'], auc_['y_clipr'],auc_['ms'], auc_['auc_clipr']),\n",
    "        }.get(typee, (None, None, None, None))\n",
    "\n",
    "    def get_params_iou(iou_, typee):\n",
    "        if typee == 'auc_iou':\n",
    "\n",
    "            # xmb, ymb = iou_[3], np.max(iou_[1])\n",
    "\n",
    "            Xa,Ya,Ma,La = iou_['X'], iou_['Y'], None, iou_['x_best']\n",
    "            # Xb,Yb,Mb,Lb = auc_IoU_bpt['X'], auc_IoU_bpt['Y'], None, auc_IoU_bpt['x_best']\n",
    "\n",
    "            xma, yma = iou_['max_IoU_score'], np.max(iou_['Y'])\n",
    "            # xmb, ymb = auc_IoU_bpt['max_IoU_score'], np.max(auc_IoU_bpt['Y'])\n",
    "\n",
    "            # Xa, Ya, Ma, La = iou_[0], iou_[1], None, iou_[4]\n",
    "            # xma, yma = iou_[3], np.max(iou_[1])\n",
    "            return Xa, Ya, Ma, La, xma, yma\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "    for i, config in enumerate(plot_defs):\n",
    "        ax = axes[i]\n",
    "        title = config['title']\n",
    "        typee = config['typee']\n",
    "        source = config['from']\n",
    "\n",
    "        # Select correct dict\n",
    "        if source == 'aucI':\n",
    "            Xa, Ya, Ma, La = get_params_auc(aucI_aa, typee)\n",
    "            Xb, Yb, Mb, Lb = get_params_auc(aucI_bpt, typee)\n",
    "            Xl, Yl, Ml, Ll = get_params_auc(aucI_lime, typee)\n",
    "        elif source == 'aucD':\n",
    "            Xa, Ya, Ma, La = get_params_auc(aucD_aa, typee)\n",
    "            Xb, Yb, Mb, Lb = get_params_auc(aucD_bpt, typee)\n",
    "            Xl, Yl, Ml, Ll = get_params_auc(aucD_lime, typee)\n",
    "        elif source == 'iou':\n",
    "            Xa, Ya, Ma, La, xma, yma = get_params_iou(auc_IoU_aa,  typee)\n",
    "            Xb, Yb, Mb, Lb, xmb, ymb = get_params_iou(auc_IoU_bpt, typee)\n",
    "            Xl, Yl, Ml, Ll, xml, yml = get_params_iou(auc_IoU_lime,   typee)\n",
    "\n",
    "        # Boldness logic\n",
    "        Sa, Sb = ('\\\\textbf', '') if La < Lb else ('', '\\\\textbf')\n",
    "        if i in [0,2,4,6,8]: Sa, Sb = Sb, Sa\n",
    "\n",
    "        # Plot\n",
    "        ax.plot(Xa, Ya, c='#2465a6', label=f'{Sa}{{AA}} {La:.4f}')\n",
    "        ax.fill_between(Xa, Ya, color='#2465a6', alpha=0.15, hatch='///')\n",
    "        ##########\n",
    "        ax.plot(Xb, Yb, c='#9d2f4d', label=f'{Sb}{{BPT}} {Lb:.4f}', alpha=0.80)\n",
    "        ax.fill_between(Xb, Yb, color='#9d2f4d', alpha=0.15, hatch='\\\\\\\\\\\\')\n",
    "        ##########\n",
    "        if plot_lime:\n",
    "            ax.plot(Xl, Yl, c=\"#01B0A7\", label=f'{Sb}{{LM}} {Ll:.4f}', alpha=0.80)\n",
    "            ax.fill_between(Xl, Yl, color='#01B0A7', alpha=0.15, hatch='\\\\\\\\\\\\')\n",
    "\n",
    "\n",
    "        if typee == 'auc_iou':\n",
    "            ax.scatter(xma, yma, s=40, color='blue')\n",
    "            ax.scatter(xmb, ymb, s=40, color='red')\n",
    "\n",
    "        if i < 4:\n",
    "            ax.axhline(0.0, ls='--', c='grey', zorder=0)  # placeholder for f_S - f_0\n",
    "\n",
    "        ax.axhline(0, c='lightgrey', zorder=0)\n",
    "        ax.legend(borderpad=0.2, labelspacing=0.1, loc='upper right' if i>=1 else 'lower right')\n",
    "        ax.set_title(title, fontsize=fontsize)\n",
    "    axes[-1].imshow(image_to_explain); axes[-1].set_xticks([]); axes[-1].set_yticks([])\n",
    "    axes[-1].set_title(f'{ttl.split(\",\")[0]} - {class_names[predicted_cls]} {f_S}')\n",
    "    if set_title:\n",
    "        plt.suptitle(f'{ttl}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_fig and path is not None:\n",
    "        plt.savefig(f'{path}/{file_name}_{save_version}_paired_auc_metrics.png', dpi=150, bbox_inches='tight', pad_inches=0.02)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perform_iou(methods_, save_fig=True, exp_type='demo', fontsize=12, selected_ext='png', dpi=150, transparent=True):\n",
    "    save_path = paths.results_path_single if exp_type == 'demo' else paths.plotsIoU_path\n",
    "    # fig,axs = plt.subplots(1,  len(methods_)+2, figsize=(2*(len(methods_)), 2))\n",
    "    \n",
    "    n_cols = len(methods_) + 2  # Number of subplots\n",
    "    fig, axs = plt.subplots(1, n_cols, figsize=(2 * n_cols-2, 2), constrained_layout=True)  # Constrained layout for uniform spacing\n",
    "\n",
    "    # Plot first subplot (image to explain)\n",
    "    axs[0].imshow(image_to_explain)\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "\n",
    "    # Plot second subplot (ground truth)\n",
    "    axs[1].imshow(ground_truth, cmap='binary')\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "\n",
    "    # Loop through methods and plot IoU\n",
    "    for ii, (n, _, _) in tqdm(enumerate(methods_), desc='IoU', leave=False):\n",
    "        ax = axs[ii + 2]\n",
    "        auc_IoU = IoU[n]\n",
    "        Xa, Ya, Ma, La = auc_IoU['X'], auc_IoU['Y'], None, auc_IoU['auc_IoU']\n",
    "        xma, yma = auc_IoU['x_best'], np.max(auc_IoU['Y'])\n",
    "\n",
    "        ax.plot(Xa, Ya, c='#2465a6', label=f'{La:.4}')\n",
    "        ax.fill_between(Xa, Ya, color='#2465a6', alpha=0.15, hatch='///')\n",
    "        ax.scatter(xma, yma, s=40, color='blue')\n",
    "        ax.axhline(f_S, ls='--', c='grey', zorder=0)\n",
    "        ax.axhline(0, c='lightgrey', zorder=0)\n",
    "        ax.legend(borderpad=0.2, labelspacing=0.1, loc='upper right', fontsize=fontsize)\n",
    "        ax.set_title('$\\\\mathit{AU}{\\!-\\!}\\\\mathit{IoU}$', fontsize=fontsize)\n",
    "        # ax.set_xticks([])\n",
    "        # ax.set_yticks([])\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.subplots_adjust(wspace=0.1)\n",
    "\n",
    "    # Save figure\n",
    "    if save_fig:\n",
    "        suffix = f'{image_no}_{params.background_type}_PM_iou.{selected_ext}'\n",
    "        plt.savefig(f'{save_path}//{suffix}', dpi=dpi, transparent=transparent, bbox_inches='tight', pad_inches=0.02)\n",
    "        print(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTER METHODS for Fewer XAI for PAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_plot_filtered_heatmaps(methods_, heatmaps, exp_type=None, draw_gt_contour=True, title=None, \n",
    "                               plot_title=False, ttl=None, fontsize=14, plot_colorbar=False, save_fig=True, \n",
    "                               selected_ext='svg', dpi=200, transparent=True, destroy_fig=False, filter_methods=None):\n",
    "    \n",
    "    # Filter methods based on user selection\n",
    "    selected_methods = [(n, c, v) for n, c, v in methods_ if filter_methods is None or n in filter_methods]\n",
    "    num_methods = len(selected_methods)\n",
    "\n",
    "    # If no methods are selected, exit\n",
    "    if num_methods == 0:\n",
    "        print(\"No methods selected for filtering. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Define save path\n",
    "    if exp_type == 'demo':\n",
    "        save_path = paths.results_path_single\n",
    "    elif exp_type == 'selected':\n",
    "        save_path = paths.results_path_selected\n",
    "    else:\n",
    "        save_path = paths.plots_path\n",
    "\n",
    "    # Change file extension for selected experiments\n",
    "    selected_ext = 'svg' if exp_type == 'selected' else 'png'\n",
    "\n",
    "    # Set up subplots: input + ground truth + selected methods\n",
    "    num_subplots = num_methods + 2\n",
    "    fig, axes = plt.subplots(1, num_subplots, figsize=(2 * num_subplots, 2))\n",
    "\n",
    "    # Plot Input Image\n",
    "    axes[0].imshow(image_to_explain)\n",
    "    axes[0].set_xticks([]) \n",
    "    axes[0].set_yticks([])\n",
    "\n",
    "    # Plot Ground Truth\n",
    "    axes[1].imshow(ground_truth, cmap='binary')\n",
    "    axes[1].set_xticks([]) \n",
    "    axes[1].set_yticks([])\n",
    "\n",
    "    # Plot Heatmaps for Selected Methods\n",
    "    for i, (n, c, _) in enumerate(selected_methods):\n",
    "        ax = axes[i + 2]\n",
    "        vmax = np.quantile(np.abs(heatmaps[n][0]), 0.99)\n",
    "        ax.imshow(heatmaps[n][0], cmap=shap_bpt.shapley_values_colormap, vmin=-vmax, vmax=vmax)\n",
    "\n",
    "        # Draw Ground Truth Contours if enabled\n",
    "        if draw_gt_contour:\n",
    "            marked_h = mark_boundaries(\n",
    "                np.tile((255, 255, 255, 0), (heatmaps[n][0].shape[0], heatmaps[n][0].shape[1], 1)), \n",
    "                ground_truth, mode='thick', color=(0, 0, 0, 1)\n",
    "            )\n",
    "            ax.imshow(marked_h)\n",
    "\n",
    "        ax.set_xticks([]) \n",
    "        ax.set_yticks([])\n",
    "\n",
    "        if plot_title:\n",
    "            ax.set_title(n, fontsize=fontsize)\n",
    "\n",
    "    # Add optional Y-axis label\n",
    "    if ttl is not None:\n",
    "        axes[0].set_yticklabels(str(ttl), fontsize=fontsize)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    # Save figure if required\n",
    "    if save_fig:\n",
    "        if title is None:\n",
    "            suffix = f'{image_no}_{params.background_type}_filtered_heatmap.{selected_ext}'\n",
    "        else:\n",
    "            suffix = f'{image_no}_{params.background_type}_filtered_heatmap_{title}.{selected_ext}'\n",
    "        \n",
    "        print('Saving to:', save_path)\n",
    "        plt.savefig(f'{save_path}//{suffix}', dpi=dpi, transparent=transparent, bbox_inches='tight', pad_inches=0.02)\n",
    "\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "\n",
    "    plt.show()\n",
    "    del vmax, marked_h\n",
    "################################################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fun_plot_filtered_IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_plot_filtered_IoU(methods_, heatmaps, exp_type='demo', title=None, draw_gt_contour=False, \n",
    "                           plot_title=False, fontsize=14, save_fig=True, selected_ext='svg', dpi=200, \n",
    "                           transparent=True, destroy_fig=False, filter_methods=None):\n",
    "    \n",
    "    # Filter methods based on user selection\n",
    "    selected_methods = [(n, c, v) for n, c, v in methods_ if filter_methods is None or n in filter_methods]\n",
    "    num_methods = len(selected_methods)\n",
    "\n",
    "    # If no methods are selected, exit\n",
    "    if num_methods == 0:\n",
    "        print(\"No methods selected for filtering. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Define save path\n",
    "    if exp_type == 'demo':\n",
    "        save_path = paths.results_path_single\n",
    "    elif exp_type == 'selected':\n",
    "        save_path = paths.results_path_selected\n",
    "    else:\n",
    "        save_path = paths.plotsIoU_path\n",
    "\n",
    "    # Change file extension for selected experiments\n",
    "    selected_ext = 'svg' if exp_type == 'selected' else 'png'\n",
    "    \n",
    "    # Set up subplots: input + ground truth + selected methods\n",
    "    num_subplots = num_methods + 2\n",
    "    fig, axs = plt.subplots(1, num_subplots, figsize=(2 * num_subplots, 2))\n",
    "\n",
    "    # Plot Input Image\n",
    "    axs[0].imshow(image_to_explain)\n",
    "    axs[0].set_xticks([]) \n",
    "    axs[0].set_yticks([])\n",
    "\n",
    "    # Plot Ground Truth\n",
    "    axs[1].imshow(ground_truth, cmap='binary')\n",
    "    axs[1].set_xticks([]) \n",
    "    axs[1].set_yticks([])\n",
    "\n",
    "    # Plot IoU Heatmaps for Selected Methods\n",
    "    for i, (n, _, _) in tqdm(enumerate(selected_methods), desc='IoU', leave=False):\n",
    "        ax = axs[i + 2]\n",
    "        auc_IoU = IoU[n]\n",
    "        img, max_IoU = vis_IoU(heatmaps[n][0], auc_IoU['max_IoU_heatmap_threshold'], ground_truth), np.max(auc_IoU['Y'])\n",
    "\n",
    "        ax.imshow(img)\n",
    "\n",
    "        # Draw Ground Truth Contours if enabled\n",
    "        if draw_gt_contour:\n",
    "            marked_h = mark_boundaries(\n",
    "                np.tile((255, 255, 255, 0), (heatmaps[n][0].shape[0], heatmaps[n][0].shape[1], 1)), \n",
    "                ground_truth, mode='thick', color=(0, 0, 0, 1)\n",
    "            )\n",
    "            ax.imshow(marked_h)\n",
    "\n",
    "        ax.text(20, 60, f'IoU:{max_IoU:.3}', fontsize=fontsize, bbox=props, weight='bold')\n",
    "        ax.set_xticks([]) \n",
    "        ax.set_yticks([])\n",
    "\n",
    "        if plot_title:\n",
    "            ax.set_title(n, fontsize=fontsize)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    # Save figure if required\n",
    "    if save_fig:\n",
    "        if title is None:\n",
    "            suffix = f'{image_no}_{params.background_type}_filtered_IoU.{selected_ext}'\n",
    "        else:\n",
    "            suffix = f'{image_no}_{params.background_type}_filtered_IoU_{title}.{selected_ext}'\n",
    "        \n",
    "        print('Saving to:', save_path)\n",
    "        plt.savefig(f'{save_path}//{suffix}', dpi=dpi, transparent=transparent, bbox_inches='tight', pad_inches=0.02)\n",
    "\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "\n",
    "    plt.show()\n",
    "    del img, max_IoU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot_perform_filtered_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perform_filtered_iou(methods_, save_fig=True, exp_type='demo', fontsize=12, selected_ext='png', \n",
    "                              dpi=150, transparent=True, filter_methods=None):\n",
    "    \n",
    "    # Filter methods based on user selection\n",
    "    selected_methods = [(n, c, v) for n, c, v in methods_ if filter_methods is None or n in filter_methods]\n",
    "    num_methods = len(selected_methods)\n",
    "\n",
    "    # If no methods are selected, exit\n",
    "    if num_methods == 0:\n",
    "        print(\"No methods selected for filtering. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Define save path\n",
    "    save_path = paths.results_path_single if exp_type == 'demo' else paths.plotsIoU_path\n",
    "\n",
    "    # Number of subplots (input image + ground truth + filtered methods)\n",
    "    num_subplots = num_methods + 2\n",
    "    fig, axs = plt.subplots(1, num_subplots, figsize=(2 * num_subplots - 2, 2), constrained_layout=True)\n",
    "\n",
    "    # Plot Input Image\n",
    "    axs[0].imshow(image_to_explain)\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "\n",
    "    # Plot Ground Truth\n",
    "    axs[1].imshow(ground_truth, cmap='binary')\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "\n",
    "    # Plot IoU Curves for Selected Methods\n",
    "    for i, (n, _, _) in tqdm(enumerate(selected_methods), desc='IoU', leave=False):\n",
    "        ax = axs[i + 2]\n",
    "        auc_IoU = IoU[n]\n",
    "        Xa, Ya, La = auc_IoU['X'], auc_IoU['Y'], auc_IoU['auc_IoU']\n",
    "        xma, yma = auc_IoU['x_best'], np.max(auc_IoU['Y'])\n",
    "\n",
    "        ax.plot(Xa, Ya, c='#2465a6', label=f'{La:.4}')\n",
    "        ax.fill_between(Xa, Ya, color='#2465a6', alpha=0.15, hatch='///')\n",
    "        ax.scatter(xma, yma, s=40, color='blue')\n",
    "        ax.axhline(f_S, ls='--', c='grey', zorder=0)\n",
    "        ax.axhline(0, c='lightgrey', zorder=0)\n",
    "        ax.legend(borderpad=0.2, labelspacing=0.1, loc='upper right', fontsize=fontsize)\n",
    "        ax.set_title('$\\\\mathit{AU}{\\!-\\!}\\\\mathit{IoU}$', fontsize=fontsize)\n",
    "\n",
    "    # Adjust subplot spacing\n",
    "    plt.subplots_adjust(wspace=0.1)\n",
    "\n",
    "    # Save figure if required\n",
    "    if save_fig:\n",
    "        suffix = f'{image_no}_{params.background_type}_filtered_PM_iou.{selected_ext}'\n",
    "        plt.savefig(f'{save_path}//{suffix}', dpi=dpi, transparent=transparent, bbox_inches='tight', pad_inches=0.02)\n",
    "        print('Saved at:', save_path)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fun_plot_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_plot_performance_filtered(selected_methods, aa_='AA-500', bpt_='BPT-500', save_fig=True, exp_type='demo', fontsize=14, selected_ext='png', dpi=150, transparent=True):\n",
    "    save_path = paths.results_path_single if exp_type == 'demo' else paths.plotsIoU_path\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10, 2), sharex=True, sharey=True)\n",
    "\n",
    "    auc_data = {}  # Store selected methods' data\n",
    "\n",
    "    for method in selected_methods:\n",
    "        if method in aucI and method in aucD and method in IoU:\n",
    "            auc_data[method] = {\n",
    "                'aucI': aucI[method],\n",
    "                'aucD': aucD[method],\n",
    "                'IoU': IoU[method]\n",
    "            }\n",
    "\n",
    "    # Assign colors based on the method (blue for AA and red for BPT)\n",
    "    method_colors = {aa_: '#2465a6', bpt_: '#9d2f4d'}\n",
    "\n",
    "    for i in range(5):\n",
    "        ax = axes.flat[i]\n",
    "        title = \"\"\n",
    "        \n",
    "        for method, data in auc_data.items():\n",
    "            # Assign the color based on the method (AA or BPT)\n",
    "            color = method_colors.get(method, '#000000')  # Default to black if method is not AA or BPT\n",
    "            label = f\"{method} {data['aucI']['auc_reg']:.4}\"  # Example metric label\n",
    "\n",
    "            if i == 0:  # AUC+\n",
    "                title = '$\\\\mathit{AUC}^{+}$'\n",
    "                Xa, Ya, Ma, La = data['aucI']['xs'], data['aucI']['ys'], data['aucI']['ms'], data['aucI']['auc_reg']\n",
    "            elif i == 1:  # AUC-\n",
    "                title = '$\\\\mathit{AUC}^{-}$'\n",
    "                Xa, Ya, Ma, La = data['aucD']['xs'], data['aucD']['ys'], data['aucD']['ms'], data['aucD']['auc_reg']\n",
    "            elif i == 2:  # MSE+\n",
    "                title = '$\\\\mathit{MSE}^{+}$'\n",
    "                Xa, Ya, Ma, La = data['aucI']['xs'], (data['aucI']['ys'] - data['aucI']['ms']) ** 2, data['aucI']['ms'], data['aucI']['auc_mse']\n",
    "            elif i == 3:  # MSE-\n",
    "                title = '$\\\\mathit{MSE}^{-}$'\n",
    "                Xa, Ya, Ma, La = data['aucD']['xs'], (data['aucD']['ys'] - data['aucD']['ms']) ** 2, data['aucD']['ms'], data['aucD']['auc_mse']\n",
    "            elif i == 4:  # IoU\n",
    "                title = '$\\\\mathit{AU}{\\!-\\!}\\\\mathit{IoU}$'\n",
    "                Xa, Ya, Ma, La = data['IoU']['X'], data['IoU']['Y'], None, data['IoU']['auc_IoU']\n",
    "\n",
    "            ax.plot(Xa, Ya, c=color, label=label, alpha=0.8)\n",
    "            ax.fill_between(Xa, Ya, color=color, alpha=0.15)\n",
    "\n",
    "        ax.set_title(title, fontsize=fontsize)\n",
    "        ax.legend(loc='upper right' if i >= 1 else 'lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_fig:\n",
    "        suffix = f\"{selected_ext}\"\n",
    "        plt.savefig(f\"{save_path}/performance_plot_{suffix}\", dpi=dpi, transparent=transparent, bbox_inches=\"tight\", pad_inches=0.02)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(image_to_explain.shape)\n",
    "results = model.predict(image_to_explain,verbose=True)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top-k classes\n",
    "def get_top_k_classes(results, k=3):\n",
    "    # Predictions contain bounding boxes with associated scores and classes\n",
    "    class_names = model.names\n",
    "    top_k = []\n",
    "    for result_ in results:\n",
    "        boxes = result_.boxes  # List of bounding boxes\n",
    "        # Iterate through the bounding boxes\n",
    "        for box in boxes:\n",
    "            score = box.conf  # Confidence score\n",
    "            class_id = box.cls  # Class ID\n",
    "            top_k.append((int(class_id.item()),class_names[int(class_id.item())], score.item()))\n",
    "\n",
    "        # Sort by confidence and take top-k\n",
    "        top_k = sorted(top_k, key=lambda x: x[2], reverse=True)[:k]\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_classes = get_top_k_classes(results, k=params.top_classes_n)\n",
    "print(\"Top-k Classes (Class ID, Confidence):\", top_k_classes)\n",
    "\n",
    "print([class_names[int(cls)] for cls, _,_ in top_k_classes])\n",
    "print('-'*120)\n",
    "\n",
    "print('top_k_classes \\t', top_k_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predictions(image_to_explain,results,category_name = 'person')\n",
    "# plot_predictions(image_to_explain,results,category_name = 'tv')\n",
    "plot_predictions(image_to_explain,results,category_name = fixed_category,fig_size=(5,5), save_fig=True)\n",
    "\n",
    "# plot_predictions(image_to_explain,results, filter_preds=False)\n",
    "# plot_predictions(image_to_explain,results, filter_preds=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNC:   MASKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_to_explain_tensor = image\n",
    "\n",
    "def predict_yolo_masked(masks):\n",
    "    imglst_preds = []\n",
    "    for mask in masks:\n",
    "        preds = []\n",
    "        for repl in background_image_set:\n",
    "            # print(mask.shape, repl.shape)\n",
    "            if len(mask.shape)==2:\n",
    "                mask3 = np.stack([mask,mask,mask], axis=2)\n",
    "            else:\n",
    "                mask3 = mask.copy()\n",
    "            masked_image = np.where(mask3, image_to_explain, repl)\n",
    "            preds.append(predict_yolo(masked_image))\n",
    "\n",
    "        preds = np.mean(preds, axis=0)\n",
    "        imglst_preds.append(preds)       \n",
    "    \n",
    "    return np.array(imglst_preds)\n",
    "\n",
    "def predict_yolo(x,verbose=False):\n",
    "    # start_time = time.time()\n",
    "    # predict_yolo_masked\n",
    "    # res = model(x)[0]\n",
    "    x = torch.from_numpy(x).to(device)\n",
    "    x = x.cpu().numpy()\n",
    "    # x = x.to(device)\n",
    "    \n",
    "    res = model.predict(x,verbose=verbose)[0]\n",
    "    # probs = []\n",
    "    # for res in results_:\n",
    "    p = np.zeros(80)\n",
    "    for cls,prob in zip(res.boxes.cls.cpu().numpy(), res.boxes.conf.cpu().numpy()):\n",
    "        p[int(cls)] = prob\n",
    "\n",
    "            # print(cls,prob)\n",
    "        # probs.append(p)\n",
    "    # computation_time = time.time() - start_time  # End timer\n",
    "    torch.cuda.empty_cache()\n",
    "    return np.array(p)\n",
    "\n",
    "    # computation_time = time.time() - start_time  # End timer\n",
    "# predict_yolo_masked(np.zeros((2,426, 640), dtype=bool))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST BLACKBOX FUCNTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_to_explain.shape)\n",
    "bg_ls = np.zeros((100,image_to_explain.shape[0],image_to_explain.shape[1],image_to_explain.shape[2]))\n",
    "# bg_ls = np.random.randint(0, 255, (50,426, 640, 3), dtype=np.uint8)\n",
    "\n",
    "print(bg_ls.shape)\n",
    "pred = predict_yolo_masked(bg_ls)\n",
    "print(pred.shape)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_explained_classes = 2\n",
    "# batch_size            = 32\n",
    "# del batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap_bpt\n",
    "\n",
    "print('shap_bpt version:',shap_bpt.__version__)\n",
    "def get_bpt_heatmaps(num_explained_classes=1,num_samples=100,verbose=False,batch_size=64):\n",
    "    explainer = shap_bpt.Explainer(predict_yolo_masked, image_to_explain, num_explained_classes=num_explained_classes, verbose=verbose)\n",
    "    shap_values_bpt = explainer.explain_instance(num_samples, method='BPT',batch_size=batch_size)\n",
    "    del explainer\n",
    "    return shap_values_bpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Axis-Aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aa_heatmaps(num_explained_classes=1,num_samples=100,verbose=False,batch_size=64,verbose_plot=False):\n",
    "    explainer = shap_bpt.Explainer(predict_yolo_masked, image_to_explain, num_explained_classes=num_explained_classes, verbose=verbose)\n",
    "    shap_values_aa = explainer.explain_instance(num_samples, method='AA',  batch_size=batch_size, verbose_plot=verbose_plot)\n",
    "    del explainer\n",
    "    return shap_values_aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap as shap\n",
    "\n",
    "def shap_predict(img):\n",
    "    # assert model_type=='real'\n",
    "    pred = predict_yolo_masked(img)\n",
    "    # print(img.shape, pred.shape)\n",
    "    return pred\n",
    "    # return f(torch.Tensor(img).permute(0,3,1,2).to(device))\n",
    "\n",
    "def get_pe_heatmaps(num_samples=1000,batch_size=32):\n",
    "    assert len(background_tensors)==1\n",
    "    shapMasker     = shap.maskers.Image(background_tensors[0].detach().cpu().numpy(), image_to_explain.shape) # .permute(1,2,0)\n",
    "    shapPartExpl   = shap.Explainer(shap_predict, shapMasker, \n",
    "                                    output_names=[class_names[i] for i in range(len(class_names))], \n",
    "                                    algorithm=\"partition\")\n",
    "    shap_values_pe = shapPartExpl(np.expand_dims(image_to_explain, axis=0),  # permute(1,2,0) np.expand_dims(image_to_explain_preproc.detach().cpu().numpy(), 0)\n",
    "                                  max_evals=num_samples, batch_size=batch_size, \n",
    "                                  outputs=shap.Explanation.argsort.flip[:4])\n",
    "    shap_values_pe = np.moveaxis(np.sum(shap_values_pe.values[0], axis=2), 2, 0)\n",
    "    del shapMasker,shapPartExpl\n",
    "    return shap_values_pe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientExplainer SHAP\n",
    " - https://shap-lrjball.readthedocs.io/en/latest/generated/shap.GradientExplainer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradexpl_heatmap(use_abs=True,num_explained_classes=2):\n",
    "    torch.cuda.empty_cache()\n",
    "    # if pretrained_model_type  == 'vit_LRP':\n",
    "    #     return np.ones((1,224,224))\n",
    "    \n",
    "    e = shap.GradientExplainer(model.predict(), background_tensors)\n",
    "    return \n",
    "    expl = e.shap_values(torch.unsqueeze(image_to_explain_tensor, dim=0),\n",
    "                         nsamples=20, ranked_outputs=num_explained_classes)\n",
    "    heatmaps = np.sum(expl[0], axis=1)[:,:,:,0]\n",
    "    for i, clsid in enumerate(sorted_classes[:num_explained_classes]):\n",
    "        if use_abs:\n",
    "            heatmaps[i] = np.abs(heatmaps[i])\n",
    "        heatmaps[i] = heatmaps[i] * (predicted_fS[clsid] - predicted_f0[clsid]) / np.sum(heatmaps[i])\n",
    "        torch.cuda.empty_cache()\n",
    "    del e,expl\n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LIME\n",
    " - https://github.com/marcotcr/lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_number(image, md):\n",
    "    segmentation_fn = SegmentationAlgorithm('quickshift', kernel_size=4, max_dist=md, ratio=0.2, random_seed=1234) \n",
    "    segments = segmentation_fn(image)\n",
    "    return len(np.unique(segments))\n",
    "\n",
    "def search_segment_number(image, target_seg_no, init_max_dist=100, max_iter=3):\n",
    "    lmd, rmd = 0, init_max_dist\n",
    "    lsn = get_segment_number(image, lmd)\n",
    "    rsn = get_segment_number(image, rmd)\n",
    "    niter = 0\n",
    "    while niter<max_iter and rsn!=target_seg_no:\n",
    "        niter += 1\n",
    "        mmd = (lmd + rmd) / 2.0\n",
    "        msn = get_segment_number(image, mmd)\n",
    "        if msn <= target_seg_no <= lsn:\n",
    "            rsn, rmd = msn, mmd\n",
    "        else:\n",
    "            lsn, lmd = msn, mmd\n",
    "    return rmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_lime_heatmaps(segments, expl):\n",
    "    global predicted_fS, predicted_f0\n",
    "    class_heatmaps = []\n",
    "    eps = 1e-8\n",
    "    # print(expl.top_labels)\n",
    "    for clsid in expl.top_labels:\n",
    "        heatmap = np.zeros_like(segments, dtype=np.float32)\n",
    "        for segm, importance in expl.local_exp[clsid]:\n",
    "            heatmap[ segments==segm ] += importance \n",
    "        \n",
    "        heatmap = heatmap * (predicted_fS[clsid] - predicted_f0[clsid]) / (np.sum(heatmap) + eps)\n",
    "        class_heatmaps.append(heatmap)\n",
    "    return np.array(class_heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime_predict(img):\n",
    "    # global model_type\n",
    "    # if model_type=='ideal':        \n",
    "        # return f_masked_ideal(torch.Tensor(img).permute(0,3,1,2).cpu().numpy() [:,0,:,:])\n",
    "    # else:\n",
    "    # return predict_yolo_masked(torch.Tensor(img).permute(0,3,1,2).to(device))\n",
    "    return predict_yolo_masked(img)\n",
    "    \n",
    "    # return f(torch.Tensor(img).permute(0,3,1,2).to(device))\n",
    "\n",
    "def get_lime_heatmaps(num_segments=100, batch_size=32,num_samples=1000,num_explained_classes=2, use_stratification=False,verbose=False):\n",
    "    if verbose:\n",
    "        start_time = datetime.now()\n",
    "    segmentation_fn = SegmentationAlgorithm('quickshift', kernel_size=4, \n",
    "                                            max_dist=search_segment_number(image_to_explain, num_segments), \n",
    "                                            # max_dist=30,\n",
    "                                            ratio=0.2, random_seed=1234) \n",
    "    segments = segmentation_fn(image_to_explain)\n",
    "    def segments_getter(img):\n",
    "        return segments\n",
    "    if verbose:\n",
    "        end_time = datetime.now()\n",
    "        print(f'{num_segments} {\"segments Took\":<20} : {\"{}\".format(end_time - start_time)} and computed {num_segments} segments')\n",
    "    num_segments = len(np.unique(segments))\n",
    "    heatmap_list = []\n",
    "    for bg_c in background_image_preproc_set:\n",
    "        torch.cuda.empty_cache()\n",
    "        lime_explainer = lime_image.LimeImageExplainer(random_state=1234)\n",
    "        lime_expl = lime_explainer.explain_instance(image_to_explain_preproc,#.permute(1,2,0).detach().numpy(), \n",
    "                                                    lime_predict,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    top_labels=num_explained_classes,\n",
    "                                                    # use_stratification=use_stratification,\n",
    "                                                    segmentation_fn=segments_getter,\n",
    "                                                    progress_bar = verbose,\n",
    "                                                    hide_color=bg_c.permute(1,2,0).detach().numpy(), \n",
    "                                                    num_samples=num_samples)\n",
    "        if isinstance(lime_expl, tuple):\n",
    "            lime_expl = lime_expl[2]\n",
    "        heatmap_list.append(format_lime_heatmaps(segments, lime_expl))\n",
    "        torch.cuda.empty_cache()\n",
    "        del lime_expl,lime_explainer\n",
    "    del segments\n",
    "    return np.mean(heatmap_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://arxiv.org/pdf/2305.20052.pdf\n",
    "# # https://github.com/chasewalker26/Integrated-Decision-Gradients/tree/main\n",
    "# import sys\n",
    "# paths_repo = 'E:/PHD/datacloud_data/repos' \n",
    "# sys.path.append(f'{paths_repo}/Integrated-Decision-Gradients/util/attribution_methods')\n",
    "\n",
    "# from saliencyMethods import IDG\n",
    "# def get_idg_heatmaps(use_abs=True):\n",
    "#     # global predicted_fS, predicted_f0\n",
    "#     steps = 50\n",
    "#     batch_si = 25 # default 25\n",
    "#     baseline = 0\n",
    "#     heatmaps = []\n",
    "#     torch.cuda.empty_cache()\n",
    "#     for clsid in sorted_classes[:num_explained_classes]:\n",
    "#         heatmap = idg = IDG(torch.unsqueeze(image_to_explain_tensor, dim=0), model, \n",
    "#                             steps, batch_si, baseline, device, predicted_cls)\n",
    "#         heatmap = idg.detach().cpu().numpy()\n",
    "#         heatmap = np.mean(heatmap, axis=0) # reduce to one attribution per pixel\n",
    "#         # normalize\n",
    "#         if use_abs:\n",
    "#             heatmap = np.abs(heatmap)\n",
    "#         # heatmap -= np.min(heatmap)\n",
    "#         heatmap = heatmap * (predicted_fS[clsid] - predicted_f0[clsid]) / np.sum(heatmap)\n",
    "#         heatmaps.append(heatmap)\n",
    "#         del heatmap\n",
    "#     torch.cuda.empty_cache()\n",
    "#     del steps,baseline,batch_si\n",
    "#     return np.array(heatmaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://github.com/jacobgil/pytorch-grad-cam\n",
    "# # https://captum.ai/api/gradient_shap.html\n",
    "# from captum.attr import GradientShap\n",
    "# def get_gradshap_captum_heatmaps(n_samples=50):\n",
    "#     if params.pretrained_model_type == 'vit_LRP':\n",
    "#         gradient_shap = rand_img_dist = clsid = None\n",
    "#         return np.ones((1,224,224))\n",
    "#     torch.cuda.empty_cache()\n",
    "#     rand_img_dist = torch.cat([image_to_explain_tensor.unsqueeze(0) * 0, image_to_explain_tensor.unsqueeze(0) * 1])\n",
    "#     gradient_shap = GradientShap(model)\n",
    "    \n",
    "#     heatmaps = []\n",
    "#     for clsid in sorted_classes[:num_explained_classes]:\n",
    "#         clsid = torch.tensor(clsid)\n",
    "        \n",
    "#         heatmap = gradient_shap.attribute(image_to_explain_tensor.unsqueeze(0),\n",
    "#                                           n_samples=n_samples,\n",
    "#                                           stdevs=0.0001,\n",
    "#                                           baselines=rand_img_dist,\n",
    "#                                           target=clsid)\n",
    "#         heatmap = np.sum(heatmap.squeeze().cpu().detach().numpy(), axis=0)\n",
    "#         heatmap = np.abs(heatmap)\n",
    "#         heatmap = heatmap * (predicted_fS[clsid] - predicted_f0[clsid]) / np.sum(heatmap)\n",
    "#         heatmaps.append(heatmap)\n",
    "#         del heatmap\n",
    "#     torch.cuda.empty_cache()\n",
    "#     del gradient_shap,rand_img_dist,clsid\n",
    "#     return np.array(heatmaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMBINE XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     name,                 color,                  functor\n",
    "verbose = False\n",
    "\n",
    "methods = [\n",
    "    ('BPT-100',         'xkcd:light pink',     partial(get_bpt_heatmaps, num_samples=100,batch_size=64,verbose=verbose)),\n",
    "    ('BPT-500',         'xkcd:bright pink',     partial(get_bpt_heatmaps, num_samples=500,batch_size=64,verbose=verbose)),\n",
    "    ('BPT-1000',         'xkcd:deep pink',     partial(get_bpt_heatmaps, num_samples=1000,batch_size=64,verbose=verbose)),\n",
    "    ]\n",
    "# methods_pe = [ # if single background\n",
    "#     ('Partition-1000',   'xkcd:bluish',     partial(get_pe_heatmaps, num_samples=1000)),\n",
    "#     ('Partition-2000',   'xkcd:cerulean',   partial(get_pe_heatmaps, num_samples=2000)),\n",
    "#     ('Partition-5000',   'xkcd:soft blue', partial(get_pe_heatmaps, num_samples=5000))\n",
    "#     ]\n",
    "methods_aa = [ # if multiple backgrounds\n",
    "    ('AA-100', 'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=100,batch_size=64, verbose=verbose)),\n",
    "    ('AA-500', 'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=500,batch_size=64, verbose=verbose)),\n",
    "    ('AA-1000', 'xkcd:bright blue',    partial(get_aa_heatmaps, num_samples=1000,batch_size=64, verbose=verbose)),\n",
    "]\n",
    "# methods_aa_huge = [\n",
    "#     ('AA-5000', 'xkcd:bright blue',      partial(get_aa_heatmaps, num_samples=5000, verbose=verbose)),\n",
    "#     # ('AA-10000', 'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=10000,batch_size=64, verbose=verbose)),\n",
    "# ]\n",
    "# methods_lime = [\n",
    "#     ('LIME-50',        'xkcd:bright lime',     partial(get_lime_heatmaps, num_segments=50, num_samples=50*5,verbose=verbose)),\n",
    "#     ('LIME-100',        'xkcd:kermit green',   partial(get_lime_heatmaps, num_segments=100, num_samples=100*5,verbose=verbose)),\n",
    "#     ('LIME-200',        'xkcd:dark lime green',partial(get_lime_heatmaps, num_segments=200, num_samples=200*5,verbose=verbose)),\n",
    "#     ]\n",
    "\n",
    "\n",
    "methods_lime = [\n",
    "    # ('LIME-50',        'xkcd:bright lime',     partial(get_lime_heatmaps, num_segments=50, num_samples=50*5,verbose=verbose)),\n",
    "    # ('LIME-100',        'xkcd:bright lime',     partial(get_lime_heatmaps, num_segments=100, num_samples=100*5,verbose=verbose)),\n",
    "    # ('LIME-200',        'xkcd:dark lime green',partial(get_lime_heatmaps, num_segments=200, num_samples=200*5,verbose=verbose)),\n",
    "###########################################################\n",
    "## num_segments = num_samples / 10\n",
    "    # partial(get_aa_heatmaps, num_samples=100, verbose=verbose))\n",
    "    ('LIME-100',        'xkcd:bright lime',     partial(get_lime_heatmaps, num_segments=100/10, num_samples=100,verbose=verbose)),\n",
    "    ('LIME-500',        'xkcd:kermit green',   partial(get_lime_heatmaps, num_segments=500/10, num_samples=500,verbose=verbose)),\n",
    "    ('LIME-1000',        'xkcd:dark lime green',partial(get_lime_heatmaps, num_segments=1000/10, num_samples=1000,verbose=verbose))\n",
    "    ]\n",
    "\n",
    "# methods_cam = [\n",
    "#     # ('aIDG',         'xkcd:indigo',          partial(get_idg_heatmaps, use_abs=True)),\n",
    "#     ('aGradExpl',    'red',                  partial(get_gradexpl_heatmap, use_abs=True))\n",
    "#     ]\n",
    "\n",
    "# methods_ShapGradE = [\n",
    "#     ('ShapGradE',     'xkcd:camel',            partial(get_gradshap_captum_heatmaps, n_samples=20)),    \n",
    "# ]\n",
    "\n",
    "# # methods_limeSAM = [\n",
    "# #     ('LIMESAM',        'xkcd:bright lime',     partial(get_limeSAM_heatmaps, num_samples=500, verbose=verbose)),\n",
    "# #     ]\n",
    "\n",
    "\n",
    "\n",
    "# methods_LRP_ViT = [\n",
    "#         ('LRP',        'xkcd:bright lime',     get_heatmaps_LRP_ViT),\n",
    "    \n",
    "#     ]\n",
    "# methods_LRP = [\n",
    "#     ('LRP',        'xkcd:bright lime',     get_LRP_captum_heatmaps),\n",
    "    \n",
    "#     ]\n",
    "\n",
    "# method_gradcam_vit_heatmaps = [\n",
    "#     ('GradCAM',     'xkcd:camel',            get_gradcam_vit_heatmaps),\n",
    "#     ]\n",
    "\n",
    "# if pretrained_model_type  == 'swin_trans_vit' or pretrained_model_type == 'vit_LRP':\n",
    "#     methods_gradcam = [\n",
    "#     ('GradCAM',     'xkcd:camel',            get_gradcam_vit_heatmaps),\n",
    "#     ]\n",
    "# else:\n",
    "#     methods_gradcam = [\n",
    "#     ('GradCAM',     'xkcd:camel',            get_gradcam_heatmaps),\n",
    "#     ]\n",
    "    \n",
    "\n",
    "# methods += methods_pe if len(background_tensors) == 1 else methods_aa\n",
    "methods +=methods_aa\n",
    "# methods += methods_aa_huge\n",
    "methods += methods_lime\n",
    "\n",
    "\n",
    "# if pretrained_model_type  == 'swin_trans_vit' or pretrained_model_type == 'vit_LRP':\n",
    "#     methods += methods_LRP_ViT\n",
    "# else:\n",
    "#     methods += methods_LRP\n",
    "    \n",
    "# if pretrained_model_type  == 'swin_trans_vit' or pretrained_model_type == 'vit_LRP':\n",
    "#     methods += method_gradcam_vit_heatmaps\n",
    "# else:\n",
    "#     methods += methods_gradcam\n",
    "\n",
    "# methods += methods_cam\n",
    "\n",
    "# methods += methods_ShapGradE\n",
    "for n,_,_ in methods:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNC:   XAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_explained_classes  =  1         # No of Top Predicted Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #     name,                 color,                  functor\n",
    "# verbose = False\n",
    "# # if pretrained_model_type  == 'swin_trans_vit':\n",
    "# #     verbose = True\n",
    "\n",
    "# methods = [\n",
    "#     ('BPT-100',         'xkcd:light pink',     partial(get_bpt_heatmaps, num_samples=100,verbose=verbose)),\n",
    "#     ('BPT-500',         'xkcd:bright pink',     partial(get_bpt_heatmaps, num_samples=500,verbose=verbose)),\n",
    "#     ('BPT-1000',         'xkcd:deep pink',     partial(get_bpt_heatmaps, num_samples=1000,verbose=verbose)),\n",
    "#     ]\n",
    "# methods_pe = [ # if single background\n",
    "#     ('Partition-100',   'xkcd:bluish',     partial(get_pe_heatmaps, num_samples=100)),\n",
    "#     ('Partition-500',   'xkcd:cerulean',   partial(get_pe_heatmaps, num_samples=500)),\n",
    "#     ('Partition-1000',   'xkcd:soft blue', partial(get_pe_heatmaps, num_samples=1000))\n",
    "#     ]\n",
    "# methods_aa = [ # if multiple backgrounds\n",
    "#     ('AA-100', 'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=100, verbose=verbose)),\n",
    "#     ('AA-500', 'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=500, verbose=verbose)),\n",
    "#     ('AA-1000', 'xkcd:bright blue',    partial(get_aa_heatmaps, num_samples=1000, verbose=verbose)),\n",
    "# ]\n",
    "# methods_aa_huge = [\n",
    "#     ('AA-5000', 'xkcd:bright blue',      partial(get_aa_heatmaps, num_samples=5000, verbose=verbose)),\n",
    "#     ('AA-10000', 'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=10000, verbose=verbose)),\n",
    "# ]\n",
    "# methods_lime = [\n",
    "#     ('LIME-100',        'xkcd:bright lime',     partial(get_lime_heatmaps, num_segments=100/5, num_samples=100,verbose=verbose)),\n",
    "#     ('LIME-500',        'xkcd:kermit green',   partial(get_lime_heatmaps, num_segments=500/5, num_samples=500,verbose=verbose)),\n",
    "#     ('LIME-1000',        'xkcd:dark lime green',partial(get_lime_heatmaps, num_segments=1000/5, num_samples=1000,verbose=verbose))\n",
    "#     ]\n",
    "\n",
    "# methods_cam = [\n",
    "#     ('aIDG',         'xkcd:indigo',          partial(get_idg_heatmaps, use_abs=True)),\n",
    "#     ('aGradExpl',    'red',                  partial(get_gradexpl_heatmap, use_abs=True))\n",
    "#     ]\n",
    "\n",
    "# methods_ShapGradE = [\n",
    "#     ('ShapGradE',     'xkcd:camel',            partial(get_gradshap_captum_heatmaps, n_samples=20)),    \n",
    "# ]\n",
    "\n",
    "# # methods_limeSAM = [\n",
    "# #     ('LIMESAM',        'xkcd:bright lime',     partial(get_limeSAM_heatmaps, num_samples=500, verbose=verbose)),\n",
    "# #     ]\n",
    "\n",
    "\n",
    "\n",
    "# # methods_LRP_ViT = [\n",
    "# #         ('LRP',        'xkcd:bright lime',     get_heatmaps_LRP_ViT),\n",
    "    \n",
    "# #     ]\n",
    "# # methods_LRP = [\n",
    "# #     ('LRP',        'xkcd:bright lime',     get_LRP_captum_heatmaps),\n",
    "    \n",
    "# #     ]\n",
    "\n",
    "# # method_gradcam_vit_heatmaps = [\n",
    "# #     ('GradCAM',     'xkcd:camel',            get_gradcam_heatmaps_for_swin_vit), #get_gradcam_vit_heatmaps),\n",
    "# #     ]\n",
    "\n",
    "# # if params.pretrained_model_type == 'vit_LRP':\n",
    "# #     methods_gradcam = [\n",
    "# #     ('GradCAM',     'xkcd:camel',            get_gradcam_vit_heatmaps),\n",
    "# #     ]\n",
    "# # else:\n",
    "# #     methods_gradcam = [\n",
    "# #     ('GradCAM',     'xkcd:camel',            get_gradcam_heatmaps),\n",
    "# #     ]\n",
    "    \n",
    "\n",
    "# methods += methods_pe if len(background_tensors) == 1 and params.model_type!='ideal' else methods_aa\n",
    "# # if params.model_type == 'ideal':\n",
    "# #     methods += methods_aa_huge\n",
    "\n",
    "# methods += methods_lime\n",
    "# # methods += methods_limeSAM\n",
    "# ######## CAM   #############    \n",
    "# # if pretrained_model_type  != 'swin_trans_vit' :\n",
    "\n",
    "# # if params.pretrained_model_type  == 'swin_trans_vit' or params.pretrained_model_type == 'vit_LRP':\n",
    "# #     methods += methods_LRP_ViT\n",
    "# # else:\n",
    "# #     methods += methods_LRP\n",
    "\n",
    "# # if params.pretrained_model_type  == 'swin_trans_vit' or params.pretrained_model_type == 'vit_LRP':\n",
    "# #     methods += method_gradcam_vit_heatmaps\n",
    "# # else:\n",
    "# #     methods += methods_gradcam\n",
    "\n",
    "# if params.model_type != 'ideal':\n",
    "#     methods += methods_cam\n",
    "\n",
    "# methods += methods_ShapGradE\n",
    "# for n,_,functt in methods:\n",
    "#     print(n, functt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # import random\n",
    "\n",
    "# rng = np.random.default_rng(12345)\n",
    "# rng.normal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated saliency_to_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def saliency_to_auc(heatmap, batch_size=4, method='del', num_samples=101, add_noise=True):\n",
    "#     xs, ys, ms, masks,qs = [], [], [], [],[]\n",
    "\n",
    "    \n",
    "#     if add_noise:\n",
    "#         rng = np.random.default_rng(12345)\n",
    "#         heatmap = heatmap + rng.normal(0.0, 0.000000001, size=heatmap.shape)\n",
    "\n",
    "#     #heatmap = gaussian(heatmap, 2.0)\n",
    "#     for i in np.linspace(start=1.0, stop=0.0, num=num_samples):\n",
    "#         if method=='del':\n",
    "#             epsilon = (1 if i==0.0 else 0)\n",
    "#             q = (np.quantile(heatmap, q=i) - epsilon)\n",
    "#             m = heatmap <= q\n",
    "#             nx = (1.0 - np.sum(m) / m.size)\n",
    "#         elif method=='ins':\n",
    "#             epsilon = (1 if i==1.0 else 0)\n",
    "#             q = (np.quantile(heatmap, q=i) + epsilon)\n",
    "#             m = heatmap >= q\n",
    "#             nx = (np.sum(m) / m.size)\n",
    "#         else:\n",
    "#             raise Exception()\n",
    "            \n",
    "#         if len(xs)==0 or nx != xs[-1]:\n",
    "#             xs.append(nx)\n",
    "#             masks.append(m)\n",
    "#             ms.append(np.sum(heatmap[m]))\n",
    "#             qs.append(q)\n",
    "#             if len(masks) >= batch_size:\n",
    "#                 y = predict_yolo_masked(np.array(masks))[:, predicted_cls]\n",
    "#                 ys.extend(y)\n",
    "#                 masks = []\n",
    "\n",
    "#     if len(masks) > 0:\n",
    "#         y = predict_yolo_masked(np.array(masks))[:, predicted_cls]\n",
    "#         ys.extend(y)\n",
    "    \n",
    "#     xs, ys = np.array(xs), np.array(ys)\n",
    "#     auc_reg, auc_eff, auc_mse = 0.0, 0.0, 0.0\n",
    "#     assert(len(xs) == len(ys))\n",
    "#     # compute the area under the curve - use the rectangle method\n",
    "#     for i in range(1, len(xs)):\n",
    "#         delta_x = abs(xs[i] - xs[i-1])\n",
    "#         if delta_x > 0:\n",
    "#             auc_reg += abs(delta_x * 0.5*(ys[i-1] + ys[i])) # base * height\n",
    "#             auc_eff += abs(delta_x * 0.5*(ys[i-1] + ys[i] - ms[i-1] - ms[i])) # base * height\n",
    "#             auc_mse += abs(delta_x * 0.5*(ys[i-1] + ys[i] - ms[i-1] - ms[i])**2) # base * height^2\n",
    "\n",
    "#     # return xs, ys, ms, auc_reg, auc_eff, auc_mse\n",
    "#     return {'xs':xs, 'ys':ys, 'ms':ms, 'qs':qs, 'auc_reg':auc_reg, 'auc_eff':auc_eff, 'auc_mse':auc_mse,'method':method}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def saliency_to_auc(heatmap, f_S, f_0, predicted_cls, batch_size=4, method='del', num_samples=101, \n",
    "#                     rule='trapezoid'):\n",
    "\n",
    "#     # print(f'Computing AUC with method={method}, batch_size={batch_size}, num_samples={num_samples}, rule={rule}')\n",
    "#     # print('from saliency_to_auc',heatmap.shape, heatmap.dtype, heatmap.min(), heatmap.max())\n",
    "#     assert isinstance(heatmap, np.ndarray)\n",
    "#     assert len(heatmap.shape)==2 and np.issubdtype(heatmap.dtype, np.floating)\n",
    "\n",
    "#     nu_max = max(f_S, f_0)\n",
    "#     nu_min = min(f_S, f_0)\n",
    "\n",
    "#     xs, ys, ms, masks, qs = [], [], [], [], []\n",
    "#     for i, value in enumerate(np.linspace(start=1.0, stop=0.0, num=num_samples)):\n",
    "#         if method=='del':\n",
    "#             epsilon = (1 if value==0.0 else 0)\n",
    "#             q = (np.quantile(heatmap, q=value) - epsilon)\n",
    "#             m = heatmap <= q\n",
    "#             nx = (1.0 - np.sum(m) / m.size)\n",
    "#         elif method=='ins':\n",
    "#             epsilon = (1 if value==1.0 else 0)\n",
    "#             q = (np.quantile(heatmap, q=value) + epsilon)\n",
    "#             m = heatmap >= q\n",
    "#             nx = (np.sum(m) / m.size)\n",
    "#         else:\n",
    "#             raise Exception()\n",
    "            \n",
    "#         # add a new datapoint on the curve\n",
    "#         if len(xs)==0 or nx != xs[-1]: \n",
    "#             assert m.dtype==bool and len(m.shape)==2\n",
    "#             xs.append(nx)\n",
    "#             masks.append(m)\n",
    "#             ms.append(np.sum(heatmap[m]))\n",
    "#             qs.append(q)\n",
    "\n",
    "#         # evaluate the characteristic function\n",
    "#         if len(masks) >= batch_size or (len(masks)>0 and i==(num_samples-1)):\n",
    "#             y = predict_yolo_masked(np.array(masks))[:, predicted_cls]\n",
    "#             ys.extend(y)\n",
    "#             masks = []\n",
    "\n",
    "#     assert len(masks)==0    \n",
    "#     xs, ys = np.array(xs), np.array(ys)\n",
    "#     assert(len(xs) == len(ys))\n",
    "\n",
    "#     # compute considering under/over shoots\n",
    "#     overshoot_max = np.maximum(0, ys - nu_max) # overshoot for values exceeding the maximum\n",
    "#     overshoot_min = np.maximum(0, nu_min - ys) # overshoot for values below the minimum\n",
    "#     # adjust ys with the overshoot. Clip it inside the admitted range\n",
    "#     y_adjusted = np.clip(ys - 2*overshoot_max + 2*overshoot_min, nu_min, nu_max)\n",
    "\n",
    "#     # rescaling\n",
    "#     ys_rescaled = (ys - nu_min) / (nu_max - nu_min)\n",
    "#     y_adjusted_rescaled = (y_adjusted - nu_min) / (nu_max - nu_min)\n",
    "\n",
    "#     auc, auc_r, auc_mae, auc_mse, auc_adj, auc_adjr = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "#     curve_range = range(1, len(xs)) if rule=='trapezoid' else range(len(xs))\n",
    "\n",
    "#     # compute the area under the curve with the midpoint Riemann sum (i.e. the trapezoidal rule)\n",
    "#     for i in curve_range:\n",
    "#         if rule=='trapezoid':\n",
    "#             delta_x = abs(xs[i] - xs[i-1])\n",
    "#             assert delta_x > 0\n",
    "#             y_mid   =         0.5*(ys[i-1] + ys[i])\n",
    "#             y_r_mid =         0.5*(ys_rescaled[i-1] + ys_rescaled[i])\n",
    "#             err_mid = y_mid - 0.5*(ms[i-1] - ms[i])\n",
    "#             y_adj_mid =       0.5*(y_adjusted[i-1] + y_adjusted[i])\n",
    "#             y_adjr_mid =      0.5*(y_adjusted_rescaled[i-1] + y_adjusted_rescaled[i])\n",
    "#         else: # rectangles\n",
    "#             delta_x = 1.0/num_samples if i==len(xs)-1 else abs(xs[i+1] - xs[i])\n",
    "#             assert delta_x > 0\n",
    "#             y_mid   =         ys[i]\n",
    "#             y_r_mid =         ys_rescaled[i]\n",
    "#             err_mid = y_mid - ms[i]\n",
    "#             y_adj_mid =       y_adjusted[i]\n",
    "#             y_adjr_mid =      y_adjusted_rescaled[i]\n",
    "\n",
    "\n",
    "#         auc += abs(delta_x * y_mid) # base * height\n",
    "#         auc_r += abs(delta_x * y_r_mid) # base * height\n",
    "#         # auc_eff += abs(delta_x * err_mid) # base * height\n",
    "#         auc_mae += abs(delta_x * err_mid) # base * height\n",
    "#         auc_mse += abs(delta_x * (err_mid**2)) # base * height^2\n",
    "#         auc_adj += abs(delta_x * y_adj_mid)\n",
    "#         auc_adjr += abs(delta_x * y_adjr_mid)\n",
    "\n",
    "#     return {'xs':xs, 'ys':ys, 'ms':ms, 'qs':qs, 'ysr':ys_rescaled,\n",
    "#             'y_adj':y_adjusted, 'y_adjr':y_adjusted_rescaled, \n",
    "#             'method':method, #'class_id':class_id,\n",
    "#             'auc':auc, 'auc_r':auc_r, #'auc_eff':auc_eff, \n",
    "#             'auc_mae':auc_mae, 'auc_mse':auc_mse, 'auc_rmse':np.sqrt(auc_mse), \n",
    "#             'auc_adj':auc_adj, 'auc_adjr':auc_adjr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_to_auc(nu, heatmap, f_S, f_0, predicted_cls, batch_size=4, method='del', num_samples=101, rule='trapezoid'):\n",
    "                    # predict_yolo_masked,heatmaps[n][0],f_S,f_0,predicted_cls, method='del', batch_size=params.batch_size\n",
    "    assert isinstance(heatmap, np.ndarray)\n",
    "    assert len(heatmap.shape)==2 and np.issubdtype(heatmap.dtype, np.floating)\n",
    "\n",
    "    # nu_max = max(f_S, f_0)\n",
    "    # nu_min = min(f_S, f_0)\n",
    "\n",
    "    xs, ys, ms, masks, qs = [], [], [], [], []\n",
    "    for i, value in enumerate(np.linspace(start=1.0, stop=0.0, num=num_samples)):\n",
    "        if method=='del':\n",
    "            epsilon = (1 if value==0.0 else 0)\n",
    "            q = (np.quantile(heatmap, q=value) - epsilon)\n",
    "            m = heatmap <= q\n",
    "            nx = (1.0 - np.sum(m) / m.size)\n",
    "        elif method=='ins':\n",
    "            epsilon = (1 if value==1.0 else 0)\n",
    "            q = (np.quantile(heatmap, q=value) + epsilon)\n",
    "            m = heatmap >= q\n",
    "            nx = (np.sum(m) / m.size)\n",
    "        else:\n",
    "            raise Exception()\n",
    "            \n",
    "        # add a new datapoint on the curve\n",
    "        if len(xs)==0 or nx != xs[-1]: \n",
    "            assert m.dtype==bool and len(m.shape)==2\n",
    "            xs.append(nx)\n",
    "            masks.append(m)\n",
    "            ms.append(np.sum(heatmap[m]))\n",
    "            qs.append(q)\n",
    "\n",
    "        # evaluate the characteristic function\n",
    "        if len(masks) >= batch_size or (len(masks)>0 and i==(num_samples-1)):\n",
    "            y = nu(np.array(masks))[:, predicted_cls]\n",
    "            ys.extend(y)\n",
    "            masks = []\n",
    "\n",
    "    assert len(masks)==0    \n",
    "    xs, ys = np.array(xs), np.array(ys)\n",
    "    assert(len(xs) == len(ys))\n",
    "\n",
    "    # compute considering under/over shoots\n",
    "    if f_S > f_0:\n",
    "        overshoot_max = np.maximum(0, ys - f_S) # overshoot for values exceeding the maximum f(S)\n",
    "        overshoot_min = np.maximum(0, f_0 - ys) # overshoot for values below the minimum f(0)\n",
    "    else: # f(S) < f(0)\n",
    "        overshoot_max = np.maximum(0, ys - f_0) # overshoot for values exceeding the maximum f(0)\n",
    "        overshoot_min = np.maximum(0, f_S - ys) # overshoot for values below the minimum f(S)\n",
    "\n",
    "    # clip ys, no oveshoots\n",
    "    y_clipped = np.clip(ys, min(f_S, f_0), max(f_S, f_0))\n",
    "    # adjust ys with the overshoot. Clip it inside the admitted range\n",
    "    y_adjusted = np.clip(ys - 2*overshoot_max + 2*overshoot_min, min(f_S, f_0), max(f_S, f_0))\n",
    "\n",
    "    # rebase to f(0)\n",
    "    if f_S > f_0:\n",
    "        flipped = False\n",
    "        ys = ys - f_0 \n",
    "        y_clipped = y_clipped - f_0 \n",
    "        y_adjusted = y_adjusted - f_0\n",
    "    else: # f(S) < f(0)\n",
    "        flipped = True\n",
    "        ys = f_0 - ys \n",
    "        y_clipped = f_0 - y_clipped \n",
    "        y_adjusted = f_0 - y_adjusted\n",
    "\n",
    "    # rescaling\n",
    "    ys_rescaled = ys / abs(f_S - f_0)\n",
    "    y_clipped_rescaled = y_clipped / abs(f_S - f_0)\n",
    "    y_adjusted_rescaled = y_adjusted / abs(f_S - f_0)\n",
    "\n",
    "    auc, auc_r, auc_mae, auc_mse, auc_adj, auc_adjr, auc_clip, auc_clipr = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    curve_range = range(1, len(xs)) if rule=='trapezoid' else range(len(xs))\n",
    "\n",
    "    # compute the area under the curve with the midpoint Riemann sum (i.e. the trapezoidal rule)\n",
    "    for i in curve_range:\n",
    "        if rule=='trapezoid':\n",
    "            delta_x = abs(xs[i] - xs[i-1])\n",
    "            assert delta_x > 0\n",
    "            y_mid   =         0.5*(ys[i-1] + ys[i])\n",
    "            y_r_mid =         0.5*(ys_rescaled[i-1] + ys_rescaled[i])\n",
    "            err_mid = y_mid - 0.5*(ms[i-1] - ms[i])\n",
    "            y_clip_mid =       0.5*(y_clipped[i-1] + y_clipped[i])\n",
    "            y_clipr_mid =      0.5*(y_clipped_rescaled[i-1] + y_clipped_rescaled[i])\n",
    "            y_adj_mid =       0.5*(y_adjusted[i-1] + y_adjusted[i])\n",
    "            y_adjr_mid =      0.5*(y_adjusted_rescaled[i-1] + y_adjusted_rescaled[i])\n",
    "        else: # rectangles\n",
    "            delta_x = 1.0/num_samples if i==len(xs)-1 else abs(xs[i+1] - xs[i])\n",
    "            assert delta_x > 0\n",
    "            y_mid   =         ys[i]\n",
    "            y_r_mid =         ys_rescaled[i]\n",
    "            err_mid = y_mid - ms[i]\n",
    "            y_clip_mid =       y_clipped[i]\n",
    "            y_clipr_mid =      y_clipped_rescaled[i]\n",
    "            y_adj_mid =       y_adjusted[i]\n",
    "            y_adjr_mid =      y_adjusted_rescaled[i]\n",
    "\n",
    "\n",
    "        auc += abs(delta_x * y_mid) # base * height\n",
    "        auc_r += abs(delta_x * y_r_mid) # base * height\n",
    "        # auc_eff += abs(delta_x * err_mid) # base * height\n",
    "        auc_mae += abs(delta_x * err_mid) # base * height\n",
    "        auc_mse += abs(delta_x * (err_mid**2)) # base * height^2\n",
    "        auc_clip += abs(delta_x * y_clip_mid)\n",
    "        auc_clipr += abs(delta_x * y_clipr_mid)\n",
    "        auc_adj += abs(delta_x * y_adj_mid)\n",
    "        auc_adjr += abs(delta_x * y_adjr_mid)\n",
    "\n",
    "    return {'xs':xs, 'ms':ms, 'qs':qs, \n",
    "            'f_0':f_0, 'f_S':f_S, 'flipped':flipped, \n",
    "            'ys':ys, 'ysr':ys_rescaled,\n",
    "            'y_clip':y_clipped, 'y_clipr':y_clipped_rescaled, \n",
    "            'y_adj':y_adjusted, 'y_adjr':y_adjusted_rescaled, \n",
    "            'method':method, 'predicted_cls':predicted_cls,\n",
    "            'auc':auc, 'auc_r':auc_r,\n",
    "            'auc_mae':auc_mae, 'auc_mse':auc_mse, 'auc_rmse':np.sqrt(auc_mse), \n",
    "            'auc_clip':auc_clip, 'auc_clipr':auc_clipr,\n",
    "            'auc_adj':auc_adj, 'auc_adjr':auc_adjr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_groundtruth_explanation(gtruth, heatmap, threshold):\n",
    "    if gtruth.ndim == 3:\n",
    "        gt = gtruth[:,:,0]>0\n",
    "    else:\n",
    "        gt = gtruth[:,:]>0\n",
    "    ht = (heatmap >= threshold).astype(np.uint8)\n",
    "    img = np.zeros(shape=list(heatmap.shape)+[3], dtype=np.uint8)\n",
    "    img[:,:,0] = 255*(1-gt)\n",
    "    img[:,:,1] = 255*(1-ht)\n",
    "    img[:,:,2] = 255*(1-ht)\n",
    "    return img\n",
    "# def calc_IoU_curve(y_true, y_pred):\n",
    "    \n",
    "#     assert len(y_true.shape)==1 and len(y_pred.shape)==1 # assumes y_true and y_pred to be flattened arrays\n",
    "#     yd = np.array(sorted(zip(y_pred, y_true), reverse=True))\n",
    "#     X2   = np.zeros(len(y_pred))\n",
    "#     IoU2 = np.zeros(len(y_pred))\n",
    "#     Th   = np.zeros(len(y_pred))\n",
    "    \n",
    "#     nT = np.sum(y_true)\n",
    "#     nInt = 0\n",
    "#     for i in range(len(y_pred)):\n",
    "#         if yd[i,1]: \n",
    "#             nInt += 1\n",
    "        \n",
    "#         IoU2[i] = nInt / (i + nT - nInt)\n",
    "#         X2[i] = i\n",
    "#         Th[i] = yd[i,0]\n",
    "        \n",
    "#     X2 = X2 / len(y_pred)\n",
    "#     auc_IoU = 0\n",
    "#     for i in range(1, len(y_pred)):\n",
    "#         auc_IoU += (X2[i] - X2[i-1]) * (IoU2[i] + IoU2[i-1]) / 2.0\n",
    "    \n",
    "#     best_pt = np.argmax(IoU2)\n",
    "    \n",
    "#     if np.sum(y_pred) == 0:\n",
    "#         return X2, np.zeros_like(X2), Th[best_pt], X2[best_pt], 0\n",
    "#     else:\n",
    "#         return X2, IoU2, Th[best_pt], X2[best_pt], auc_IoU\n",
    "#         # return {'X':X2, 'Y':IoU2, 'max_IoU':Th[best_pt], 'x_best':X2[best_pt], 'auc_IoU':auc_IoU}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATED calc_IoU_curve_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_IoU_curve_imp(y_true, y_pred, add_noise=True):\n",
    "    assert isinstance(y_true, np.ndarray)\n",
    "    assert isinstance(y_pred, np.ndarray)\n",
    "    assert len(y_true.shape)==1 and len(y_pred.shape)==1 # assumes y_true and y_pred to be flattened arrays\n",
    "    assert len(y_true)==len(y_pred)\n",
    "    assert y_true.dtype==np.dtype('bool') and np.issubdtype(y_pred.dtype, np.floating)\n",
    "    if add_noise:\n",
    "        rng = np.random.default_rng(12345)\n",
    "        y_pred = y_pred + rng.normal(0.0, 0.000000001, size=y_pred.shape)\n",
    "    \n",
    "    yd   = np.array(sorted(zip(y_pred, y_true), reverse=True))\n",
    "    X2   = np.zeros(len(y_pred))\n",
    "    IoU2 = np.zeros(len(y_pred))\n",
    "    Th   = np.zeros(len(y_pred))\n",
    "    \n",
    "    nT = np.sum(y_true)\n",
    "    nInt = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if yd[i,1]: \n",
    "            nInt += 1\n",
    "        \n",
    "        IoU2[i] = nInt / (i + nT - nInt)\n",
    "        X2[i] = i\n",
    "        Th[i] = yd[i,0]\n",
    "        \n",
    "    X2 = X2 / len(y_pred)\n",
    "    auc_IoU = 0\n",
    "    for i in range(1, len(y_pred)):\n",
    "        auc_IoU += (X2[i] - X2[i-1]) * (IoU2[i] + IoU2[i-1]) / 2.0\n",
    "    \n",
    "    best_pt = np.argmax(IoU2)\n",
    "    # return {'X':X2, 'Y':IoU2, 'max_IoU':Th[best_pt], 'x_best':X2[best_pt], 'auc_IoU':auc_IoU}\n",
    "    return {'X':X2, 'Y':IoU2, 'max_IoU_heatmap_threshold':Th[best_pt], \n",
    "            'max_IoU_score':IoU2[best_pt], 'x_best':X2[best_pt], 'auc_IoU':auc_IoU}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_IoU_curve(y_true, y_pred, add_noise=True):\n",
    "    \n",
    "    assert len(y_true.shape)==1 and len(y_pred.shape)==1 # assumes y_true and y_pred to be flattened arrays\n",
    "    if add_noise:\n",
    "        rng = np.random.default_rng(12345)\n",
    "        # factor = np.mean(y_pred)/1000\n",
    "        y_pred = y_pred + rng.normal(0.0, 0.000000001, size=y_pred.shape) # 0.0000001\n",
    "    \n",
    "    yd = np.array(sorted(zip(y_pred, y_true), reverse=True))\n",
    "    X2   = np.zeros(len(y_pred))\n",
    "    IoU2 = np.zeros(len(y_pred))\n",
    "    Th   = np.zeros(len(y_pred))\n",
    "    \n",
    "    nT = np.sum(y_true)\n",
    "    nInt = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if yd[i,1]: \n",
    "            nInt += 1\n",
    "        \n",
    "        IoU2[i] = nInt / (i + nT - nInt)\n",
    "        X2[i] = i\n",
    "        Th[i] = yd[i,0]\n",
    "        \n",
    "    X2 = X2 / len(y_pred)\n",
    "    auc_IoU = 0\n",
    "    for i in range(1, len(y_pred)):\n",
    "        auc_IoU += (X2[i] - X2[i-1]) * (IoU2[i] + IoU2[i-1]) / 2.0\n",
    "    \n",
    "    best_pt = np.argmax(IoU2)\n",
    "    \n",
    "    if np.sum(y_pred) == 0:\n",
    "        return X2, np.zeros_like(X2), Th[best_pt], X2[best_pt], 0\n",
    "    else:\n",
    "        return X2, IoU2, Th[best_pt], X2[best_pt], auc_IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_IoU(shapley_values, threshold, ground_truth,verbose=False):\n",
    "    pred = shapley_values.flatten() >= threshold\n",
    "    real = ground_truth.flatten()\n",
    "    # real = real.astype(np.float32)\n",
    "    \n",
    "    image = np.full((len(pred), 3), 1.0, dtype=np.float32)\n",
    "    if verbose:\n",
    "        print(np.sum(pred), np.sum(real))\n",
    "    image[ pred & real, : ]    = (0.0, 0.0, 0.75) # True Positives\n",
    "    image[ pred & (~real), : ] = (1.0, 0.6, 0.2)  # False Positives\n",
    "    image[ (~pred) & real, : ] = (1.0, 0.4, 1.0)  # False Negatives\n",
    "\n",
    "    return image.reshape(list(ground_truth.shape) + [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN SINGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_run(image_no = 139,filter_methods= [], fixed_category = None,plot_img_gt=False,plot_prediction = False,verbose=False):\n",
    "    global heatmaps,IoU,aucD,aucI\n",
    "    # print('explaining :', fixed_category)\n",
    "    image_info = coco.loadImgs(image_no)[0]\n",
    "    image_path = os.path.join(paths.image_dir, image_info['file_name'])\n",
    "    load_image_to_explain(image_path,params, bg_type='gray')\n",
    "    \n",
    "    fixed_category = class_names[predicted_cls] # 'person'\n",
    "    \n",
    "    load_groundtruth(coco,image_path,fixed_category=fixed_category)\n",
    "    has_segmentation = any('segmentation' in ann for ann in annotations)\n",
    "    if has_segmentation:\n",
    "        print(f'{params.model_name} {image_no:<10} {fixed_category:<15} {class_names[predicted_cls]:<10} {f_S:<10.5}')\n",
    "        \n",
    "        if verbose:\n",
    "            print('='*90)\n",
    "            \n",
    "            print('='*90)\n",
    "        if plot_img_gt:\n",
    "            plot_img_gt_bg()\n",
    "            plot_gt(image_to_explain,annotations,fixed_category, save_fig=True,fig_size = (5,5))\n",
    "            plot_mask(ground_truth,category_name = fixed_category,save_fig=True,fig_size = (5,5))\n",
    "        ############################################################\n",
    "        results = model.predict(image_to_explain)\n",
    "        if plot_prediction:\n",
    "            plot_predictions(image_to_explain,results,category_name = fixed_category, save_fig=True,fig_size = (5,5))\n",
    "        # print(result)\n",
    "        print('-'*100)\n",
    "        #############   XAI\n",
    "        explainer = shap_bpt.Explainer(predict_yolo_masked, image_to_explain, num_explained_classes=2, verbose=True)\n",
    "        ################# EXPLANATION\n",
    "        heatmaps, aucD, aucI,IoU = {}, {}, {},{}\n",
    "        for n,_,funct in tqdm(methods, leave=False):\n",
    "            if n not in filter_methods:\n",
    "                continue;\n",
    "            # print_gpu_memory()\n",
    "            start_time = datetime.now()\n",
    "            heatmaps[n] = funct()\n",
    "            end_time = datetime.now()\n",
    "            print(f'| {n:<20} | {np.sum(heatmaps[n][0]):<20.5} | {\"{}\".format(end_time - start_time)} |')\n",
    "        ################# EVALUATION\n",
    "        if verbose:\n",
    "            print(f'| {\"method\":<10} | {\"aucI_pred\":<10} | {\"aucD_pred\":<10} | {\"aucI_mse\":<10} | {\"aucD_mse\":<10} | {\"max_IoU\":<10} | {\"au_IoU\":<10} |')\n",
    "        for n,_,funct in tqdm(methods, leave=False):\n",
    "            if n not in filter_methods:\n",
    "                continue;\n",
    "            aucD[n] = saliency_to_auc(heatmaps[n][0], method='del', batch_size=params.batch_size)\n",
    "            aucI[n] = saliency_to_auc(heatmaps[n][0], method='ins', batch_size=params.batch_size)\n",
    "            IoU[n]  = calc_IoU_curve(ground_truth.flatten(), heatmaps[n][0].flatten())\n",
    "            if verbose:\n",
    "                print(f\"| {n:<10} | {aucI[n]['auc_reg']:<10.5} | {aucD[n]['auc_reg']:<10.5} | {aucI[n]['auc_mse']:<10.5} | {aucD[n]['auc_mse']:<10.5} | {np.max(IoU[n][1]):<10.5} | {IoU[n][4]:<10.5} |\")\n",
    "\n",
    "        ################# PLOTTING\n",
    "        fun_plot_heatmaps(methods,heatmaps,destroy_fig=False, selected_ext='png', save_fig=True,plot_colorbar=False, plot_title=True)\n",
    "        fun_plot_IoU(methods,heatmaps,destroy_fig=False, selected_ext='png',plot_title=False, save_fig=True,fontsize=12)\n",
    "        plot_perform_iou(methods,IoU)\n",
    "        ################# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST_SINGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_single_test = False\n",
    "run_single_test = True\n",
    "\n",
    "# filter_methods = ['AA-500','Partition-500','BPT-500','LIME-500']\n",
    "filter_methods = []\n",
    "\n",
    "# USE_METHOD_FILTER = True\n",
    "USE_METHOD_FILTER = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,_,_ in methods:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_single_test:\n",
    "    \n",
    "    image_no        =   113235 \n",
    "    # image_no        =   1490 \n",
    "    fixed_category  =   None\n",
    "    plot_img_gt     =   True\n",
    "    plot_prediction =   True\n",
    "    verbose         =   False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_yolo_masked(np.expand_dims(ground_truth, axis=0))\n",
    "\n",
    "# predict_yolo_masked(np.expand_dims(image_to_explain, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get background values\n",
    "# f_G, f_B = get_bg_values_yolo(f_masked_yolo, ground_truth, predicted_cls, class_names, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_single_test:\n",
    "    image_info = coco.loadImgs(image_no)[0]\n",
    "    image_path = os.path.join(paths.image_dir, image_info['file_name'])\n",
    "    load_image_to_explain(image_path,params, bg_type='black')\n",
    "\n",
    "    \n",
    "\n",
    "    fixed_category = class_names[predicted_cls] # 'person'\n",
    "    \n",
    "    load_groundtruth(coco,image_path,fixed_category=fixed_category)\n",
    "    has_segmentation = any('segmentation' in ann for ann in annotations)\n",
    "    if has_segmentation:\n",
    "        print('='*90)\n",
    "        \n",
    "        if verbose:\n",
    "            print('='*90)\n",
    "            \n",
    "            print('='*90)\n",
    "        #--------------------------------------------------------------------------------------\n",
    "        # f_G, f_B = get_bg_values(predict_yolo,ground_truth,predicted_cls,class_names, verbose= True)\n",
    "        #--------------------------------------------------------------------------------------\n",
    "        print(f'{params.model_name} {image_no:<10} {fixed_category:<15} {class_names[predicted_cls]:<10} {f_S:<10.5} {f_0:<10.5}')\n",
    "        if plot_img_gt:\n",
    "            plot_img_gt_bg()\n",
    "            plot_gt(image_to_explain,annotations,fixed_category, save_fig=True,fig_size = (5,5))\n",
    "            plot_mask(ground_truth,category_name = fixed_category,save_fig=True,fig_size = (5,5))\n",
    "        results = model.predict(image_to_explain)\n",
    "        if plot_prediction:\n",
    "            plot_predictions(image_to_explain,results,category_name = fixed_category, save_fig=True,fig_size = (5,5))\n",
    "        # print(result)\n",
    "        print('-'*100)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SINGLE : EXPLANATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_single_test:\n",
    "    heatmaps = {}\n",
    "    evaluate_explanation = True\n",
    "    print(f'{\"| Method\":<20} | {\"f_S\":<10} | {\"f_T\":<10} | {\"f_0\":<10} | {\"TIME\":<10} |')\n",
    "    for ii, (n,_,funct) in enumerate(tqdm(methods, leave=False, desc = 'Explanation: ')):\n",
    "        if n not in filter_methods and USE_METHOD_FILTER:\n",
    "                # print('skipping - ',n)\n",
    "                continue\n",
    "        start_time = datetime.now()\n",
    "        heatmaps[n] = funct()\n",
    "        end_time = datetime.now()\n",
    "        print(f'| {n:<20} | {f_S:<10.7} |{np.sum(heatmaps[n][0]):<10.7} |{f_0:<10.7} | {\"{}\".format(end_time - start_time)} |')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SINGLE : EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_single_test:\n",
    "    aucD, aucI,IoU = {}, {}, {}\n",
    "    print('='*130)\n",
    "    print(f'| {\"method\":<10} | {\"f_S\":<8} | {\"f_T\":<8} | {\"f_S-f_T\":<12} | {\"aucI_pred\":<10} | {\"aucD_pred\":<10} | {\"aucI_mse\":<10} | {\"aucD_mse\":<10} | {\"max_IoU\":<10} | {\"au_IoU\":<10} |')\n",
    "    print('='*130)\n",
    "    for n,_,funct in tqdm(methods, leave=False, desc ='evaluation'):\n",
    "        ###############################################\n",
    "        if n not in filter_methods and USE_METHOD_FILTER:\n",
    "                # print('skipping - ',n)\n",
    "                continue\n",
    "        ###############################################\n",
    "        if evaluate_explanation:\n",
    "            st = time.time()\n",
    "            aucD[n] = saliency_to_auc(predict_yolo_masked,heatmaps[n][0],f_S,f_0,predicted_cls, method='del', batch_size=params.batch_size)\n",
    "            aucI[n] = saliency_to_auc(predict_yolo_masked,heatmaps[n][0],f_S,f_0,predicted_cls, method='ins', batch_size=params.batch_size)\n",
    "            IoU[n]  = calc_IoU_curve_imp(ground_truth.flatten(), heatmaps[n][0].flatten())\n",
    "            print(f\"| {n:<10} | {f_S:<8.5} |{np.sum(heatmaps[n][0]):<8.5} |{f_S - np.sum(heatmaps[n][0]):<12.7} |\\\n",
    "                   {aucI[n]['auc']:<10.5} | {aucD[n]['auc']:<10.5} | {aucI[n]['auc_r']:<10.5} | {aucD[n]['auc_r']:<10.5} | {np.max(IoU[n]['Y']):<10.5} | {IoU[n]['auc_IoU']:<10.5} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SINGLE : PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_single_test:\n",
    "    if len(filter_methods)==0:\n",
    "        fun_plot_heatmaps(methods,heatmaps,destroy_fig=False, selected_ext='png',\n",
    "                      exp_type='demo',\n",
    "                       save_fig=True,plot_colorbar=False, plot_title=True)\n",
    "    else:\n",
    "        fun_plot_filtered_heatmaps(methods,heatmaps,destroy_fig=False, selected_ext='png',\n",
    "                      exp_type='demo',save_fig=True,plot_colorbar=False, plot_title=True,\n",
    "                      filter_methods=filter_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_single_test:\n",
    "    if len(filter_methods)==0:\n",
    "        fun_plot_IoU(methods,heatmaps,destroy_fig=False, selected_ext='png',\n",
    "                 exp_type = 'demo',\n",
    "                 plot_title=True, save_fig=True,fontsize=12)\n",
    "        plot_perform_iou(methods,exp_type = 'demo')\n",
    "    else:\n",
    "        fun_plot_filtered_IoU(methods,heatmaps,destroy_fig=False, selected_ext='png',\n",
    "                 exp_type = 'demo',\n",
    "                 plot_title=True, save_fig=True,fontsize=12, filter_methods=filter_methods)\n",
    "        plot_perform_filtered_iou(methods,exp_type = 'demo', filter_methods=filter_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_ttl = f'{image_no}, explained_class: {predicted_cls} '\\\n",
    "                            f'f_S:\\ {f_S:0.6}, f_0: {f_0:0.6}, delta: {abs(f_S-f_0):0.6}'\n",
    "\n",
    "\n",
    "if run_single_test:\n",
    "\n",
    "    if len(filter_methods)==0:\n",
    "        fun_plot_performance(aucI,aucD,IoU, save_fig = True, ttl=plt_ttl, layout='2rows')\n",
    "    else:\n",
    "        fun_plot_performance_filtered(selected_methods=filter_methods)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SN: FULL TEST DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_demo = False\n",
    "run_demo = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_demo:\n",
    "    num_explained_classes = 2\n",
    "    # batch_size            = 32\n",
    "    print(f'{\"image\":<10} {\"total_obj\":<10} {\"selected_obj\":<10} {\"prob\":<10} {\"aucD_mse\":<10} {\"max_IoU\":<10} {\"au_IoU\"}:<10')\n",
    "    for im_id,image_no in enumerate(tqdm(coco.getImgIds())):\n",
    "        if image_no==139 or True:\n",
    "            #----------------------------------------------------------------------------------------\n",
    "            image_info = coco.loadImgs(image_no)[0]\n",
    "            image_path = os.path.join(paths.image_dir, image_info['file_name'])\n",
    "            load_image_to_explain(image_path,params, bg_type='gray')\n",
    "            #----------------------------------------------------------------------------------------\n",
    "            \n",
    "            if class_names[predicted_cls]=='tv':\n",
    "                continue\n",
    "            # print(f'top pred class === \\t{} : {}')\n",
    "            fixed_category = class_names[predicted_cls] # 'person'\n",
    "            # fixed_category = 'person' #class_names[predicted_cls] # 'person'\n",
    "            annotations = get_annotation(coco,image_path)[0]\n",
    "            \n",
    "            load_groundtruth(coco,image_path,fixed_category=fixed_category)\n",
    "            #----------------------------------------------------------------------------------------\n",
    "            has_segmentation = any('segmentation' in ann for ann in annotations)\n",
    "            if has_segmentation:\n",
    "                print(f'{image_no:<10} {fixed_category:<15} {class_names[predicted_cls]:<10} {f_S:<10.5}')\n",
    "                # plot_img_gt_bg()\n",
    "                plot_gt(image_to_explain,annotations,fixed_category, save_fig=True,fig_size = (5,5))\n",
    "                # plot_mask(ground_truth,category_name = fixed_category,save_fig=True,fig_size = (5,5))\n",
    "                #----------------------------------------------------------------------------------------\n",
    "                results = model.predict(image_to_explain)\n",
    "                \n",
    "                plot_predictions(image_to_explain,results,category_name = fixed_category, save_fig=True,fig_size = (5,5))\n",
    "                # print(result)\n",
    "                print('-'*100)\n",
    "                #############   XAI\n",
    "                explainer = shap_bpt.Explainer(predict_yolo_masked, image_to_explain, num_explained_classes=2, verbose=True)\n",
    "                ############\n",
    "                heatmaps, aucD, aucI,IoU = {}, {}, {},{}\n",
    "                for n,_,funct in tqdm(methods, leave=False):\n",
    "                    if n not in filter_methods and USE_METHOD_FILTER:\n",
    "                        # print('skipping - ',n)\n",
    "                        continue\n",
    "                    print('method : ',n)\n",
    "                    # print_gpu_memory()\n",
    "\n",
    "                    heatmaps[n] = funct()\n",
    "                #----------------------------------------------------------------------------------------\n",
    "                for n,_,funct in tqdm(methods, leave=False):\n",
    "                    if n not in filter_methods and USE_METHOD_FILTER:\n",
    "                        # print('skipping - ',n)\n",
    "                        continue\n",
    "                    aucD[n] = saliency_to_auc(predict_yolo_masked,heatmaps[n][0],f_S,f_0,predicted_cls, method='del', batch_size=params.batch_size)\n",
    "                    aucI[n] = saliency_to_auc(predict_yolo_masked,heatmaps[n][0],f_S,f_0,predicted_cls, method='ins', batch_size=params.batch_size)\n",
    "                    IoU[n]  = calc_IoU_curve_imp(ground_truth.flatten(), heatmaps[n][0].flatten())\n",
    "                if len(filter_methods)==0:\n",
    "                    fun_plot_heatmaps(methods,heatmaps,destroy_fig=False, selected_ext='png', save_fig=True,plot_colorbar=False)\n",
    "                    fun_plot_IoU(methods,heatmaps,destroy_fig=False, selected_ext='png',plot_title=True, save_fig=True,fontsize=12)\n",
    "                else:\n",
    "                    fun_plot_filtered_heatmaps(methods,heatmaps, filter_methods=filter_methods,\n",
    "                                               destroy_fig=False, selected_ext='png', save_fig=True,plot_colorbar=False)\n",
    "                    fun_plot_filtered_IoU(methods,heatmaps, filter_methods=filter_methods,\n",
    "                                          destroy_fig=False, selected_ext='png',plot_title=True, save_fig=True,fontsize=12)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{params.model_name} {model.info()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN ON SELECTED IMAGES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_on_selected_images = False\n",
    "run_on_selected_images = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     name,                 color,                  functor\n",
    "verbose = False\n",
    "\n",
    "methods_selected = [\n",
    "    # ('BPT-100',         'xkcd:light pink',     partial(get_bpt_heatmaps, num_samples=100,batch_size=64,verbose=verbose)),\n",
    "    ('BPT-500',         'xkcd:bright pink',     partial(get_bpt_heatmaps, num_samples=500,batch_size=64,verbose=verbose)),\n",
    "    # ('BPT-1000',         'xkcd:deep pink',     partial(get_bpt_heatmaps, num_samples=1000,batch_size=64,verbose=verbose)),\n",
    "    ]\n",
    "methods_selected_aa = [ # if multiple backgrounds\n",
    "    # ('AA-100', 'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=100,batch_size=64, verbose=verbose)),\n",
    "    ('AA-500', 'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=500,batch_size=64, verbose=verbose)),\n",
    "    # ('AA-1000', 'xkcd:bright blue',    partial(get_aa_heatmaps, num_samples=1000,batch_size=64, verbose=verbose)),\n",
    "]\n",
    "# methods_aa_huge = [\n",
    "#     ('AA-5000', 'xkcd:bright blue',      partial(get_aa_heatmaps, num_samples=5000, verbose=verbose)),\n",
    "#     # ('AA-10000', 'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=10000,batch_size=64, verbose=verbose)),\n",
    "# ]\n",
    "# methods_lime = [\n",
    "#     ('LIME-50',        'xkcd:bright lime',     partial(get_lime_heatmaps, num_segments=50, num_samples=50*5,verbose=verbose)),\n",
    "#     ('LIME-100',        'xkcd:kermit green',   partial(get_lime_heatmaps, num_segments=100, num_samples=100*5,verbose=verbose)),\n",
    "#     ('LIME-200',        'xkcd:dark lime green',partial(get_lime_heatmaps, num_segments=200, num_samples=200*5,verbose=verbose)),\n",
    "#     ]\n",
    "\n",
    "\n",
    "methods_selected_lime = [\n",
    "    # ('LIME-50',        'xkcd:bright lime',     partial(get_lime_heatmaps, num_segments=50, num_samples=50*5,verbose=verbose)),\n",
    "    # ('LIME-100',        'xkcd:bright lime',     partial(get_lime_heatmaps, num_segments=100, num_samples=100*5,verbose=verbose)),\n",
    "    # ('LIME-200',        'xkcd:dark lime green',partial(get_lime_heatmaps, num_segments=200, num_samples=200*5,verbose=verbose)),\n",
    "###########################################################\n",
    "## num_segments = num_samples / 10\n",
    "    # partial(get_aa_heatmaps, num_samples=100, verbose=verbose))\n",
    "    # ('LIME-100',        'xkcd:bright lime',     partial(get_lime_heatmaps, num_segments=100/10, num_samples=100,verbose=verbose)),\n",
    "    ('LIME-500',        'xkcd:kermit green',   partial(get_lime_heatmaps, num_segments=500/10, num_samples=500,verbose=verbose)),\n",
    "    # ('LIME-1000',        'xkcd:dark lime green',partial(get_lime_heatmaps, num_segments=1000/10, num_samples=1000,verbose=verbose))\n",
    "    ]\n",
    "\n",
    "# methods_cam = [\n",
    "#     # ('aIDG',         'xkcd:indigo',          partial(get_idg_heatmaps, use_abs=True)),\n",
    "#     ('aGradExpl',    'red',                  partial(get_gradexpl_heatmap, use_abs=True))\n",
    "#     ]\n",
    "\n",
    "# methods_ShapGradE = [\n",
    "#     ('ShapGradE',     'xkcd:camel',            partial(get_gradshap_captum_heatmaps, n_samples=20)),    \n",
    "# ]\n",
    "\n",
    "# # methods_limeSAM = [\n",
    "# #     ('LIMESAM',        'xkcd:bright lime',     partial(get_limeSAM_heatmaps, num_samples=500, verbose=verbose)),\n",
    "# #     ]\n",
    "\n",
    "\n",
    "\n",
    "# methods_LRP_ViT = [\n",
    "#         ('LRP',        'xkcd:bright lime',     get_heatmaps_LRP_ViT),\n",
    "    \n",
    "#     ]\n",
    "# methods_LRP = [\n",
    "#     ('LRP',        'xkcd:bright lime',     get_LRP_captum_heatmaps),\n",
    "    \n",
    "#     ]\n",
    "\n",
    "# method_gradcam_vit_heatmaps = [\n",
    "#     ('GradCAM',     'xkcd:camel',            get_gradcam_vit_heatmaps),\n",
    "#     ]\n",
    "\n",
    "# if pretrained_model_type  == 'swin_trans_vit' or pretrained_model_type == 'vit_LRP':\n",
    "#     methods_gradcam = [\n",
    "#     ('GradCAM',     'xkcd:camel',            get_gradcam_vit_heatmaps),\n",
    "#     ]\n",
    "# else:\n",
    "#     methods_gradcam = [\n",
    "#     ('GradCAM',     'xkcd:camel',            get_gradcam_heatmaps),\n",
    "#     ]\n",
    "    \n",
    "\n",
    "# methods += methods_pe if len(background_tensors) == 1 else methods_aa\n",
    "methods_selected +=methods_selected_aa\n",
    "# methods += methods_aa_huge\n",
    "methods_selected += methods_selected_lime\n",
    "\n",
    "\n",
    "# if pretrained_model_type  == 'swin_trans_vit' or pretrained_model_type == 'vit_LRP':\n",
    "#     methods += methods_LRP_ViT\n",
    "# else:\n",
    "#     methods += methods_LRP\n",
    "    \n",
    "# if pretrained_model_type  == 'swin_trans_vit' or pretrained_model_type == 'vit_LRP':\n",
    "#     methods += method_gradcam_vit_heatmaps\n",
    "# else:\n",
    "#     methods += methods_gradcam\n",
    "\n",
    "# methods += methods_cam\n",
    "\n",
    "# methods += methods_ShapGradE\n",
    "for n,_,_ in methods_selected:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_on_selected_images:\n",
    "    exp_type = 'selected'\n",
    "    # selected_set = [\n",
    "    #                 8021,\n",
    "    #                 1000, #\n",
    "    #                 1490, # person\n",
    "    #                 1584, # bus\n",
    "    #                 1761, #airplane\n",
    "    #                 2153, #person INTRESTING CASE\n",
    "    #                 2473, # ski, INTRESTING CASE\n",
    "    #                 3156, \n",
    "    #                 3845, #  cup - 0.88561 # OCCLUDED\n",
    "    #                 253002, ####### INSPECT\n",
    "    #                 139,\n",
    "    #                 7888,\n",
    "    #                 8277,\n",
    "    #                 8762,\n",
    "    #                 9483, # keyboard\n",
    "    #                 11051, # person -> 2\n",
    "                     \n",
    "    # #                 397133\n",
    "\n",
    "                    # ]\n",
    "    \n",
    "    selected_set = [785,\n",
    "                    360661,     # MULTI HORSES\n",
    "                    181666,     # --> two person very small\n",
    "                    233771,     # --> RGB BJECT ON GRAY IMAGE\n",
    "                    238866,     # --> GRAY MULTIPLE OBJECTS \n",
    "                    25560,      # --> TINY OBJECT in Left corner\n",
    "                    41888,      # --> Multi Objects 3 birds\n",
    "                    80671,      # --> PERSON IN DIFFERENT POSE\n",
    "                    85329,      # --> VERIFYYYYYYYYYY TINY OBJECT\n",
    "                    87038,      # --> TINY OBJECT\n",
    "                    125211,     # --> ZEBRA STRIPESSSSSSSSSSSSSSSSSSSS \n",
    "                    252219,     # --> MULTI OBJECTS 3 person\n",
    "                    270244,     #   --> ZEBRA IN FOREST \n",
    "                    286994,     #   --> MULTIPLE MANY MANY OBJECTS ???  \n",
    "                    516316,     #   --> MULTIPLE TINY OBJECTS\n",
    "\n",
    "    ]\n",
    "    \n",
    "    # selected_set = [785,\n",
    "    #                 # 5037,\n",
    "    #                 # 5060,\n",
    "    #                 # 7816,\n",
    "    #                 # 10764,\n",
    "    #                 # 15440,\n",
    "    #                 # 18737,\n",
    "    #                 # 22396\n",
    "    #                 ]\n",
    "    print('exp_type',exp_type)\n",
    "    print('selected_set',selected_set)\n",
    "print(filter_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_on_selected_images:\n",
    "    data_to_csv =  []\n",
    "\n",
    "    plot_heatmaps            = True\n",
    "    plot_IoU                 = False #True\n",
    "    compute_auc_curves       = False\n",
    "    save_fig                 = True\n",
    "    destroy_fig              = False \n",
    "    save_vectors_heatmaps    = False if run_on_selected_images else True\n",
    "    save_vectors_evaluation  = False \n",
    "    plot_title               = False\n",
    "    st_full                  = time.time()\n",
    "\n",
    "    # disallowed_vectors = ['LRP','GradCAM','aIDG','aGradExpl','ShapGradE']\n",
    "    # if model_type=='real':\n",
    "    # disallowed_vectors = ['Partition-100','Partition-500','Partition-1000','aGradExpl','GradCAM','LRP']\n",
    "\n",
    "    methods_ls,methods_ls_id = [],[]\n",
    "    for i_id,(i,_,_) in enumerate(methods):\n",
    "        # i = i.replace('Partition','PE')\n",
    "        # i = i.replace('GradCAM','GC')\n",
    "        i = i.replace('-','_')\n",
    "        # methods_ls.append(i)\n",
    "        # methods_ls_id.append(i_id+1)\n",
    "    files_success =[]\n",
    "    # print('saving data :\\t',paths.plotsIoU_path)\n",
    "    start_time = datetime.now()\n",
    "    print(f'code started:\\t{start_time}')\n",
    "\n",
    "    paths.csv_filename = f'{paths.path_csv}/csv_exp_{suffix}_{len(methods)}.csv'\n",
    "    print('='*95)\n",
    "    # print(f'{params.model_name} {model.info()}')\n",
    "    # print('='*95)\n",
    "    print(f'| {\"No\":<10}| {\"Image no\":<10} | {\"predicted class\":<25} | {\"annotations\":<10} | {\"predicted prob\":<12} | {\"predicted class-id\":<15} |')\n",
    "    print('='*95)\n",
    "\n",
    "    verify_annotation_preds = []\n",
    "    for im_id,image_no in enumerate(tqdm(selected_set)):\n",
    "        # print(image_no)\n",
    "        # break\n",
    "        \n",
    "        if image_no not in selected_set:\n",
    "            # print(image_no, image_no in selected_set)\n",
    "        # else:\n",
    "            continue\n",
    "        # break\n",
    "        # if im_id>1000:\n",
    "        #     break\n",
    "        # if image_no!=226111:\n",
    "        #     continue\n",
    "        # image_no = int(im_no.split('\\\\')[-1].split('.')[0])\n",
    "        st_load = time.time()\n",
    "\n",
    "        image_info = coco.loadImgs(image_no)[0]\n",
    "        image_path = os.path.join(paths.image_dir, image_info['file_name'])\n",
    "        load_image_to_explain(image_path,params, bg_type='gray')\n",
    "        ########################################################################\n",
    "        \n",
    "        # if class_names[predicted_cls]=='tv':\n",
    "        #     continue\n",
    "        # print(f'top pred class === \\t{class_names[predicted_cls]} : {f_S:10.5}')\n",
    "        fixed_category = class_names[predicted_cls] # 'person'\n",
    "        # fixed_category = 'person' #class_names[predicted_cls] # 'person'\n",
    "        annotations_all = get_annotation(coco,image_path,category_name=None)\n",
    "        \n",
    "\n",
    "        # print(ima,len(annotations))\n",
    "        if len(annotations_all)==0:\n",
    "            continue\n",
    "        preds_ = []\n",
    "        for annotation in annotations_all:\n",
    "            bbox = annotation['bbox']  # [x, y, width, height]\n",
    "            category = coco.loadCats(annotation['category_id'])[0]['name']\n",
    "            preds_.append(category)\n",
    "\n",
    "        ########################################################################\n",
    "        fixed_category = class_names[predicted_cls] # 'person'\n",
    "        # fixed_category = 'person' #class_names[predicted_cls] # 'person'\n",
    "\n",
    "        annotations_selected = get_annotation(coco,image_path,category_name=fixed_category)\n",
    "        \n",
    "        if len(annotations_selected)==0:\n",
    "            verify_annotation_preds.append({\n",
    "            'image_no':image_no,\n",
    "            'annotation_count':len(annotations_selected),\n",
    "            'top_predicted': class_names[predicted_cls],\n",
    "            'preds': preds_,\n",
    "            'True?': class_names[predicted_cls] in preds_\n",
    "            })\n",
    "            # print(f'| {im_id:<5} | {image_no:<10} | {fixed_category:<25} | {len(annotations_selected):<10} | {f_S:<12.5} | {predicted_cls:<15} |')\n",
    "            continue\n",
    "        \n",
    "        load_groundtruth(coco,image_path,fixed_category=fixed_category)\n",
    "        ########################################################################            \n",
    "        annotations_selected = annotations_selected[0]\n",
    "\n",
    "        has_segmentation = any('segmentation' in ann for ann in annotations_selected)\n",
    "        if not has_segmentation:\n",
    "            continue\n",
    "\n",
    "        results = model.predict(image_to_explain)\n",
    "        time_load = time.time()-st_load\n",
    "        # plot_predictions(image_to_explain,results,category_name = fixed_category)\n",
    "\n",
    "        print(f'| {im_id:<10} | {image_no:<10} | {fixed_category:<25} | {len(annotations_selected):<10} | {f_S:<12.5} | {predicted_cls:<15} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_on_selected_images:\n",
    "    data_to_csv =  []\n",
    "\n",
    "    plot_heatmaps            = True\n",
    "    plot_IoU                 = False #True\n",
    "    compute_auc_curves       = False\n",
    "    save_fig                 = True\n",
    "    destroy_fig              = False \n",
    "    save_vectors_heatmaps    = False if run_on_selected_images else True\n",
    "    save_vectors_evaluation  = False \n",
    "    plot_title               = False\n",
    "    st_full                  = time.time()\n",
    "\n",
    "    # disallowed_vectors = ['LRP','GradCAM','aIDG','aGradExpl','ShapGradE']\n",
    "    # if model_type=='real':\n",
    "    # disallowed_vectors = ['Partition-100','Partition-500','Partition-1000','aGradExpl','GradCAM','LRP']\n",
    "\n",
    "    methods_ls,methods_ls_id = [],[]\n",
    "    for i_id,(i,_,_) in enumerate(methods):\n",
    "        # i = i.replace('Partition','PE')\n",
    "        # i = i.replace('GradCAM','GC')\n",
    "        i = i.replace('-','_')\n",
    "        # methods_ls.append(i)\n",
    "        # methods_ls_id.append(i_id+1)\n",
    "    files_success =[]\n",
    "    # print('saving data :\\t',paths.plotsIoU_path)\n",
    "    start_time = datetime.now()\n",
    "    print(f'code started:\\t{start_time}')\n",
    "\n",
    "    paths.csv_filename = f'{paths.path_csv}/csv_exp_{suffix}_{len(methods)}.csv'\n",
    "    print('='*95)\n",
    "    # print(f'{params.model_name} {model.info()}')\n",
    "    # print('='*95)\n",
    "    print(f'| {\"No\":<10}| {\"Image no\":<10} | {\"predicted class\":<25} | {\"annotations\":<10} | {\"predicted prob\":<12} | {\"predicted class-id\":<15} |')\n",
    "    print('='*95)\n",
    "\n",
    "    verify_annotation_preds = []\n",
    "    for im_id,image_no in enumerate(tqdm(selected_set)):\n",
    "        # print(image_no)\n",
    "        # break\n",
    "        \n",
    "        if image_no not in selected_set:\n",
    "            # print(image_no, image_no in selected_set)\n",
    "        # else:\n",
    "            continue\n",
    "        # break\n",
    "        # if im_id>1000:\n",
    "        #     break\n",
    "        # if image_no!=226111:\n",
    "        #     continue\n",
    "        # image_no = int(im_no.split('\\\\')[-1].split('.')[0])\n",
    "        st_load = time.time()\n",
    "\n",
    "        image_info = coco.loadImgs(image_no)[0]\n",
    "        image_path = os.path.join(paths.image_dir, image_info['file_name'])\n",
    "        load_image_to_explain(image_path,params, bg_type='gray')\n",
    "        ########################################################################\n",
    "        \n",
    "        # if class_names[predicted_cls]=='tv':\n",
    "        #     continue\n",
    "        # print(f'top pred class === \\t{class_names[predicted_cls]} : {f_S:10.5}')\n",
    "        fixed_category = class_names[predicted_cls] # 'person'\n",
    "        # fixed_category = 'person' #class_names[predicted_cls] # 'person'\n",
    "        annotations_all = get_annotation(coco,image_path,category_name=None)\n",
    "        \n",
    "\n",
    "        # print(ima,len(annotations))\n",
    "        if len(annotations_all)==0:\n",
    "            \n",
    "            # annot__ = get_annotation(coco,image_path,category_name=None)\n",
    "            \n",
    "            # preds_ = []\n",
    "            # for ar in range(len(annot__)):\n",
    "            #     print(ar, class_names[annot__[ar]['category_id']])\n",
    "            #     preds_.append(class_names[annot__[ar]['category_id']])\n",
    "            # fail_cases.append({\n",
    "            #     'image_no':image_no,\n",
    "            #     'annotation_count':len(annot__),\n",
    "            #     'top_predicted': class_names[predicted_cls],\n",
    "            #     'preds': preds_\n",
    "            # })\n",
    "            continue\n",
    "        preds_ = []\n",
    "        for annotation in annotations_all:\n",
    "            bbox = annotation['bbox']  # [x, y, width, height]\n",
    "            category = coco.loadCats(annotation['category_id'])[0]['name']\n",
    "            preds_.append(category)\n",
    "        # else:\n",
    "            # pa\n",
    "            # print(image_no, len(annotations))\n",
    "        ########################################################################\n",
    "        fixed_category = class_names[predicted_cls] # 'person'\n",
    "        # fixed_category = 'person' #class_names[predicted_cls] # 'person'\n",
    "\n",
    "        annotations_selected = get_annotation(coco,image_path,category_name=fixed_category)\n",
    "        \n",
    "        if len(annotations_selected)==0:\n",
    "            verify_annotation_preds.append({\n",
    "            'image_no':image_no,\n",
    "            'annotation_count':len(annotations_selected),\n",
    "            'top_predicted': class_names[predicted_cls],\n",
    "            'preds': preds_,\n",
    "            'True?': class_names[predicted_cls] in preds_\n",
    "            })\n",
    "            # print(f'| {im_id:<5} | {image_no:<10} | {fixed_category:<25} | {len(annotations_selected):<10} | {f_S:<12.5} | {predicted_cls:<15} |')\n",
    "            continue\n",
    "        \n",
    "        load_groundtruth(coco,image_path,fixed_category=fixed_category)\n",
    "        ########################################################################            \n",
    "        annotations_selected = annotations_selected[0]\n",
    "\n",
    "        has_segmentation = any('segmentation' in ann for ann in annotations_selected)\n",
    "        if not has_segmentation:\n",
    "            continue\n",
    "        # if not class_names[predicted_cls] in preds_:\n",
    "\n",
    "        #     print(f'| FAIL: {im_id:<5} | {image_no:<10} | {fixed_category:<25} | {len(annotations_selected):<10} | {f_S:<12.5} | {predicted_cls:<15} |')\n",
    "        # continue\n",
    "        \n",
    "        \n",
    "        # print(f'{image_no:<10} {fixed_category:<15} ')\n",
    "        # print(f'{image_no:<10} {fixed_category:<15} {class_names[predicted_cls]:<10} {f_S:<10.5}')\n",
    "        # plot_img_gt_bg()\n",
    "        # break\n",
    "        results = model.predict(image_to_explain)\n",
    "        time_load = time.time()-st_load\n",
    "        # plot_predictions(image_to_explain,results,category_name = fixed_category)\n",
    "\n",
    "        # print(result)\n",
    "        # print('-'*95)\n",
    "        print(f'| {im_id:<10} | {image_no:<10} | {fixed_category:<25} | {len(annotations_selected):<10} | {f_S:<12.5} | {predicted_cls:<15} |')\n",
    "        #############   XAI\n",
    "        explainer = shap_bpt.Explainer(predict_yolo_masked, image_to_explain, num_explained_classes=2, verbose=True)\n",
    "        ############     HeatMaps    ############\n",
    "        heatmaps = {}\n",
    "        \n",
    "        time_exp = {}\n",
    "        for n,_,funct in tqdm(methods, desc='Explanation',leave=False):\n",
    "            if len(filter_methods)>0:\n",
    "                if n not in filter_methods  and USE_METHOD_FILTER:\n",
    "                    # print('skipping - ',n)\n",
    "                    continue;\n",
    "            # heatmap_filename = f'{vector_path}//heatmaps_{image_n}_{n}.pkl'\n",
    "            \n",
    "            # if save_vectors_heatmaps:\n",
    "            #     if os.path.exists(heatmap_filename):\n",
    "            #         print(f'loaded : {image_n}_{n}.pkl')\n",
    "            st = time.time()\n",
    "            heatmaps[n] = funct()\n",
    "            time_exp[n] = time.time()-st\n",
    "        \n",
    "        if plot_heatmaps:\n",
    "            if len(filter_methods)==0:\n",
    "                fun_plot_heatmaps(methods,heatmaps,exp_type=exp_type,destroy_fig=destroy_fig,\n",
    "                            #   exp_type='selected',\n",
    "                              save_fig=save_fig,plot_title=plot_title, dpi=100)\n",
    "            else:\n",
    "                fun_plot_filtered_heatmaps(methods,heatmaps,destroy_fig=destroy_fig,\n",
    "                                           exp_type=exp_type,save_fig=save_fig,plot_colorbar=False, plot_title=plot_title,\n",
    "                                           dpi=200,\n",
    "                                           filter_methods=filter_methods)\n",
    "                \n",
    "        if compute_auc_curves:\n",
    "            ############     AUCs    ############\n",
    "            aucD, aucI,IoU = {}, {},{}\n",
    "            overlaps={}\n",
    "            for n,_,_ in tqdm(methods, desc='Evaluation',leave=False):\n",
    "                if len(filter_methods)>0:\n",
    "                    if n not in filter_methods  and USE_METHOD_FILTER:\n",
    "                        # print('skipping - ',n)\n",
    "                        continue;\n",
    "                #############     aucD    ############################\n",
    "                st = time.time()\n",
    "                aucD[n] = saliency_to_auc(predict_yolo_masked,heatmaps[n][0],f_S,f_0,predicted_cls, method='del', batch_size=params.batch_size)\n",
    "                   \n",
    "                time_aucD = time.time()-st\n",
    "                ############    aucI     ############################\n",
    "                st = time.time()\n",
    "                aucI[n] = saliency_to_auc(predict_yolo_masked,heatmaps[n][0],f_S,f_0,predicted_cls, method='ins', batch_size=params.batch_size)\n",
    "                time_aucI = time.time()-st\n",
    "                st = time.time()\n",
    "                ###########   IOU  ############################\n",
    "                IoU[n]  = calc_IoU_curve_imp(ground_truth.flatten(), heatmaps[n][0].flatten())\n",
    "                \n",
    "                time_auc_IoU = time.time()-st      \n",
    "            \n",
    "                data_selected = {'image'         : image_no,\n",
    "                                'image_size'    : image_to_explain.shape,\n",
    "                                'bg_type'       : params.background_type,\n",
    "                                'inference_time': results[0].speed['inference'],\n",
    "                                'pred_cls'      : predicted_cls,\n",
    "                                'pred_lbl'      : class_names[predicted_cls],\n",
    "                                'object_count'  : len(annotations),\n",
    "                                #----------------------------------------------------------------------------------------\n",
    "                                'f_S'           : f_S,\n",
    "                                'f_0'           : f_0,\n",
    "                                'f_T'           : np.sum(heatmaps[n][0]),               \n",
    "                                'f_N'           : len(np.unique(heatmaps[n][0])),           ## UNIQUE PATCHES IN EXPLANATION\n",
    "                                'method'        : n,\n",
    "                                #----------------------------------------------------------------------------------------                        \n",
    "                                'aucI_pred'     : aucI[n]['auc'],  \n",
    "                                'aucD_pred'     : aucD[n]['auc'],  \n",
    "                                ##------------------------------------\n",
    "                                'aucI_r'        : aucI[n]['auc_r'],  \n",
    "                                'aucD_r'        : aucD[n]['auc_r'],  \n",
    "                                ##------------------------------------\n",
    "                                'aucI_adj'      : aucI[n]['auc_adj'],  \n",
    "                                'aucD_adj'      : aucD[n]['auc_adj'],  \n",
    "                                ##------------------------------------\n",
    "                                'aucI_adj_r'    : aucI[n]['auc_adjr'],  \n",
    "                                'aucD_adj_r'    : aucD[n]['auc_adjr'],  \n",
    "                                ##------------------------------------\n",
    "                                'aucI_clip'     : aucI[n]['auc_clip'], \n",
    "                                'aucI_clipr'    : aucI[n]['auc_clipr'],\n",
    "                                ##------------------------------------\n",
    "                                'aucD_clip'     : aucD[n]['auc_clip'], \n",
    "                                'aucD_clipr'    : aucD[n]['auc_clipr'],\n",
    "                                #----------------------------------------------------------------------------------------\n",
    "                                'threshold'     : IoU[n]['max_IoU_heatmap_threshold'],      # [2],\n",
    "                                'best_point'    : IoU[n]['x_best'],     # [3],\n",
    "                                'max_IoU'       : np.max(IoU[n]['Y']),  # [1],\n",
    "                                'auc_IoU'        : IoU[n]['auc_IoU'],     # [4],\n",
    "                                #----------------------------------------------------------------------------------------\n",
    "                                'time_load'     : time_load,\n",
    "                                'time_exp'      : time_exp[n],\n",
    "                                'time_aucI'     : time_aucI,\n",
    "                                'time_aucD'     : time_aucD,\n",
    "                                'time_auc_IoU'  : time_auc_IoU,\n",
    "                                'time_total'    : time_load+time_exp[n]+time_aucI+time_aucD+time_auc_IoU\n",
    "                                }\n",
    "                \n",
    "                data_to_csv.append(data_selected)\n",
    "            if plot_IoU:\n",
    "                if len(filter_methods)==0:\n",
    "                    fun_plot_IoU(methods,heatmaps,exp_type=exp_type,\n",
    "                            destroy_fig=destroy_fig,save_fig=save_fig,\n",
    "                            plot_title=plot_title, dpi=100,text_x=45,text_y=110)\n",
    "                else:\n",
    "                    fun_plot_filtered_IoU(methods,heatmaps, filter_methods=filter_methods,\n",
    "                                        exp_type=exp_type,\n",
    "                                        destroy_fig=destroy_fig,\n",
    "                                        plot_title=plot_title, save_fig=save_fig,fontsize=12)\n",
    "        \n",
    "        df_selected = pd.DataFrame(data_to_csv)\n",
    "    \n",
    "    time_full = time.time()-st_full\n",
    "    print(f'{\"Time for selected test is\":<20} : {time_full:<10.10}')\n",
    "    end_time = datetime.now()\n",
    "    print(f'{\"Duration\":<20} : {\"{}\".format(end_time - start_time)}')\n",
    "    \n",
    "    chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_full_exp = False\n",
    "run_full_exp = True\n",
    "if run_full_exp:\n",
    "    paths.csv_filename = f'{paths.path_csv}/csv_exp_{suffix}_{len(methods)}.csv'\n",
    "    print('csv file will be saved at :', paths.csv_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_bg_values(f_masked,ground_truth,predicted_cls,class_names):\n",
    "#     global f_G, f_B\n",
    "#     # evaluate the ground truth mask with the background replacement strategy for masking function\n",
    "#     predicted_fG = f_masked(np.expand_dims(ground_truth, axis=0))[0]\n",
    "#     f_G = float(predicted_fG[predicted_cls])\n",
    "#     print(class_names[predicted_cls], f_G, predicted_cls, f_G)\n",
    "#     # print('softmax prob:', np_softmax(predicted_fG)[predicted_cls])\n",
    "\n",
    "#     # evaluate the backgrounf (negative of the ground truth mask)\n",
    "#     background_mask = np.logical_not(ground_truth)\n",
    "#     predicted_fB = f_masked(np.expand_dims(background_mask, axis=0))[0]\n",
    "#     f_B = float(predicted_fB[predicted_cls])\n",
    "#     print(class_names[predicted_cls], f_B, predicted_cls, f_B)\n",
    "#     # print('softmax prob:', np_softmax(predicted_fB)[predicted_cls])\n",
    "\n",
    "#     print()\n",
    "#     print('nu(S):  ', round(f_S, 4))\n",
    "#     print('nu(G):  ', round(f_G, 4))\n",
    "#     print('nu(S/G):', round(f_B, 4))\n",
    "#     print('nu(0):  ', round(f_0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_full_exp:\n",
    "    run_on_full_first = 0\n",
    "    data_to_csv =  []\n",
    "\n",
    "    plot_heatmaps            = False #True\n",
    "    plot_IoU                 = False #True\n",
    "    save_fig                 = False #True\n",
    "    destroy_fig              = True\n",
    "    save_vectors_heatmaps    = True\n",
    "    save_vectors_evaluation  = False\n",
    "    plot_title               = False\n",
    "    verbose_print            = False\n",
    "    st_full                  = time.time()\n",
    "\n",
    "    full_img_subset          = coco.getImgIds()[:params.data_subset]\n",
    "    \n",
    "    # disallowed_vectors = ['LRP','GradCAM','aIDG','aGradExpl','ShapGradE']\n",
    "    # if model_type=='real':\n",
    "    # disallowed_vectors = ['Partition-100','Partition-500','Partition-1000','aGradExpl','GradCAM','LRP']\n",
    "\n",
    "    methods_ls,methods_ls_id = [],[]\n",
    "    for i_id,(i,_,_) in enumerate(methods):\n",
    "        # i = i.replace('Partition','PE')\n",
    "        # i = i.replace('GradCAM','GC')\n",
    "        i = i.replace('-','_')\n",
    "        # methods_ls.append(i)\n",
    "        # methods_ls_id.append(i_id+1)\n",
    "    files_success =[]\n",
    "    print(f'Running for images: {params.data_subset}')\n",
    "    print('saving data :\\t',paths.plotsIoU_path)\n",
    "    print(f'SAVING CSV AT :', paths.csv_filename)\n",
    "    start_time = datetime.now()\n",
    "    print(f'code started:\\t{start_time}')\n",
    "\n",
    "    paths.csv_filename = f'{paths.path_csv}/csv_exp_{suffix}_{len(methods)}.csv'\n",
    "    if verbose_print:\n",
    "        print('='*95)\n",
    "        print(f'{params.model_name} {model.info()}')\n",
    "        print('='*95)\n",
    "        print(f'| {\"No\":<10}| {\"Image no\":<10} | {\"predicted class\":<25} | {\"annotations\":<10} | {\"predicted prob\":<12} | {\"predicted class-id\":<15} |')\n",
    "        print('='*95)\n",
    "\n",
    "    verify_annotation_preds = []\n",
    "    for im_id,image_no in enumerate(tqdm(full_img_subset)):\n",
    "        if run_on_full_first==0:\n",
    "            start_time_first = datetime.now()\n",
    "        # if image_no!=226111:\n",
    "        #     continue\n",
    "        # image_no = int(im_no.split('\\\\')[-1].split('.')[0])\n",
    "        st_load = time.time()\n",
    "\n",
    "        image_info = coco.loadImgs(image_no)[0]\n",
    "        image_path = os.path.join(paths.image_dir, image_info['file_name'])\n",
    "        load_image_to_explain(image_path,params, bg_type='gray')\n",
    "        ########################################################################\n",
    "\n",
    "        fixed_category = class_names[predicted_cls] # 'person'\n",
    "        # fixed_category = 'person' #class_names[predicted_cls] # 'person'\n",
    "        annotations_all = get_annotation(coco,image_path,category_name=None)\n",
    "\n",
    "        if len(annotations_all)==0:\n",
    "            continue\n",
    "        preds_ = []\n",
    "        for annotation in annotations_all:\n",
    "            bbox = annotation['bbox']  # [x, y, width, height]\n",
    "            category = coco.loadCats(annotation['category_id'])[0]['name']\n",
    "            preds_.append(category)\n",
    "        # else:\n",
    "            # pa\n",
    "            # print(image_no, len(annotations))\n",
    "        ########################################################################\n",
    "        fixed_category = class_names[predicted_cls] # 'person'\n",
    "        # fixed_category = 'person' #class_names[predicted_cls] # 'person'\n",
    "\n",
    "        annotations_selected = get_annotation(coco,image_path,category_name=fixed_category)\n",
    "        \n",
    "        if len(annotations_selected)==0:\n",
    "            verify_annotation_preds.append({\n",
    "            'image_no':image_no,\n",
    "            'annotation_count':len(annotations_selected),\n",
    "            'top_predicted': class_names[predicted_cls],\n",
    "            'preds': preds_,\n",
    "            'True?': class_names[predicted_cls] in preds_\n",
    "            })\n",
    "            # print(f'| {im_id:<5} | {image_no:<10} | {fixed_category:<25} | {len(annotations_selected):<10} | {f_S:<12.5} | {predicted_cls:<15} |')\n",
    "            continue\n",
    "        \n",
    "        load_groundtruth(coco,image_path,fixed_category=fixed_category)\n",
    "        ####################\n",
    "        # get_bg_values(predict_yolo_masked,ground_truth,predicted_cls,class_names)\n",
    "        ####################\n",
    "        ########################################################################\n",
    "            \n",
    "        annotations_selected = annotations_selected[0]\n",
    "        \n",
    "        has_segmentation = any('segmentation' in ann for ann in annotations_selected)\n",
    "        if not has_segmentation:\n",
    "            continue\n",
    "\n",
    "        results = model.predict(image_to_explain)\n",
    "        time_load = time.time()-st_load\n",
    "        # plot_predictions(image_to_explain,results,category_name = fixed_category)\n",
    "\n",
    "        if verbose_print:\n",
    "            print(f'| {im_id:<5} | {image_no:<10} | {fixed_category:<25} | {len(annotations_selected):<10} | {f_S:<12.5} | {predicted_cls:<15} |')\n",
    "        #############   XAI\n",
    "        explainer = shap_bpt.Explainer(predict_yolo_masked, image_to_explain, num_explained_classes=2, verbose=True)\n",
    "        ############     HeatMaps    ############\n",
    "        heatmaps = {}\n",
    "        \n",
    "        time_exp = {}\n",
    "        for n,_,funct in tqdm(methods, desc='Explanation',leave=False):\n",
    "            # heatmap_filename = f'{vector_path}//heatmaps_{image_n}_{n}.pkl'\n",
    "            \n",
    "            # if save_vectors_heatmaps:\n",
    "            #     if os.path.exists(heatmap_filename):\n",
    "            #         print(f'loaded : {image_n}_{n}.pkl')\n",
    "            st = time.time()\n",
    "            heatmaps[n] = funct()\n",
    "            time_exp[n] = time.time()-st\n",
    "        \n",
    "        if plot_heatmaps:\n",
    "            fun_plot_heatmaps(methods,heatmaps,exp_type='full',destroy_fig=destroy_fig,save_fig=save_fig,plot_title=plot_title, dpi=100)\n",
    "        ############     AUCs    ############\n",
    "        aucD, aucI,IoU = {}, {},{}\n",
    "        overlaps={}\n",
    "        for n,_,_ in tqdm(methods, desc='Evaluation',leave=False):\n",
    "            #############     aucD    ############################\n",
    "            st = time.time()\n",
    "            aucD[n] = saliency_to_auc(predict_yolo_masked,heatmaps[n][0],f_S,f_0,predicted_cls, method='del', batch_size=params.batch_size)\n",
    "                    \n",
    "            time_aucD = time.time()-st\n",
    "            ############    aucI     ############################\n",
    "            st = time.time()\n",
    "            aucI[n] = saliency_to_auc(predict_yolo_masked,heatmaps[n][0],f_S,f_0,predicted_cls, method='ins', batch_size=params.batch_size)\n",
    "                    \n",
    "            time_aucI = time.time()-st\n",
    "            st = time.time()\n",
    "            ###########   IOU  ############################\n",
    "            IoU[n]  = calc_IoU_curve_imp(ground_truth.flatten(), heatmaps[n][0].flatten())\n",
    "            \n",
    "            time_auc_IoU = time.time()-st      \n",
    "            \n",
    "            data = {'image'         : image_no,\n",
    "                    'image_size'    : image_to_explain.shape,\n",
    "                    'bg_type'       : params.background_type,\n",
    "                    'inference_time': results[0].speed['inference'],\n",
    "                    'pred_cls'      : predicted_cls,\n",
    "                    'pred_lbl'      : class_names[predicted_cls],\n",
    "                    'object_count'  : len(annotations),\n",
    "                    'f_S'           : f_S,\n",
    "                    'f_0'           : f_0,\n",
    "                    'delta_f'       : f_S-f_0,\n",
    "                    # 'f_G'           : f_B,\n",
    "                    # 'f_B'           : f_G,\n",
    "                    'f_T'           : np.sum(heatmaps[n][0]),               \n",
    "                    'f_N'           : len(np.unique(heatmaps[n][0])),           ## UNIQUE PATCHES IN EXPLANATION\n",
    "                    'method'        : n,\n",
    "                    # 'threshold'     : IoU[n]['max_IoU_heatmap_threshold'],      # [2],\n",
    "                    # 'best_point'    : IoU[n]['x_best'],     # [3],\n",
    "                    # 'max_IoU'       : np.max(IoU[n]['Y']),  # [1],\n",
    "                    # 'auc_IoU'        : IoU[n]['auc_IoU'],     # [4],\n",
    "                    # 'aucI_pred'     : aucI[n]['auc_reg'],   # aucI[n][-3],\n",
    "                    # 'aucD_pred'     : aucD[n]['auc_reg'],   # aucD[n][-3],\n",
    "                    # 'aucI_mse'      : aucI[n]['auc_mse'],   # aucI[n][-1],\n",
    "                    # 'aucD_mse'      : aucD[n]['auc_mse'],   # aucD[n][-1],\n",
    "                    ##############################\n",
    "                    'aucI_pred'     : aucI[n]['auc'],  \n",
    "                    'aucD_pred'     : aucD[n]['auc'],  \n",
    "                    ##------------------------------------\n",
    "                    'aucI_r'        : aucI[n]['auc_r'],  \n",
    "                    'aucD_r'        : aucD[n]['auc_r'],  \n",
    "                    ##------------------------------------\n",
    "                    'aucI_adj'      : aucI[n]['auc_adj'],  \n",
    "                    'aucD_adj'      : aucD[n]['auc_adj'],  \n",
    "                    ##------------------------------------\n",
    "                    'aucI_adj_r'    : aucI[n]['auc_adjr'],  \n",
    "                    'aucD_adj_r'    : aucD[n]['auc_adjr'],  \n",
    "                    ##------------------------------------\n",
    "                    'aucI_clip'     : aucI[n]['auc_clip'], \n",
    "                    'aucI_clipr'    : aucI[n]['auc_clipr'],\n",
    "                    ##------------------------------------\n",
    "                    'aucD_clip'     : aucD[n]['auc_clip'], \n",
    "                    'aucD_clipr'    : aucD[n]['auc_clipr'],\n",
    "                    #----------------------------\n",
    "                    'threshold'     : IoU[n]['max_IoU_heatmap_threshold'],      # [2],\n",
    "                    'best_point'    : IoU[n]['x_best'],     # [3],\n",
    "                    'max_IoU'       : np.max(IoU[n]['Y']),  # [1],\n",
    "                    'auc_IoU'        : IoU[n]['auc_IoU'],     # [4],\n",
    "                    #----------------------------\n",
    "                    'time_load'     : time_load,\n",
    "                    'time_exp'      : time_exp[n],\n",
    "                    'time_aucI'     : time_aucI,\n",
    "                    'time_aucD'     : time_aucD,\n",
    "                    'time_auc_IoU'  : time_auc_IoU,\n",
    "                    'time_total'    : time_load+time_exp[n]+time_aucI+time_aucD+time_auc_IoU\n",
    "                    }\n",
    "            \n",
    "            data_to_csv.append(data)\n",
    "        if plot_IoU:\n",
    "            fun_plot_IoU(methods,heatmaps,exp_type='full',destroy_fig=destroy_fig,save_fig=save_fig,plot_title=plot_title, dpi=100)\n",
    "        # print('-'*90)\n",
    "        df = pd.DataFrame(data_to_csv)\n",
    "        df.to_csv(f'{paths.csv_filename}', sep=',')\n",
    "        if run_on_full_first==0:\n",
    "            end_time_first = datetime.now()\n",
    "            print(f'{\"Duration for single example is \":<20} : {\"{}\".format(end_time_first - start_time_first)}, therefor {params.data_subset} images, it can take {\"{}\".format( (end_time_first - start_time_first)*params.data_subset)}')\n",
    "            # print(f\"Duration for single example is: {end_time_first - start_time_first:.6f} seconds \"\n",
    "            #       f\"for {params.data_subset} data, it can take \"\n",
    "            #       f\"{(end_time_first - start_time_first) * params.data_subset:.6f} seconds in total.\")\n",
    "            run_on_full_first +=1\n",
    "            \n",
    "        # break\n",
    "\n",
    "    time_full = time.time()-st_full\n",
    "    \n",
    "    print(f'{\"Time for test is\":<20} : {time_full:<10.10}')\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print(f'{\"Duration\":<20} : {\"{}\".format(end_time - start_time)}')\n",
    "    \n",
    "    chime.success()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END FULL TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paths.csv_filename)\n",
    "get_file_modify_time(filepath = paths.csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'started:\\t{start_time}')\n",
    "print(f'{\"Duration\":<20} : {\"{}\".format(end_time - start_time)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
