# ShapBPT: Image Feature Attributions using Data-Aware Binary Partition Trees  
### Supplementary Material â€“ MS-COCO Object Detection Experiments (YOLO11s)

This folder provides the **complete supplementary material** for the MS-COCO experiment conducted in the paper:

> **_ShapBPT: Image Feature Attributions using Data-Aware Binary Partition Trees_**

The goal of this experiment is to evaluate **ShapBPT** as an eXplainable AI (**XAI**) method for **object detection**, using the **YOLO11s** model on the **MS-COCO 2017 validation set**.  
All notebooks, CSV files, precomputed heatmaps, ground-truth IoU comparisons, and plots are included here for reproducibility.

---

# ğŸ“ Folder Overview

This directory contains the following components:

### **Folders**
- **[`CSV/`](CSV/)**  
  Contains the **precomputed CSV files** generated by running  
  **`N1_MS_COCO.ipynb`**.  
  These CSV files store:
  - AUC curves  
  - MSE curves  
  - IoU scores  
  - Pixel-mask evaluation metrics  
  - Per-image saliency statistics  

- **[`results/`](results/)**  
  Contains:
  - All **heatmaps** generated using ShapBPT and baseline methods  
  - Per-image **IoU visualizations**  
  - **Prediction overlays** (YOLO11s bounding boxes)  
  - **Saliency â†’ metric plots** (AUC/MSE vs. mask percentage)

---

# ğŸ“„ Notebook

## **1. `N1_MS_COCO.ipynb`**
This is the **main notebook** for running the complete MS-COCO experiment.  
It includes:

- Loading and preprocessing MS-COCO validation images  
- Running **YOLO11s** on each image  
- Applying **ShapBPT** and baseline XAI methods  
- Visualizing:
  - saliency heatmaps  
  - prediction overlays  
  - groundtruth masks  
- Computing evaluation metrics:
  - AUC curves  
  - MSE curves  
  - IoU  
  - Max-IoU comparison  
- Saving results into structured folders  
- Optionally running **full-dataset evaluation** and saving outputs under `results/`

---

# ğŸ” Example Outputs

Below are example visualizations for COCO image **113235**, using YOLO11s and gray background replacement.

---

## ğŸŸ¥ Model Predictions

<center>
<img src="results/yolo11s_gray/single/113235_yolo_predictions.png" width="70%">
</center>

<p align="center"><i>Top-k predicted objects on MS-COCO image 113235 (YOLO11s).</i></p>

---

## ğŸŸ¥ Ground-Truth Segmentation

<center>
<img src="results/yolo11s_gray/single/113235_gray_bg_gt.png" width="90%">
</center>

<p align="center"><i>Ground-truth objects from MS-COCO annotations, visualized on a gray background.</i></p>

---

## ğŸŸ¦ Saliency Map (ShapBPT)

<center>
<img src="results/yolo11s_gray/single/113235_gray_heatmap.png">
</center>

<p align="center"><i>ShapBPT heatmap for image 113235 (gray background replacement, YOLO11s).</i></p>

---

## ğŸ“ˆ Evaluation Metrics (AUC / MSE)

<center>
<img src="results/yolo11s_gray/single/113235_gray_PM.png">
</center>

<p align="center"><i>AUC and MSE curves measuring importance fidelity across masking percentages.</i></p>

---

## ğŸŸ© IoU Evaluation (Ground-Truth Comparison)

<center>
<img src="results/yolo11s_gray/single/113235_gray_IoU.png">
</center>

<p align="center"><i>IoU computed between saliency regions and true object masks.</i></p>

---

## ğŸŸ© Max-IoU Evaluation

<center>
<img src="results/yolo11s_gray/single/113235_gray_PM_iou.png">
</center>

<p align="center"><i>Max-IoU analysis showing the best-matching region-wise overlap for evaluation.</i></p>

---

# ğŸ“¦ Full Test Evaluation

The final section of the notebook (`N1_MS_COCO.ipynb`) enables **full validation-set evaluation**:

### âœ” Runs ShapBPT for each MS-COCO image  
### âœ” Computes and stores:
- Heatmaps  
- IoU maps  
- Prediction overlays  
- AUC/MSE curves  
- CSV summaries  

### âœ” Results are saved automatically into:
```
results/yolo11s_gray/
CSV/
```

This allows complete replication of the MS-COCO results reported in the ShapBPT paper.

