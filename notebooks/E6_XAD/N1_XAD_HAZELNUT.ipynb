{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28038e76-b496-489a-b09d-04d1a8eeec2c",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d18b6fe-34d3-4826-bff5-be5190ea63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils as ut\n",
    "import models as mdl\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings( \"ignore\", module = \"matplotlib\\..*\" )\n",
    "logging.getLogger('matplotlib').setLevel(level=logging.CRITICAL)\n",
    "logging.getLogger('tensorflow').setLevel(level=logging.FATAL)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import random,sys,importlib,keras,os,cv2,time,string,sklearn\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.15 tensorflow_addons tensorflow_probability \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de7566-6b41-4f55-9473-e22da4d21bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_current  = os.getcwd()\n",
    "if path_current.split('\\\\')[-1]=='E6_XAD':\n",
    "    print(path_current)\n",
    "    path_models = os.path.join(path_current,'models')\n",
    "    if os.path.exists(path_models):\n",
    "        path_models_VAE = os.path.join(path_models,'hazelnut_VAE_GAN_30000')\n",
    "        if os.path.exists(path_models_VAE):\n",
    "            print('-'*120)\n",
    "            print(f'Model Found ::::::: {path_models_VAE}')\n",
    "            print('-'*120)\n",
    "        else:\n",
    "            print('-'*120)\n",
    "            print(f'------ Model NOT FOUND  ------ hazelnut_VAE_GAN_30000')\n",
    "            print('-'*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f55c5-f5e3-4314-9acf-8d267b249eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tensorflow \\t\\t:\\t{tf.__version__}\")\n",
    "# use_tfp= True\n",
    "# if use_tfp:\n",
    "    # import tensorflow_probability as tfp\n",
    "    # print(f\"TensorflowProb \\t\\t:\\t{tfp.__version__}\")\n",
    "print(f\"Python \\t\\t\\t:\\t{sys.version}\")\n",
    "print(f\"Pandas \\t\\t\\t:\\t{pd.__version__}\")\n",
    "print(f\"Numpy \\t\\t\\t:\\t{np.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(f'GPU Usage\\t\\t:\\t{gpu}')\n",
    "if gpu:\n",
    "    tf.tpu.XLAOptions(\n",
    "    use_spmd_for_xla_partitioning=True, enable_xla_dynamic_padder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f90162-350c-4aae-8cfc-5ef5053ec48e",
   "metadata": {},
   "source": [
    "## Path Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da198f1-6076-406d-ad53-879a38571323",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_version = False\n",
    "path_curr = os.getcwd()\n",
    "path_notebook = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "path_supplementary = os.path.abspath(os.path.join(path_notebook, os.pardir))\n",
    "\n",
    "if submission_version:\n",
    "    DS_path_main = os.path.abspath(os.path.join(path_notebook,'dataset\\mvtec_anomaly_detection'))\n",
    "else:\n",
    "    DS_path_main = 'D:\\DS\\AD\\mvtec_anomaly_detection'\n",
    "\n",
    "DS_name = 'hazelnut'\n",
    "DS_path = os.path.join(DS_path_main,DS_name)\n",
    "\n",
    "results_path        = os.path.join(path_curr,         'results')\n",
    "path_csv            = os.path.join(results_path,          'csv')\n",
    "models_main_path    = os.path.join(path_curr,          'models')\n",
    "results_subs = os.path.join(results_path,        'test_results')\n",
    "\n",
    "print('Found:', DS_path) if os.path.exists(DS_path) else print('Not Found:', DS_path)\n",
    "print('Found:', models_main_path) if os.path.exists(models_main_path) else print('Not Found:', models_main_path)\n",
    "print('Found:', results_path) if os.path.exists(results_path) else print('Not Found:', results_path)\n",
    "print('Found:', path_csv) if os.path.exists(path_csv) else print('Not Found:', path_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbc7d58-a2e5-4d88-a50c-c9305806eed4",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557e142-12d9-4e92-97bb-f690d2dd7037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d078ba6-2336-4e48-b478-116f60a644bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dir,gtruth_dir,test_dir = ut.Data.get_subdata(DS_path=DS_path)\n",
    "\n",
    "train_dir = os.path.join(DS_path,'train')\n",
    "gtruth_dir = os.path.join(DS_path,'ground_truth2')\n",
    "test_dir = os.path.join(DS_path,'test2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a678cc-f298-4378-bb1e-f81da751a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################   GENERAL CONFIGURATION     ##################\n",
    "dpi=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe02706-4c2d-4836-8b41-71948d491c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ut)   \n",
    "codes_path = os.getcwd()\n",
    "ut.Data.path_verifier(path=results_path)\n",
    "ut.Data.path_verifier(path=results_path)\n",
    "ut.Data.path_verifier(path=models_main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3597d9-780f-4d37-a327-c735d6442d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ut)   \n",
    "anomaly_types = sorted(os.listdir(test_dir))\n",
    "anomaly_types_gt = sorted(os.listdir(gtruth_dir))\n",
    "anomaly_types,anomaly_types_gt = ut.Data.get_anomaly_types(test_dir=test_dir,\n",
    "                                                           dataset=DS_name,\n",
    "                                                           gt_dir=gtruth_dir)\n",
    "image_counter_cls = []\n",
    "for i in range(len(anomaly_types)):\n",
    "    image_counter_cls.extend([[anomaly_types[i],len(os.listdir(os.path.join(test_dir,anomaly_types[i])))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfe7a4-0205-4e85-8b2d-1332efbe6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Normal and Anamolous Data\n",
    "importlib.reload(ut)\n",
    "\n",
    "ds   = ut.Data.load_data_normal(DS_path=f'{train_dir}', batch_size=image_counter_cls[0][1])\n",
    "print('************ Loading test data ************')\n",
    "ds_a0 = ut.Data.load_data_abnormal(DS_path=f'{test_dir}/{anomaly_types[0]}', batch_size=image_counter_cls[0][1])\n",
    "ds_a1 = ut.Data.load_data_abnormal(DS_path=f'{test_dir}/{anomaly_types[1]}', batch_size=image_counter_cls[1][1])\n",
    "ds_a2 = ut.Data.load_data_abnormal(DS_path=f'{test_dir}/{anomaly_types[2]}', batch_size=image_counter_cls[2][1])\n",
    "ds_a3 = ut.Data.load_data_abnormal(DS_path=f'{test_dir}/{anomaly_types[3]}', batch_size=image_counter_cls[3][1])\n",
    "ds_a4 = ut.Data.load_data_abnormal(DS_path=f'{test_dir}/{anomaly_types[4]}', batch_size=image_counter_cls[4][1])\n",
    "\n",
    "print('************ Loading GTruth ************')\n",
    "gt_a1 = ut.Data.load_data_gtruth(DS_path=f'{gtruth_dir}/{anomaly_types[1]}', batch_size=image_counter_cls[1][1])\n",
    "gt_a2 = ut.Data.load_data_gtruth(DS_path=f'{gtruth_dir}/{anomaly_types[2]}', batch_size=image_counter_cls[2][1])\n",
    "gt_a3 = ut.Data.load_data_gtruth(DS_path=f'{gtruth_dir}/{anomaly_types[3]}', batch_size=image_counter_cls[3][1])\n",
    "gt_a4 = ut.Data.load_data_gtruth(DS_path=f'{gtruth_dir}/{anomaly_types[4]}', batch_size=image_counter_cls[4][1])\n",
    "\n",
    "ds_a = [ds_a0,ds_a1,ds_a2,ds_a3,ds_a4]\n",
    "gt_a = [ds_a0,gt_a1,gt_a2,gt_a3,gt_a4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b5eb2-6247-4bbb-8659-179551ce442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ut)\n",
    "importlib.reload(mdl)\n",
    "augmentation_target = 'custom' # 'medium', 'full' minimal , custom\n",
    "train_generator,test_generator, gtruth_generator= ut.Data2.load_data(train_dir = train_dir,\n",
    "                                                                     test_dir = test_dir,\n",
    "                                                                     gtruth_dir = gtruth_dir,\n",
    "                                                                     dataset=DS_name,\n",
    "                                                                     classes = anomaly_types,\n",
    "                                                                     augmentation_target=augmentation_target,\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c25f9-33f8-4b0e-8fa2-cecc70c7ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_counter = {class_name: len(os.listdir(os.path.join(test_dir, class_name))) for class_name in test_generator.class_indices}\n",
    "print(image_counter)\n",
    "\n",
    "min_image_count = min(image_counter.items(), key=lambda x: x[1])[1]\n",
    "min_image_class = min(image_counter.items(), key=lambda x: x[1])[0]\n",
    "print(min_image_class,min_image_count)\n",
    "from collections import Counter\n",
    "Counter(test_generator.classes)\n",
    "lbls_cls = list(image_counter.keys())\n",
    "count_cls = list(image_counter.values())\n",
    "lbls_cls,count_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34dc9cb-4e60-4def-a06f-4b202af5a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_generator.next()\n",
    "print(x.shape)\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(5,3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x[i])\n",
    "    ax.set_axis_off()\n",
    "# plt.suptitle('Augmented training dataset')\n",
    "plt.tight_layout(pad=0.20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d607405c-fbf6-4385-87e6-bd71199e023a",
   "metadata": {},
   "source": [
    "## VAE_GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5cbab-6eb0-404b-b82c-67d9210c8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=[128, 128]\n",
    "latent_dim=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70761c-049d-4c74-bd40-36a4f8dd6d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ut)\n",
    "importlib.reload(mdl)\n",
    "\n",
    "latent_dim = 32\n",
    "model_type = ['VAE_GAN']\n",
    "mdl_type = model_type[0]\n",
    "ittl = f'vae_{mdl_type}'\n",
    "\n",
    "def build_model(image_size, latent_dim):\n",
    "    encoder = mdl.Model_VAE_GAN_functions.get_encoder(latent_dim=latent_dim, print_summary=False)\n",
    "    decoder = mdl.Model_VAE_GAN_functions.get_decoder(latent_dim=latent_dim, print_summary=False)\n",
    "    discriminator = mdl.Model_VAE_GAN_functions.get_discriminator(shape=image_size + [3], print_summary=False)\n",
    "    vae = mdl.VAE(encoder, decoder)\n",
    "    model = mdl.VAE_GAN(vae, discriminator)\n",
    "    return model\n",
    "def save_model(model, prefix):\n",
    "    model.save_weights(prefix+'_model', save_format='tf')\n",
    "    model.vae.save_weights(prefix+'_vae', save_format='tf')\n",
    "    model.vae.encoder.save_weights(prefix+'_encoder', save_format='tf')\n",
    "    model.vae.decoder.save_weights(prefix+'_decoder', save_format='tf')\n",
    "    model.discriminator.save_weights(prefix+'_discriminator', save_format='tf')\n",
    "    print('Model saved.')\n",
    "def load_model(model, prefix):\n",
    "    model.load_weights(prefix+'_model')\n",
    "    model.vae.load_weights(prefix+'_vae')\n",
    "    model.vae.encoder.load_weights(prefix+'_encoder')\n",
    "    model.vae.decoder.load_weights(prefix+'_decoder')\n",
    "    model.discriminator.load_weights(prefix+'_discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548276b-d730-4a06-9418-5054f99d6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30000\n",
    "models_path = os.path.abspath(f'{models_main_path}/{DS_name}_VAE_GAN_{num_epochs}')\n",
    "print('Model Path:',models_path)\n",
    "model = build_model(image_size, latent_dim)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "history_frame = pd.DataFrame(columns=['vae_loss', 'disc_loss', 'gen_los'])\n",
    "prefix_fname = models_path + f'/{DS_name}_{mdl_type}_{num_epochs}'\n",
    "history_fname = prefix_fname + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2991ba1-8200-4b13-ae07-bfb8ba97c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(history_fname):\n",
    "    print(f'Trying Loading file: {prefix_fname}')\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "    load_model(model, prefix_fname)\n",
    "    history_frame = pd.read_csv(history_fname, sep=',')\n",
    "    print('*'*120)\n",
    "    print(f'Model Found with \\t:\\t{len(history_frame)} epochs')\n",
    "    epochs = {len(history_frame)}\n",
    "    print('*'*120)\n",
    "else:\n",
    "    print(f'Model not Found \\t:\\t{history_fname}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74066a01-9bbc-4c19-9093-6409be592e42",
   "metadata": {},
   "source": [
    "#### Train or Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4674e1-7820-41ac-99b5-2be37f140dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = False\n",
    "###############################################################\n",
    "save_weights = True\n",
    "importlib.reload(ut)\n",
    "importlib.reload(mdl)\n",
    "ittl = f'vae_{mdl_type}'\n",
    "train_batches = 5\n",
    "for bb in range(train_batches):\n",
    "    if train_model:\n",
    "        start = time.time()\n",
    "        history = model.fit(train_generator, \n",
    "                            epochs=len(history_frame) + num_epochs, \n",
    "                            initial_epoch=len(history_frame), \n",
    "                            verbose=1)\n",
    "        history_frame = pd.concat([history_frame, pd.DataFrame(history.history)], ignore_index=True)\n",
    "        print('Total training time:', time.time() - start)\n",
    "\n",
    "        if save_weights:\n",
    "            save_model(model, prefix_fname)\n",
    "            history_frame.to_csv(history_fname, sep=',', index=False)\n",
    "    else:\n",
    "        if os.path.exists(history_fname):\n",
    "            load_model(model, prefix_fname)\n",
    "            print('*'*120)\n",
    "            print(f'Model Loaded\\t:\\t {len(history_frame)}')\n",
    "            print('*'*120)\n",
    "            epochs = len(history_frame)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ae41a-7e45-4140-9323-a3e302db3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, N):\n",
    "    csum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (csum[N:] - csum[:-N]) / float(N)\n",
    "\n",
    "fig,axes = plt.subplots(3, 1, figsize=(10, 6))\n",
    "for ii, metric in enumerate(['vae_loss', 'disc_loss', 'gen_los']):\n",
    "    history_frame.loc[:, [metric]].plot(ax=axes[ii])\n",
    "    axes[ii].plot(running_mean(history_frame[metric], 20))\n",
    "axes[-1].set_xlabel('Epochs')\n",
    "plt.tight_layout(pad=0.05)\n",
    "# plt.savefig(f'{results_path}/{metric}_{mdl_type}_{epochs}_plot.png',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6590d444-0157-483c-9ea7-4a3b12cd7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(list(train_generator.next()))\n",
    "ind =20\n",
    "_, b_img = model.predict(np.array([images[ind]]), verbose=False)\n",
    "plt.subplot(131); plt.imshow(images[ind]); plt.xticks([]); plt.yticks([])\n",
    "plt.subplot(132); plt.imshow(b_img[0]);    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "diff_img = images[ind]- b_img[0]\n",
    "diff_img = np.linalg.norm(diff_img, axis=2)\n",
    "diff_img = np.square(diff_img)\n",
    "am_max = np.max(diff_img)\n",
    "\n",
    "plt.subplot(133); plt.imshow(diff_img, cmap='bwr', vmin=-am_max, vmax=am_max); plt.xticks([]); plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853e2c26-790b-44cb-afbc-b218e00f212c",
   "metadata": {},
   "source": [
    "# Anomay Map from Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ddd58c-d7f0-453b-bfd5-f9d305f859cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 2\n",
    "a_type = anomaly_types[3]\n",
    "print('Anomaly Type:\\t',a_type)\n",
    "print('Image No:\\t',img_id)\n",
    "I_A,gt = ut.Data.get_img_gt_by_index_class(anomaly_type=a_type,\n",
    "                                            data_train=ds,\n",
    "                                            data_test=ds_a,\n",
    "                                            data_gtruth=gt_a,\n",
    "                                            dataset=DS_name,\n",
    "                                            image_no2=img_id)\n",
    "zIN_mean, zIN_logvar, zIN = np.array(model.vae.encoder(np.array([I_A])))[:,0,:]\n",
    "R_A = np.array(model.vae.decoder(np.array([zIN_mean]))[0])\n",
    "plt.subplot(131);plt.imshow(I_A); plt.xticks([]); plt.yticks([]);\n",
    "plt.subplot(132);plt.imshow(R_A); plt.xticks([]); plt.yticks([]);\n",
    "\n",
    "anomaly_map = np.max(np.abs(R_A-I_A), axis=2)\n",
    "am_max = np.max(anomaly_map)\n",
    "plt.subplot(133); plt.imshow(anomaly_map, cmap='bwr', vmin=-am_max, vmax=am_max); plt.xticks([]); plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4389eca2-ec8b-4c72-9f14-2b117787b46c",
   "metadata": {},
   "source": [
    "<h2 style='color:red'> Find Anomaly Scores for Whole Test Set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf4e209-79ff-4631-a778-e79851cec169",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = 'max' # sum max\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "test_ds = { at : image_dataset_from_directory(test_dir+'/'+at, labels=None, label_mode = None,\n",
    "                                         image_size=image_size, interpolation='nearest', \n",
    "                                         batch_size=64, shuffle=False)\n",
    "           for at in anomaly_types }\n",
    "anomaly_scores = []\n",
    "test_images = [ np.array(list(test_ds[at].take(1))[0]) for at in anomaly_types ]\n",
    "for i, at in enumerate(anomaly_types):\n",
    "    print(at, len(test_images[i]))\n",
    "    z_mean, z_log_var, z = model.vae.encoder(test_images[i] / 255.0)\n",
    "    reconstruction = model.vae.decoder(z_mean)\n",
    "    if selector=='max':\n",
    "        def get_anomaly_score(i, r):\n",
    "            diff_norm = np.abs(r - i)\n",
    "            return np.max(diff_norm)\n",
    "    elif selector=='sum':\n",
    "        def get_anomaly_score(i, r):\n",
    "            diff_norm = np.abs(r - i)\n",
    "            return np.sum(diff_norm)\n",
    "    anomaly_scores.extend([(get_anomaly_score(reconstruction[j], test_images[i][j] / 255.0), \n",
    "                            at!='good', i, j,anomaly_types[i])  \n",
    "                           for j in range(len(reconstruction))])\n",
    "df_as = pd.DataFrame(anomaly_scores)\n",
    "df_as.columns =['anomaly_score_new', 'good_or_bad','a_type_id','img_no','a_type' ]\n",
    "print(np.min(df_as.anomaly_score_new),np.max(df_as.anomaly_score_new))\n",
    "df_as.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef3b18-a147-43a5-9486-fdb45b8e9b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "postfix_csv = f'{DS_name}_{epochs}_AS'\n",
    "ascsv_filename = f'{path_csv}/testresults_{postfix_csv}.csv'\n",
    "df_as.to_csv(ascsv_filename, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6958c954-7720-408a-b2cc-958b461eb0b0",
   "metadata": {},
   "source": [
    "<h2 style='color:red'> FIND Delta Opt</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75463d-5ae6-49b3-8e6f-ef1b818b8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ut)\n",
    "delta_opt = ut.Evaluate.find_optimal_separation_threshold(anomaly_scores)\n",
    "print(f'delta_opt\\t:\\t{delta_opt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7809c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f974b7a1-c289-4b05-8afb-9aea6e4fac76",
   "metadata": {},
   "source": [
    "# Load_Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da29166-67af-45c0-8824-679ce50ea7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_A = R_A = gt =y_true_flat=predicted_flat=ground_truth=binary_mask=None\n",
    "def load_image(anomaly_type=None, img_id=None):\n",
    "    global I_A,R_A,ground_truth,y_true_flat,predicted_flat,binary_mask\n",
    "    I_A,ground_truth = ut.Data.get_img_gt_by_index_class(anomaly_type=anomaly_type,\n",
    "                                               data_train=ds,\n",
    "                                               data_test=ds_a,\n",
    "                                               data_gtruth=gt_a,\n",
    "                                               dataset=DS_name,\n",
    "                                               image_no2=img_id)\n",
    "    zIN_mean, zIN_logvar, zIN = np.array(model.vae.encoder(np.array([I_A])))[:,0,:]\n",
    "    R_A = np.array(model.vae.decoder(np.array([zIN_mean]))[0])\n",
    "    predicted_flat  = np.linalg.norm(I_A - R_A, axis=2).flatten()\n",
    "    \n",
    "    y_true_flat = (ground_truth[:,:,0]!=0).flatten()\n",
    "    binary_mask = ground_truth[:,:,0].astype(np.uint8)\n",
    "    del zIN_mean,zIN_logvar,zIN\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls_cls, count_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35609cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524cda1c-3e01-4f52-849c-550e370c411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_class = lbls_cls[1]\n",
    "img_id = 17\n",
    "\n",
    "print('anomaly_class: \\t',a_class)\n",
    "print('Image no: \\t',img_id)\n",
    "\n",
    "load_image(anomaly_type=a_class, img_id=img_id)\n",
    "plt.subplot(131);plt.imshow(I_A); plt.xticks([]);plt.yticks([]);\n",
    "plt.subplot(132);plt.imshow(R_A); plt.xticks([]);plt.yticks([]);\n",
    "plt.subplot(133);plt.imshow((ground_truth[:,:,0]), cmap='binary'); \n",
    "plt.xticks([]);plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db132a18-6122-4e88-90b5-076105c71759",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask_tp = None\n",
    "def get_mask(mask_type='blend_2'):\n",
    "    global mask,mask_tp\n",
    "    if mask_type=='blend_2':\n",
    "        mask = I_A*0.5+R_A*0.5\n",
    "        mask_tp = f\"x+x\\'\"\n",
    "    elif mask_type=='blend_3':\n",
    "            mask = I_A*0.33+R_A*0.33 + gt * 0.34\n",
    "            mask_tp = f\"x+x\\'+gt\"\n",
    "    elif mask_type=='input':\n",
    "            mask = I_A\n",
    "            mask_tp = f\"x+x\\'+gt\"\n",
    "    elif mask_type=='reconstructed':\n",
    "            mask = R_A\n",
    "            mask_tp = f\"x\\'\"\n",
    "get_mask(mask_type='blend_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8902bcd7-9f04-433a-80b8-d93f3a625983",
   "metadata": {},
   "source": [
    "# XAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75182836-ca70-49be-83aa-34fd887543e1",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e83086-e9fe-45c1-affc-ac6eaa42ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import shap_bpt\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "# LIME \n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "from lime.lime_image import LimeImageExplainer\n",
    "import skimage\n",
    "from skimage.segmentation import quickshift\n",
    "## \n",
    "from skimage.segmentation import mark_boundaries\n",
    "#\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.rc('text', usetex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6e56b8-5b3c-4f4e-9757-0acd85a90b7d",
   "metadata": {},
   "source": [
    "# Default Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaab7c8-8288-4ac4-9bfa-25b1ad32d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_explained_classes = 1\n",
    "batch_size = 16\n",
    "num_samples= 500\n",
    "verbose=True\n",
    "\n",
    "run_partial_test = False \n",
    "# run_partial_test = True\n",
    "evaluate_explanation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5a13a-69c7-4d2e-9f39-0bde1c118052",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec94cd72-e3a6-4013-9a18-17740455c604",
   "metadata": {},
   "source": [
    "## Loss Function for XAI METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4ecb1-225b-4f57-b8b8-a8cd8824d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From \"General Frameworks for Anomaly Detection Explainability: A comparative study\"\n",
    "importlib.reload(ut)\n",
    "from keras import backend as K\n",
    "def mean_predict(model, data):\n",
    "    z_mean, z_log_var, z = model.vae.encoder(data)\n",
    "    reconstruction = model.vae.decoder(z_mean)\n",
    "    return reconstruction\n",
    "def lime_predict_loss(data, verbose=False):\n",
    "    global model\n",
    "    batch_size = K.shape(data)[0]\n",
    "    reconstruction = mean_predict(model, data)\n",
    "    MSE_loss = tf.reduce_sum(tf.square(reconstruction - data), axis=[1,2,3])\n",
    "    return np.array([ [l] for l in MSE_loss ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fecf12-6b4f-420d-b299-00724e681856",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_functions     = [lime_predict_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f71a6-a8b7-455f-856b-7e85f576db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array([I_A])\n",
    "print('lime_predict_loss\\t\\t',lime_predict_loss(img)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b91fca6-558b-4ed0-a61d-54cc6253b223",
   "metadata": {},
   "source": [
    "## Saliency_to_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10494e75-a0ea-455e-8c22-1d78d22ae649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def saliency_to_auc(heatmap, batch_size=4, method='del', num_samples=101, add_noise= True):\n",
    "#     assert len(heatmap.shape)==2 and heatmap.dtype in (float, np.float64, np.float32)\n",
    "#     if add_noise:\n",
    "#         rng = np.random.default_rng(12345)\n",
    "#         heatmap = heatmap + rng.normal(0.0, 0.000000001, size=heatmap.shape)\n",
    "    \n",
    "#     xs, ys, ms, masks, qs = [], [], [], [], []\n",
    "#     #heatmap = gaussian(heatmap, 2.0)\n",
    "#     for i in np.linspace(start=1.0, stop=0.0, num=num_samples):\n",
    "#         if method=='del':\n",
    "#             epsilon = (1 if i==0.0 else 0)\n",
    "#             q = (np.quantile(heatmap, q=i) - epsilon)\n",
    "#             m = heatmap <= q\n",
    "#             nx = (1.0 - np.sum(m) / m.size)\n",
    "#         elif method=='ins':\n",
    "#             epsilon = (1 if i==1.0 else 0)\n",
    "#             q = (np.quantile(heatmap, q=i) + epsilon)\n",
    "#             m = heatmap >= q\n",
    "#             nx = (np.sum(m) / m.size)\n",
    "#         else:\n",
    "#             raise Exception()\n",
    "            \n",
    "#         if len(xs)==0 or nx != xs[-1]:\n",
    "#             xs.append(nx)\n",
    "#             masks.append(m)\n",
    "#             ms.append(np.sum(heatmap[m]))\n",
    "#             qs.append(q)\n",
    "#             if len(masks) >= batch_size:\n",
    "#                 y = shap_bpt_masked_model(np.array(masks))[:, 0]\n",
    "#                 ys.extend(y)\n",
    "#                 masks = []\n",
    "\n",
    "#     if len(masks) > 0:\n",
    "#         y = shap_bpt_masked_model(np.array(masks))[:, 0]\n",
    "#         ys.extend(y)\n",
    "    \n",
    "#     xs, ys = np.array(xs), np.array(ys)\n",
    "#     auc_reg, auc_eff, auc_mse = 0.0, 0.0, 0.0\n",
    "#     assert(len(xs) == len(ys))\n",
    "#     # compute the area under the curve - use the rectangle method\n",
    "#     for i in range(1, len(xs)):\n",
    "#         delta_x = abs(xs[i] - xs[i-1])\n",
    "#         if delta_x > 0:\n",
    "#             auc_reg += abs(delta_x * 0.5*(ys[i-1] + ys[i])) # base  height\n",
    "#             auc_eff += abs(delta_x * 0.5*(ys[i-1] + ys[i] - ms[i-1] - ms[i])) # base *  height\n",
    "#             auc_mse += abs(delta_x * 0.5*(ys[i-1] + ys[i] - ms[i-1] - ms[i])**2) # base  height^2\n",
    "\n",
    "#     # return xs, ys, ms, auc_reg, auc_eff, auc_mse\n",
    "#     return {'xs':xs, 'ys':ys, 'ms':ms, 'qs':qs, 'auc_reg':auc_reg, 'auc_eff':auc_eff, 'auc_mse':auc_mse,'method':method}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c242060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_groundtruth_explanation(gtruth, heatmap, threshold):\n",
    "    if gtruth.ndim == 3:\n",
    "        gt = gtruth[:,:,0]>0\n",
    "    else:\n",
    "        gt = gtruth[:,:]>0\n",
    "    ht = (heatmap >= threshold).astype(np.uint8)\n",
    "    img = np.zeros(shape=list(heatmap.shape)+[3], dtype=np.uint8)\n",
    "    img[:,:,0] = 255*(1-gt)\n",
    "    img[:,:,1] = 255*(1-ht)\n",
    "    img[:,:,2] = 255*(1-ht)\n",
    "    return img\n",
    "def calc_IoU_curve(y_true, y_pred, add_noise=True):\n",
    "    \n",
    "    assert isinstance(y_true, np.ndarray)\n",
    "    assert isinstance(y_pred, np.ndarray)\n",
    "    assert len(y_true.shape)==1 and len(y_pred.shape)==1 # assumes y_true and y_pred to be flattened arrays\n",
    "    assert len(y_true)==len(y_pred)\n",
    "    assert y_true.dtype==np.dtype('bool') and np.issubdtype(y_pred.dtype, np.floating)\n",
    "    if add_noise:\n",
    "        rng = np.random.default_rng(12345)\n",
    "        y_pred = y_pred + rng.normal(0.0, 0.000000001, size=y_pred.shape)\n",
    "\n",
    "    yd = np.array(sorted(zip(y_pred, y_true), reverse=True))\n",
    "    X2   = np.zeros(len(y_pred))\n",
    "    IoU2 = np.zeros(len(y_pred))\n",
    "    Th   = np.zeros(len(y_pred))\n",
    "    \n",
    "    nT = np.sum(y_true)\n",
    "    nInt = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if yd[i,1]: \n",
    "            nInt += 1\n",
    "        \n",
    "        IoU2[i] = nInt / (i + nT - nInt)\n",
    "        X2[i] = i\n",
    "        Th[i] = yd[i,0]\n",
    "        \n",
    "    X2 = X2 / len(y_pred)\n",
    "    auc_IoU = 0\n",
    "    for i in range(1, len(y_pred)):\n",
    "        auc_IoU += (X2[i] - X2[i-1]) * (IoU2[i] + IoU2[i-1]) / 2.0\n",
    "    \n",
    "    best_pt = np.argmax(IoU2)\n",
    "    \n",
    "    if np.sum(y_pred) == 0:\n",
    "        return X2, np.zeros_like(X2), Th[best_pt], X2[best_pt], 0\n",
    "    else:\n",
    "        return X2, IoU2, Th[best_pt], X2[best_pt], auc_IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33535af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def saliency_to_auc(f_masked,heatmap, f_S, f_0, predicted_cls, batch_size=4, method='del', num_samples=101, \n",
    "#                     rule='trapezoid'):\n",
    "\n",
    "#     # print(f'Computing AUC with method={method}, batch_size={batch_size}, num_samples={num_samples}, rule={rule}')\n",
    "#     # print('from saliency_to_auc',heatmap.shape, heatmap.dtype, heatmap.min(), heatmap.max())\n",
    "#     assert isinstance(heatmap, np.ndarray)\n",
    "#     assert len(heatmap.shape)==2 and np.issubdtype(heatmap.dtype, np.floating)\n",
    "\n",
    "#     nu_max = max(f_S, f_0)\n",
    "#     nu_min = min(f_S, f_0)\n",
    "\n",
    "#     xs, ys, ms, masks, qs = [], [], [], [], []\n",
    "#     for i, value in enumerate(np.linspace(start=1.0, stop=0.0, num=num_samples)):\n",
    "#         if method=='del':\n",
    "#             epsilon = (1 if value==0.0 else 0)\n",
    "#             q = (np.quantile(heatmap, q=value) - epsilon)\n",
    "#             m = heatmap <= q\n",
    "#             nx = (1.0 - np.sum(m) / m.size)\n",
    "#         elif method=='ins':\n",
    "#             epsilon = (1 if value==1.0 else 0)\n",
    "#             q = (np.quantile(heatmap, q=value) + epsilon)\n",
    "#             m = heatmap >= q\n",
    "#             nx = (np.sum(m) / m.size)\n",
    "#         else:\n",
    "#             raise Exception()\n",
    "            \n",
    "#         # add a new datapoint on the curve\n",
    "#         if len(xs)==0 or nx != xs[-1]: \n",
    "#             assert m.dtype==bool and len(m.shape)==2\n",
    "#             xs.append(nx)\n",
    "#             masks.append(m)\n",
    "#             ms.append(np.sum(heatmap[m]))\n",
    "#             qs.append(q)\n",
    "\n",
    "#         # evaluate the characteristic function\n",
    "#         if len(masks) >= batch_size or (len(masks)>0 and i==(num_samples-1)):\n",
    "#             y = f_masked(np.array(masks))[:, predicted_cls]\n",
    "#             ys.extend(y)\n",
    "#             masks = []\n",
    "\n",
    "#     assert len(masks)==0    \n",
    "#     xs, ys = np.array(xs), np.array(ys)\n",
    "#     assert(len(xs) == len(ys))\n",
    "\n",
    "#     # compute considering under/over shoots\n",
    "#     overshoot_max = np.maximum(0, ys - nu_max) # overshoot for values exceeding the maximum\n",
    "#     overshoot_min = np.maximum(0, nu_min - ys) # overshoot for values below the minimum\n",
    "#     # adjust ys with the overshoot. Clip it inside the admitted range\n",
    "#     y_adjusted = np.clip(ys - 2*overshoot_max + 2*overshoot_min, nu_min, nu_max)\n",
    "\n",
    "#     # rescaling\n",
    "#     ys_rescaled = (ys - nu_min) / (nu_max - nu_min)\n",
    "#     y_adjusted_rescaled = (y_adjusted - nu_min) / (nu_max - nu_min)\n",
    "\n",
    "#     auc, auc_r, auc_mae, auc_mse, auc_adj, auc_adjr = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "#     curve_range = range(1, len(xs)) if rule=='trapezoid' else range(len(xs))\n",
    "\n",
    "#     # compute the area under the curve with the midpoint Riemann sum (i.e. the trapezoidal rule)\n",
    "#     for i in curve_range:\n",
    "#         if rule=='trapezoid':\n",
    "#             delta_x = abs(xs[i] - xs[i-1])\n",
    "#             assert delta_x > 0\n",
    "#             y_mid   =         0.5*(ys[i-1] + ys[i])\n",
    "#             y_r_mid =         0.5*(ys_rescaled[i-1] + ys_rescaled[i])\n",
    "#             err_mid = y_mid - 0.5*(ms[i-1] - ms[i])\n",
    "#             y_adj_mid =       0.5*(y_adjusted[i-1] + y_adjusted[i])\n",
    "#             y_adjr_mid =      0.5*(y_adjusted_rescaled[i-1] + y_adjusted_rescaled[i])\n",
    "#         else: # rectangles\n",
    "#             delta_x = 1.0/num_samples if i==len(xs)-1 else abs(xs[i+1] - xs[i])\n",
    "#             assert delta_x > 0\n",
    "#             y_mid   =         ys[i]\n",
    "#             y_r_mid =         ys_rescaled[i]\n",
    "#             err_mid = y_mid - ms[i]\n",
    "#             y_adj_mid =       y_adjusted[i]\n",
    "#             y_adjr_mid =      y_adjusted_rescaled[i]\n",
    "\n",
    "\n",
    "#         auc += abs(delta_x * y_mid) # base * height\n",
    "#         auc_r += abs(delta_x * y_r_mid) # base * height\n",
    "#         # auc_eff += abs(delta_x * err_mid) # base * height\n",
    "#         auc_mae += abs(delta_x * err_mid) # base * height\n",
    "#         auc_mse += abs(delta_x * (err_mid**2)) # base * height^2\n",
    "#         auc_adj += abs(delta_x * y_adj_mid)\n",
    "#         auc_adjr += abs(delta_x * y_adjr_mid)\n",
    "\n",
    "#     return {'xs':xs, 'ys':ys, 'ms':ms, 'qs':qs, 'ysr':ys_rescaled,\n",
    "#             'y_adj':y_adjusted, 'y_adjr':y_adjusted_rescaled, \n",
    "#             'method':method, #'class_id':class_id,\n",
    "#             'auc':auc, 'auc_r':auc_r, #'auc_eff':auc_eff, \n",
    "#             'auc_mae':auc_mae, 'auc_mse':auc_mse, 'auc_rmse':np.sqrt(auc_mse), \n",
    "#             'auc_adj':auc_adj, 'auc_adjr':auc_adjr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5754eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_to_auc(nu, heatmap, f_S, f_0, predicted_cls, batch_size=4, method='del', num_samples=101, \n",
    "                    rule='trapezoid'):\n",
    "    assert isinstance(heatmap, np.ndarray)\n",
    "    assert len(heatmap.shape)==2 and np.issubdtype(heatmap.dtype, np.floating)\n",
    "\n",
    "    # nu_max = max(f_S, f_0)\n",
    "    # nu_min = min(f_S, f_0)\n",
    "\n",
    "    xs, ys, ms, masks, qs = [], [], [], [], []\n",
    "    for i, value in enumerate(np.linspace(start=1.0, stop=0.0, num=num_samples)):\n",
    "        if method=='del':\n",
    "            epsilon = (1 if value==0.0 else 0)\n",
    "            q = (np.quantile(heatmap, q=value) - epsilon)\n",
    "            m = heatmap <= q\n",
    "            nx = (1.0 - np.sum(m) / m.size)\n",
    "        elif method=='ins':\n",
    "            epsilon = (1 if value==1.0 else 0)\n",
    "            q = (np.quantile(heatmap, q=value) + epsilon)\n",
    "            m = heatmap >= q\n",
    "            nx = (np.sum(m) / m.size)\n",
    "        else:\n",
    "            raise Exception()\n",
    "            \n",
    "        # add a new datapoint on the curve\n",
    "        if len(xs)==0 or nx != xs[-1]: \n",
    "            assert m.dtype==bool and len(m.shape)==2\n",
    "            xs.append(nx)\n",
    "            masks.append(m)\n",
    "            ms.append(np.sum(heatmap[m]))\n",
    "            qs.append(q)\n",
    "\n",
    "        # evaluate the characteristic function\n",
    "        if len(masks) >= batch_size or (len(masks)>0 and i==(num_samples-1)):\n",
    "            y = nu(np.array(masks))[:, predicted_cls]\n",
    "            ys.extend(y)\n",
    "            masks = []\n",
    "\n",
    "    assert len(masks)==0    \n",
    "    xs, ys = np.array(xs), np.array(ys)\n",
    "    assert(len(xs) == len(ys))\n",
    "\n",
    "    # compute considering under/over shoots\n",
    "    if f_S > f_0:\n",
    "        overshoot_max = np.maximum(0, ys - f_S) # overshoot for values exceeding the maximum f(S)\n",
    "        overshoot_min = np.maximum(0, f_0 - ys) # overshoot for values below the minimum f(0)\n",
    "    else: # f(S) < f(0)\n",
    "        overshoot_max = np.maximum(0, ys - f_0) # overshoot for values exceeding the maximum f(0)\n",
    "        overshoot_min = np.maximum(0, f_S - ys) # overshoot for values below the minimum f(S)\n",
    "\n",
    "    # clip ys, no oveshoots\n",
    "    y_clipped = np.clip(ys, min(f_S, f_0), max(f_S, f_0))\n",
    "    # adjust ys with the overshoot. Clip it inside the admitted range\n",
    "    y_adjusted = np.clip(ys - 2*overshoot_max + 2*overshoot_min, min(f_S, f_0), max(f_S, f_0))\n",
    "\n",
    "    # rebase to f(0)\n",
    "    if f_S > f_0:\n",
    "        flipped = False\n",
    "        ys = ys - f_0 \n",
    "        y_clipped = y_clipped - f_0 \n",
    "        y_adjusted = y_adjusted - f_0\n",
    "    else: # f(S) < f(0)\n",
    "        flipped = True\n",
    "        ys = f_0 - ys \n",
    "        y_clipped = f_0 - y_clipped \n",
    "        y_adjusted = f_0 - y_adjusted\n",
    "\n",
    "    # rescaling\n",
    "    ys_rescaled = ys / abs(f_S - f_0)\n",
    "    y_clipped_rescaled = y_clipped / abs(f_S - f_0)\n",
    "    y_adjusted_rescaled = y_adjusted / abs(f_S - f_0)\n",
    "\n",
    "    auc, auc_r, auc_mae, auc_mse, auc_adj, auc_adjr, auc_clip, auc_clipr = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    curve_range = range(1, len(xs)) if rule=='trapezoid' else range(len(xs))\n",
    "\n",
    "    # compute the area under the curve with the midpoint Riemann sum (i.e. the trapezoidal rule)\n",
    "    for i in curve_range:\n",
    "        if rule=='trapezoid':\n",
    "            delta_x = abs(xs[i] - xs[i-1])\n",
    "            assert delta_x > 0\n",
    "            y_mid   =         0.5*(ys[i-1] + ys[i])\n",
    "            y_r_mid =         0.5*(ys_rescaled[i-1] + ys_rescaled[i])\n",
    "            err_mid = y_mid - 0.5*(ms[i-1] - ms[i])\n",
    "            y_clip_mid =       0.5*(y_clipped[i-1] + y_clipped[i])\n",
    "            y_clipr_mid =      0.5*(y_clipped_rescaled[i-1] + y_clipped_rescaled[i])\n",
    "            y_adj_mid =       0.5*(y_adjusted[i-1] + y_adjusted[i])\n",
    "            y_adjr_mid =      0.5*(y_adjusted_rescaled[i-1] + y_adjusted_rescaled[i])\n",
    "        else: # rectangles\n",
    "            delta_x = 1.0/num_samples if i==len(xs)-1 else abs(xs[i+1] - xs[i])\n",
    "            assert delta_x > 0\n",
    "            y_mid   =         ys[i]\n",
    "            y_r_mid =         ys_rescaled[i]\n",
    "            err_mid = y_mid - ms[i]\n",
    "            y_clip_mid =       y_clipped[i]\n",
    "            y_clipr_mid =      y_clipped_rescaled[i]\n",
    "            y_adj_mid =       y_adjusted[i]\n",
    "            y_adjr_mid =      y_adjusted_rescaled[i]\n",
    "\n",
    "\n",
    "        auc += abs(delta_x * y_mid) # base * height\n",
    "        auc_r += abs(delta_x * y_r_mid) # base * height\n",
    "        # auc_eff += abs(delta_x * err_mid) # base * height\n",
    "        auc_mae += abs(delta_x * err_mid) # base * height\n",
    "        auc_mse += abs(delta_x * (err_mid**2)) # base * height^2\n",
    "        auc_clip += abs(delta_x * y_clip_mid)\n",
    "        auc_clipr += abs(delta_x * y_clipr_mid)\n",
    "        auc_adj += abs(delta_x * y_adj_mid)\n",
    "        auc_adjr += abs(delta_x * y_adjr_mid)\n",
    "\n",
    "    return {'xs':xs, 'ms':ms, 'qs':qs, \n",
    "            'f_0':f_0, 'f_S':f_S, 'flipped':flipped, \n",
    "            'ys':ys, 'ysr':ys_rescaled,\n",
    "            'y_clip':y_clipped, 'y_clipr':y_clipped_rescaled, \n",
    "            'y_adj':y_adjusted, 'y_adjr':y_adjusted_rescaled, \n",
    "            'method':method, 'predicted_cls':predicted_cls,\n",
    "            'auc':auc, 'auc_r':auc_r,\n",
    "            'auc_mae':auc_mae, 'auc_mse':auc_mse, 'auc_rmse':np.sqrt(auc_mse), \n",
    "            'auc_clip':auc_clip, 'auc_clipr':auc_clipr,\n",
    "            'auc_adj':auc_adj, 'auc_adjr':auc_adjr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758c24f-1f1d-4f20-a1f2-d0b69302c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(feat_importance=None, plt=None):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    vm = np.max(np.abs(feat_importance))\n",
    "    plt.imshow(feat_importance, vmin = -vm, vmax = vm, cmap=shap_bpt.shapley_values_colormap)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee3017-4114-4e58-a49a-1a53dbb052da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_predict_loss(np.expand_dims(I_A,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328283b8-e3ef-45a3-8490-3a27e374d1f0",
   "metadata": {},
   "source": [
    "# ShapBPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb9591-94d1-4f92-b46f-49b969a2302a",
   "metadata": {},
   "source": [
    "## Shap_AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf82f0-1873-4f49-bf28-c48c7b94d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_bpt_masked_model(masks):\n",
    "    X = []\n",
    "    for m in masks:\n",
    "        m3 = m\n",
    "        img = R_A.copy()\n",
    "        img[m3] = I_A[m3]\n",
    "        X.append(img)\n",
    "    return np.array(lime_predict_loss(np.array(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77467b-3dc8-4a0f-8b2d-123ede278672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aa_heatmaps(num_samples=100,verbose=False):\n",
    "    explainer = shap_bpt.Explainer(shap_bpt_masked_model, I_A, num_explained_classes=num_explained_classes, verbose=verbose)\n",
    "    shap_values_aa = explainer.explain_instance(num_samples, method='AA', verbose_plot=False, \n",
    "                                                batch_size=batch_size)\n",
    "    return shap_values_aa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544cafed-99ab-4024-9aed-bc42e6dfe85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_partial_test:\n",
    "    heatmap_shap = get_aa_heatmaps(num_samples=num_samples,verbose=True)\n",
    "    \n",
    "    plot_feature_importance(feat_importance=heatmap_shap,plt=plt)\n",
    "    AUCD = saliency_to_auc(heatmap_shap, method='del', batch_size=batch_size)\n",
    "    AUCI = saliency_to_auc(heatmap_shap, method='ins', batch_size=batch_size)\n",
    "    plt.figure(figsize=(4.5,2))\n",
    "    plt.subplot(121);plt.plot(AUCD['xs'],AUCD['ys']);plt.xticks([]);plt.yticks([]);plt.title('del curve');\n",
    "    plt.subplot(122);plt.plot(AUCI['xs'],AUCI['ys']);plt.xticks([]);plt.yticks([]);plt.title('ins curve');plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c17308-572e-4868-bda1-84c013e4066f",
   "metadata": {},
   "source": [
    "## Shap_BPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699cc8d0-6e56-46b2-8798-4a4d76ab1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_bpt_explainer = shap_bpt.Explainer(shap_bpt_masked_model, I_A, num_explained_classes=num_explained_classes, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd25a7-9852-4746-a8c0-d7b22d64a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bpt_heatmaps(num_samples=100,verbose=False):\n",
    "    bpt = shap_bpt.build_bpt_from_image((I_A*255).astype('uint8'))\n",
    "    explainer = shap_bpt.Explainer(shap_bpt_masked_model, I_A, num_explained_classes=num_explained_classes, verbose=verbose)\n",
    "    shap_values_bpt = explainer.explain_instance(num_samples, method='BPT',\n",
    "                                             batch_size=batch_size,bpt=bpt)\n",
    "    return shap_values_bpt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867206e5-7e70-479e-aa70-e954c011b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_partial_test:\n",
    "    heatmap_shapbpt = get_bpt_heatmaps(num_samples=num_samples,verbose=True)\n",
    "    \n",
    "    plot_feature_importance(feat_importance=heatmap_shapbpt,plt=plt)\n",
    "    # AUCD = {}\n",
    "    AUCD = saliency_to_auc(heatmap_shapbpt, method='del', batch_size=batch_size)\n",
    "    # AUCD = {}\n",
    "    AUCI = saliency_to_auc(heatmap_shapbpt, method='ins', batch_size=batch_size)\n",
    "    plt.figure(figsize=(4.5,2))\n",
    "    plt.subplot(121);plt.plot(AUCD['xs'],AUCD['ys']);plt.xticks([]);plt.yticks([]); plt.title('del curve')\n",
    "    plt.subplot(122);plt.plot(AUCI['xs'],AUCI['ys']);plt.xticks([]);plt.yticks([]); plt.title('ins curve');plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3aa0bb-34dd-41a6-b439-24cfeb32d9c8",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc6e52-21e9-4370-b9a5-f632c1a8529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_number(image, md):\n",
    "    segments = quickshift(image, kernel_size=2, max_dist=md, ratio=0.95, rng=1234, sigma=0.05) \n",
    "    # segments = quickshift(image, kernel_size=2, max_dist=md, ratio=0.8, rng=1234, sigma=0.25) \n",
    "    return len(np.unique(segments)), segments\n",
    "\n",
    "def search_segment_number(image, target_seg_no, init_max_dist=100):\n",
    "    lmd, rmd = 0, init_max_dist\n",
    "    lsn, _ = get_segment_number(image, lmd)\n",
    "    rsn, _ = get_segment_number(image, rmd)\n",
    "    niter = 0\n",
    "    while niter<40 and rsn!=target_seg_no:\n",
    "        niter += 1\n",
    "        mmd = (lmd + rmd) / 2.0\n",
    "        msn, _ = get_segment_number(image, mmd)\n",
    "        if msn <= target_seg_no <= lsn:\n",
    "            rsn, rmd = msn, mmd\n",
    "        else:\n",
    "            lsn, lmd = msn, mmd\n",
    "    return get_segment_number(image, rmd) #rmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14514e94-cfbc-42fd-a095-82ac6df145a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_functions = [lime_predict_loss]\n",
    "score_function =score_functions[0]\n",
    "score_function_name = f'{score_function.__name__}'\n",
    "score_function_name = score_function_name.replace('lime_predicter_', 'lm_p_')\n",
    "score_function_name = score_function_name.replace('lime_predict_', 'lm_p_')\n",
    "score_function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d6486-dd89-4521-9330-87ac50aba2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = None\n",
    "def format_lime_heatmaps(segments, expl):\n",
    "    global predicted_fS, predicted_f0\n",
    "    class_heatmaps = []\n",
    "    heatmap = np.zeros_like(segments, dtype=np.float32)\n",
    "    for segm, importance in expl.local_exp[expl.top_labels[0]]:\n",
    "        heatmap[ segments==segm ] += importance \n",
    "    return np.array(heatmap)\n",
    "def get_heatmaps_lime(num_samples=100,num_segments=100,verbose=False):\n",
    "    global beta\n",
    "    segs,segments = search_segment_number(mask,target_seg_no=num_segments)\n",
    "    def segments_getter(img):\n",
    "        return segments\n",
    "    # score_function_name = f'{score_function.__name__}'\n",
    "    # score_function_name = score_function_name.replace('lime_predicter_', 'lm_p_')\n",
    "    # score_function_name = score_function_name.replace('lime_predict_', 'lm_p_')\n",
    "    lime_explainer = LimeImageExplainer(random_state=1234)\n",
    "    st = time.time()\n",
    "    \n",
    "    explanation = lime_explainer.explain_instance(I_A, score_functions[0],\n",
    "                                                  labels = [a_type],\n",
    "                                                  segmentation_fn=segments_getter,\n",
    "                                                  hide_color=R_A,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  num_samples=num_samples,\n",
    "                                                 progress_bar=verbose\n",
    "                                                 )\n",
    "    if isinstance(explanation, tuple):\n",
    "        explanation = explanation[2]\n",
    "    # beta = ut.Explanation.get_beta_from_expl(explanation)\n",
    "    heatmap_lime = format_lime_heatmaps(segments, explanation)\n",
    "    beta = ut.Explanation.get_beta_from_expl(explanation)\n",
    "    return heatmap_lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ab8b3-d3d0-451d-9805-06eba73c96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_partial_test:\n",
    "    heatmap_lime = get_heatmaps_lime(num_samples=num_samples, verbose=True)\n",
    "    plot_feature_importance(feat_importance=heatmap_lime,plt=plt)\n",
    "    AUCD = saliency_to_auc(heatmap_lime, method='del', batch_size=batch_size)\n",
    "    AUCI = saliency_to_auc(heatmap_lime, method='ins', batch_size=batch_size)\n",
    "    plt.figure(figsize=(4.5,2))\n",
    "    plt.subplot(121);plt.plot(AUCD['xs'],AUCD['ys']);plt.xticks([]);plt.yticks([]);plt.title('del curve');\n",
    "    plt.subplot(122);plt.plot(AUCI['xs'],AUCI['ys']);plt.xticks([]);plt.yticks([]);plt.title('ins curve');plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7511ebc8-666d-489b-88d2-d4a55f6bd429",
   "metadata": {},
   "source": [
    "## PLOT OWEN VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6632781-8a5e-4b33-9db1-928dc79369a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_partial_test:\n",
    "    shap_bpt_explainer = shap_bpt.Explainer(shap_bpt_masked_model, I_A, num_explained_classes=num_explained_classes, verbose=verbose)\n",
    "    shap_bpt.plot_owen_values(shap_bpt_explainer, [np.expand_dims(heatmap_shapbpt,axis= 0),\n",
    "                                                   np.expand_dims(heatmap_shap, axis= 0),\n",
    "                                                   np.expand_dims(heatmap_lime,axis= 0)],\n",
    "                              [a_type],\n",
    "                              names=['ShapBPT','ShapAA','LIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3143b9d2-6887-4bc8-8e65-010e8bd64d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_partial_test:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(161);plt.imshow(I_A);          plt.xticks([]);plt.yticks([]);\n",
    "    plt.subplot(162);plt.imshow(R_A);          plt.xticks([]);plt.yticks([]);\n",
    "    plt.subplot(163);plt.imshow(ground_truth);  plt.xticks([]);plt.yticks([]);\n",
    "    plt.subplot(164);plt.imshow(heatmap_shapbpt, vmin=-np.max(np.abs(heatmap_shapbpt)), vmax=np.max(np.abs(heatmap_shapbpt)), cmap=shap_bpt.shapley_values_colormap); \n",
    "    plt.xticks([]);plt.yticks([]);\n",
    "    plt.subplot(165);plt.imshow(heatmap_shap, vmin=-np.max(np.abs(heatmap_shap)), vmax=np.max(np.abs(heatmap_shap)), cmap=shap_bpt.shapley_values_colormap); \n",
    "    plt.xticks([]);plt.yticks([]);\n",
    "    plt.subplot(166);plt.imshow(heatmap_lime, vmin=-np.max(np.abs(heatmap_lime)), vmax=np.max(np.abs(heatmap_lime)), cmap=shap_bpt.shapley_values_colormap); \n",
    "    plt.xticks([]);plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af85fb1-df7b-4606-9a04-2dd492d419c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_map = am_max = None\n",
    "def get_anomaly_map_score():\n",
    "    global anomaly_map,am_max\n",
    "    anomaly_map = np.max(np.abs(R_A-I_A), axis=2)\n",
    "    am_max = np.max(anomaly_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5808b8c-c186-49bc-9b97-c7734472e264",
   "metadata": {},
   "source": [
    "# Combining All Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473642c-c456-4e6b-a9ea-1ed8c3796c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "\n",
    "methods = [\n",
    "    ('BPT-100',         'xkcd:light pink',      partial(get_bpt_heatmaps, num_samples=100,verbose=verbose)),\n",
    "    ('BPT-500',         'xkcd:light pink',      partial(get_bpt_heatmaps, num_samples=500,verbose=verbose)),\n",
    "    ('BPT-1000',         'xkcd:light pink',      partial(get_bpt_heatmaps, num_samples=1000,verbose=verbose)),\n",
    "\n",
    "    ('AA-100',          'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=100, verbose=verbose)),\n",
    "    ('AA-500',          'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=500, verbose=verbose)),\n",
    "    ('AA-1000',         'xkcd:bright blue',     partial(get_aa_heatmaps, num_samples=1000, verbose=verbose)),\n",
    "    \n",
    "    ('LIME-100',        'xkcd:bright lime',     partial(get_heatmaps_lime, num_segments=20, num_samples=100,verbose=verbose)),\n",
    "    ('LIME-500',        'xkcd:bright lime',     partial(get_heatmaps_lime, num_segments=100, num_samples=500,verbose=verbose)),\n",
    "    ('LIME-1000',        'xkcd:bright lime',     partial(get_heatmaps_lime, num_segments=200, num_samples=1000,verbose=verbose)),\n",
    "]\n",
    "for n,_,_ in methods:\n",
    "    print(n)\n",
    "\n",
    "methods_ls = [x for x,_,_ in methods ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d123d1-4024-4984-8398-a5085eefa1cf",
   "metadata": {},
   "source": [
    "## Functions for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e194c-1b32-4706-a935-fc28ff9f15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_save_figure(img=None,type_groundtruth=False, destroy_fig=True,save_fig=True,fname=None,transparent=True,dpi=250):\n",
    "    fig=plt.figure(figsize=(2,2))\n",
    "    if type_groundtruth:\n",
    "        # ground_truth[:,:,0]), cmap='binary'\n",
    "        plt.imshow(img[:,:,0], cmap='binary')    \n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    if save_fig:\n",
    "        plt.savefig(fname,dpi=dpi, transparent=transparent, bbox_inches = 'tight')\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "    plt.show()\n",
    "###################################################################################\n",
    "def draw_plot_gt(I_A,ground_truth):\n",
    "    contoured_image = I_A.copy()\n",
    "    contoured_image = ut.Data.draw_gt_contour(groundtruth_image=ground_truth,input_image=I_A)\n",
    "    binary_mask = ground_truth[:,:,0].astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(contoured_image, contours, -1, (255, 255, 0), 1)  # (0, 255, 255) corresponds to yellow, 2 is the thickness\n",
    "    return contoured_image\n",
    "###################################################################################\n",
    "def draw_heatmaps(feat_import=None,ground_truth=None,save_fig=True,fname=None,figsize=(2,2),dpi=250, transparent=True,destroy_fig=True):\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    vmax = np.quantile(np.abs(feat_import), 0.99)\n",
    "    plt.imshow(feat_import, cmap=shap_bpt.shapley_values_colormap, vmin=-vmax, vmax=vmax)\n",
    "    if ground_truth is not None:\n",
    "        marked_h = mark_boundaries(np.tile((255,255,255,0), (feat_import.shape[0],feat_import.shape[1],1)), ground_truth[:,:,0], \n",
    "                             mode='thick', color=(0,0,0,1))\n",
    "        plt.imshow(marked_h)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    if save_fig:\n",
    "        plt.savefig(fname,dpi=dpi, transparent=transparent, bbox_inches = 'tight')\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "    plt.show()\n",
    "\n",
    "###################################################################################\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.6, pad=0.2)\n",
    "def draw_IoU(feat_import=None,IoU_=None,max_IoU_=None,save_fig=True,fname=None,figsize=(2,2),dpi=250,transparent=True, fontsize=18,destroy_fig=True):\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.6, pad=0.2)\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    img = ut.visualize.vis_IoU(feat_import, IoU_,ground_truth[:,:,0]!=0)\n",
    "    plt.imshow(img)\n",
    "    plt.text(8,22, f\"$${max_IoU_:.3}$$\", fontsize=fontsize, bbox=props) #,weight='bold')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    if save_fig:\n",
    "        plt.savefig(fname,dpi=dpi, transparent=transparent, bbox_inches = 'tight')\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "    plt.show()\n",
    "def draw_anomaly_map(img=None,save_fig=True,fname=None,figsize=(2,2),dpi=250,transparent=True,destroy_fig=True):\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    vm = np.max(np.abs(img))\n",
    "    plt.imshow(img, cmap=shap_bpt.shapley_values_colormap, vmin = -vm, vmax = vm)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    if save_fig:\n",
    "        plt.savefig(fname,dpi=dpi, transparent=transparent, bbox_inches = 'tight')\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "    plt.show()\n",
    "\n",
    "##################### FULl PLOTS\n",
    "def plot_figures_full(plot_colorbar=False,plot_title=True,fontsize= 14):\n",
    "    \n",
    "    \n",
    "    if plot_colorbar:\n",
    "        fraction,shrink,pad      = 0.048,1.0,0.02\n",
    "    fig,axes = plt.subplots(1, len(methods)+4, figsize=(15, 1.5))\n",
    "    axes[0].imshow(I_A); axes[0].set_title('Input', fontsize=fontsize)\n",
    "    axes[1].imshow(R_A); axes[1].set_title('Recons', fontsize=fontsize)\n",
    "    vm = np.max(np.abs(anomaly_map))\n",
    "    axes[2].imshow(anomaly_map, cmap=shap_bpt.shapley_values_colormap, vmin = -vm, vmax = vm)\n",
    "    axes[2].set_title('Anomaly Map', fontsize=fontsize)\n",
    "    contoured_image = draw_plot_gt(I_A,ground_truth)\n",
    "    print(f'{\"Method\":<20} Sum(heatmaps)')\n",
    "    print('-'*120)\n",
    "    axes[-1].imshow(contoured_image); axes[-1].set_title('GroundTruth', fontsize=fontsize)\n",
    "    for ii, (n,c,_) in enumerate(methods):\n",
    "        ax = axes[ii+3]\n",
    "        vmax = np.max(np.abs(heatmaps[n]))\n",
    "        heatmap_clr_bar=ax.imshow(heatmaps[n], cmap=shap_bpt.shapley_values_colormap, vmin=-vmax, vmax=vmax)\n",
    "        marked_h = mark_boundaries(np.tile((255,255,255,0), (heatmaps[n].shape[0],heatmaps[n].shape[1],1)), ground_truth[:,:,0], \n",
    "                             mode='thick', color=(0,0,0,1))\n",
    "        ax.imshow(marked_h)\n",
    "        if plot_colorbar:\n",
    "            cbar = plt.colorbar(heatmap_clr_bar , pad=pad, orientation='horizontal',fraction=fraction, shrink=shrink,ax=ax)\n",
    "        print(f'{n:<20} {np.sum(heatmaps[n][0])}')\n",
    "        if plot_title:\n",
    "            ax.set_title(f'{n}', fontsize=fontsize)\n",
    "    for ax in axes:\n",
    "        ax.set_xticks([]) ; ax.set_yticks([])\n",
    "    plt.subplots_adjust()\n",
    "    plt.tight_layout(pad = 0.05)\n",
    "    plt.show()\n",
    "def plot_evaluations_full(plot_add_legend = False,fontsize=14):\n",
    "    fig,axes = plt.subplots(2, len(methods), figsize=(2*(len(methods)+2), 3))\n",
    "    aucD,aucI= {},{}\n",
    "    for ii, (n,c,_) in enumerate(methods):\n",
    "        aucD[n] = saliency_to_auc(heatmaps[n], method='del', batch_size=batch_size)\n",
    "        aucI[n] = saliency_to_auc(heatmaps[n], method='ins', batch_size=batch_size)\n",
    "        \n",
    "        axes[0][ii].plot(aucD[n]['xs'], aucD[n]['ys'], color='orange', label=f\"{aucD[n]['method']}-{n}\")\n",
    "        axes[1][ii].plot(aucI[n]['xs'], aucI[n]['ys'], color='blue', label=f\"{aucI[n]['method']}-{n}\")\n",
    "        if ii==0:\n",
    "            yloc = np.max(aucD[n]['ys'])-10\n",
    "            xloc = np.max(aucD[n]['xs'])-0.5\n",
    "        else:\n",
    "            yloc = np.max(aucD[n]['ys'])-10\n",
    "            xloc = np.max(aucD[n]['xs'])-0.5\n",
    "        \n",
    "        if plot_add_legend:\n",
    "            axes[0][ii].text(xloc,yloc, f\"auc_reg:{aucD[n]['auc_reg']:0.3}\\nauc_eff:{aucD[n]['auc_eff']:0.3}\")\n",
    "            axes[1][ii].text(np.max(aucI[n]['xs'])-0.5,np.max(aucI[n]['ys'])-10, f\"auc_reg:{aucI[n]['auc_reg']:0.3}\\nauc_eff:{aucI[n]['auc_eff']:0.3}\")\n",
    "        \n",
    "        axes[0][ii].set_title(f'{n}',fontsize=fontsize)\n",
    "    axes[0][0].set_ylabel(f\"{aucD[n]['method']}\",fontsize=fontsize)\n",
    "    axes[1][0].set_ylabel(f\"{aucI[n]['method']}\",fontsize=fontsize)\n",
    "    plt.show()\n",
    "def plot_IoUs_full(plot_title=True,fontsize=14):\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.6, pad=0.2)\n",
    "    fig,axes = plt.subplots(1, len(methods)+4, figsize=(15, 1.5))\n",
    "    axes[0].imshow(I_A); axes[0].set_title('Input', fontsize=fontsize)\n",
    "    axes[1].imshow(R_A); axes[1].set_title('Recons', fontsize=fontsize)\n",
    "    vm = np.max(np.abs(anomaly_map))\n",
    "    axes[2].imshow(anomaly_map, cmap=shap_bpt.shapley_values_colormap, vmin = -vm, vmax = vm)\n",
    "    axes[2].set_title('Anomaly Map', fontsize=fontsize)\n",
    "    axes[-1].imshow(ground_truth); axes[-1].set_title('ground_truth', fontsize=fontsize)\n",
    "    \n",
    "    for ii, (n,_,_) in tqdm(enumerate(methods), desc='IoU',leave=False):\n",
    "        ax = axes[ii+3]\n",
    "        img, max_IoU, name = ut.visualize.vis_IoU(heatmaps[n], IoU[n]['max_IoU_old'],ground_truth[:,:,0]!=0),np.max(IoU[n]['Y']), f'{n}'\n",
    "        ax.imshow(img)\n",
    "        \n",
    "        ax.text(10,25, f\"IoU:{max_IoU:.3}\", fontsize=fontsize, bbox=props) #,weight='bold')\n",
    "        if plot_title:\n",
    "            ax.set_title(f'{n}', fontsize=fontsize)\n",
    "    for ax in axes:\n",
    "        ax.set_xticks([]) ; ax.set_yticks([])\n",
    "    plt.subplots_adjust()\n",
    "    plt.tight_layout(pad = 0.05)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10183987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_IoU(shapley_values, threshold, ground_truth,verbose=False):\n",
    "    \n",
    "\n",
    "    pred = shapley_values.flatten() >= threshold\n",
    "    real = ground_truth.flatten()\n",
    "    image = np.full((len(pred), 3), 1.0, dtype=np.float32)\n",
    "    if verbose:\n",
    "        print(np.sum(pred), np.sum(real))\n",
    "    image[ pred & real, : ]    = (0.0, 0.0, 0.75) # True Positives\n",
    "    image[ pred & (~real), : ] = (1.0, 0.6, 0.2)  # False Positives\n",
    "    image[ (~pred) & real, : ] = (1.0, 0.4, 1.0)  # False Negatives\n",
    "    # plt.show()\n",
    "    # plt.imshow(image.reshape(ground_truth.shape + (3,)))\n",
    "    # plt.show()\n",
    "    # print(np.min(shapley_values), np.min(image), np.max(image))\n",
    "    # print('IoU:', np.sum(pred), np.sum(real), np.sum(pred & real), np.sum(pred & (~real)), np.sum((~pred) & real))\n",
    "    return image.reshape(list(ground_truth.shape) + [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "props = dict(boxstyle='round', facecolor='white', alpha=0.6, pad=0.2)\n",
    "\n",
    "def plot_figures_full_filtered(\n",
    "    heatmaps, selected_methods=None, save_fig=True, plot_recon=False, fname=None, \n",
    "    figsize=(2, 2), dpi=250, plot_colorbar=False, plot_title=True, fontsize=14, \n",
    "    text_x=15, text_y=25,\n",
    "    destroy_fig = True\n",
    "):\n",
    "    if plot_colorbar:\n",
    "        fraction, shrink, pad = 0.048, 1.0, 0.02\n",
    "\n",
    "    # Filter methods if selected_methods is provided\n",
    "    filtered_methods = [m for m in methods if selected_methods is None or m[0] in selected_methods]\n",
    "\n",
    "    # Number of columns depends on whether reconstruction is plotted\n",
    "    num_cols = 3 + len(filtered_methods) * 2 if plot_recon else 2 + len(filtered_methods) * 2\n",
    "    fig, axes = plt.subplots(1, num_cols, figsize=(15, 2))  # All in one row\n",
    "\n",
    "    # First column: Input Image\n",
    "    axes[0].imshow(I_A)\n",
    "    if plot_title:\n",
    "        axes[0].set_title('Input', fontsize=fontsize)\n",
    "\n",
    "    # Second column: Reconstructed Image (if enabled)\n",
    "    if plot_recon:\n",
    "        axes[1].imshow(R_A)\n",
    "        if plot_title:\n",
    "            axes[1].set_title('Reconstruction', fontsize=fontsize)\n",
    "\n",
    "    # Third column: Ground Truth\n",
    "    gt_idx = 2 if plot_recon else 1  # Adjust index based on plot_recon flag\n",
    "    axes[gt_idx].imshow(ground_truth[:, :, 0], cmap='binary')\n",
    "    if plot_title:\n",
    "        axes[gt_idx].set_title('Ground Truth', fontsize=fontsize)\n",
    "\n",
    "    print(f'{\"Method\":<20} Sum(heatmaps)')\n",
    "    print('-' * 120)\n",
    "\n",
    "    # Start plotting from the correct index\n",
    "    start_idx = gt_idx + 1  # Next column after Ground Truth\n",
    "\n",
    "    for ii, (n, c, _) in enumerate(filtered_methods):\n",
    "        # Column for Shapley values heatmap\n",
    "        ax1 = axes[start_idx + ii * 2]  \n",
    "        vmax = np.max(np.abs(heatmaps[n]))\n",
    "        heatmap_clr_bar = ax1.imshow(heatmaps[n], cmap=shap_bpt.shapley_values_colormap, vmin=-vmax, vmax=vmax)\n",
    "\n",
    "        # Overlay boundaries\n",
    "        marked_h = mark_boundaries(\n",
    "            np.tile((255, 255, 255, 0), (heatmaps[n].shape[0], heatmaps[n].shape[1], 1)),\n",
    "            ground_truth[:, :, 0],\n",
    "            color=(0, 0, 0, 1)\n",
    "        )\n",
    "        ax1.imshow(marked_h)\n",
    "\n",
    "        if plot_colorbar:\n",
    "            plt.colorbar(heatmap_clr_bar, pad=pad, orientation='horizontal', fraction=fraction, shrink=shrink, ax=ax1)\n",
    "\n",
    "        print(f'{n:<20} {np.sum(heatmaps[n][0])}')\n",
    "\n",
    "        if plot_title:\n",
    "            ax1.set_title(f'Shapley: {n}', fontsize=fontsize)\n",
    "\n",
    "        # Column for Max IoU Visualization (right next to the Shapley map)\n",
    "        ax2 = axes[start_idx + ii * 2 + 1]\n",
    "\n",
    "        # max___iou = IoU[n]['max_IoU_old']# X2[best_pt]\n",
    "        max___iou = IoU[n][2]\n",
    "        IoU__Y =  np.max(IoU[n][1])\n",
    "        img, max_IoU, name = vis_IoU(heatmaps[n],max___iou , ground_truth[:, :, 0] != 0), IoU__Y, f'{n}'\n",
    "        ax2.imshow(img)\n",
    "        ax2.text(text_x, text_y, f\"$${max_IoU:.3}$$\", fontsize=fontsize, bbox=props)\n",
    "\n",
    "    # Remove ticks from all axes\n",
    "    for ax in axes:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.subplots_adjust()\n",
    "    plt.tight_layout(pad=0.05)\n",
    "    plt.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "    # Save figure if required\n",
    "    if save_fig and fname:\n",
    "        plt.savefig(fname, dpi=dpi, transparent=True, bbox_inches='tight')\n",
    "    if destroy_fig:\n",
    "        plt.close(fig)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d8668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# def fun_plot_performance(aucI,aucD,IoU,budget_set='100',ext_type='png',path=None,save_fig=True,fontsize=14):\n",
    "\n",
    "#     fig,axes = plt.subplots(1,9, figsize=(20,2.5), sharex=True)#, sharey=True) #3,3  figsize=(8,2.2)\n",
    "#     # if len(background_tensors)==1:\n",
    "#     #     if params.model_type=='ideal':    \n",
    "#     #         aucI_aa =  aucI['AA-100']\n",
    "#     #         aucD_aa =  aucD['AA-100']\n",
    "#     #         auc_IoU_aa =  IoU['AA-100']\n",
    "#     #         ttl = 'PE'\n",
    "#     #     else:\n",
    "#     #         aucI_aa =  aucI['Partition-100']\n",
    "#     #         aucD_aa =  aucD['Partition-100']\n",
    "#     #         auc_IoU_aa =  IoU['Partition-100']\n",
    "#     # else:\n",
    "#     aucI_aa =  aucI['AA-100']\n",
    "#     aucD_aa =  aucD['AA-100']\n",
    "#     auc_IoU_aa =  IoU['AA-100']\n",
    "#     ttl = 'AA'\n",
    "#     aucI_bpt =  aucI['BPT-100']\n",
    "#     aucD_bpt =  aucD['BPT-100']\n",
    "#     auc_IoU_bpt =  IoU['BPT-100']\n",
    "    \n",
    "#     for i in range(9):\n",
    "#         ax = axes.flat[i]\n",
    "#         ############  AUC\n",
    "#         if i==0: # insertion/regression\n",
    "#             # Xa,Ya,Ma,La      = aucI_aa['xs'],aucI_aa['ys'],aucI_aa['ms'],aucI_aa['auc_reg']\n",
    "#             title='$\\\\mathit{AUC}^{+}$'\n",
    "#             Xa,Ya,Ma,La      = aucI_aa ['xs'],aucI_aa ['ys'],aucI_aa ['ms'],aucI_aa ['auc']\n",
    "#             Xb,Yb,Mb,Lb      = aucI_bpt['xs'],aucI_bpt['ys'],aucI_bpt['ms'],aucI_bpt['auc']\n",
    "#             # Xb,Yb,Mb,Lb = aucI_bpt[0], aucI_bpt[1], aucI_bpt[2], aucI_bpt[3]\n",
    "#         elif i==1: # deletion/regression\n",
    "#             title='$\\\\mathit{AUC}^{-}$'\n",
    "#             Xa,Ya,Ma,La      = aucD_aa ['xs'],aucD_aa ['ys'],aucD_aa ['ms'],aucD_aa ['auc']\n",
    "#             Xb,Yb,Mb,Lb      = aucD_bpt['xs'],aucD_bpt['ys'],aucD_bpt['ms'],aucD_bpt['auc']\n",
    "\n",
    "\n",
    "#         ############  AUC_Adj\n",
    "#         elif i==2: # insertion/error\n",
    "#             title='$\\\\mathit{AUC-Adj}^{+}$'\n",
    "#             Xa,Ya,Ma,La      = aucI_aa ['xs'],aucI_aa ['y_adj'],aucI_aa ['ms'],aucI_aa ['auc_adj']\n",
    "#             Xb,Yb,Mb,Lb      = aucI_bpt['xs'],aucI_bpt['y_adj'],aucI_bpt['ms'],aucI_bpt['auc_adj']\n",
    "#         elif i==3: # deletion/error\n",
    "#             title='$\\\\mathit{AUC-Adj}^{-}$'\n",
    "#             Xa,Ya,Ma,La      = aucD_aa ['xs'],aucD_aa ['y_adj'],aucD_aa ['ms'],aucD_aa ['auc_adj']\n",
    "#             Xb,Yb,Mb,Lb      = aucD_bpt['xs'],aucD_bpt['y_adj'],aucD_bpt['ms'],aucD_bpt['auc_adj']\n",
    "\n",
    "\n",
    "\n",
    "#         ############  AUC_r\n",
    "#         elif i==4: # insertion/error\n",
    "#             title='$\\\\mathit{AUC-r}^{+}$'\n",
    "#             Xa,Ya,Ma,La      = aucI_aa ['xs'],aucI_aa ['ysr'],aucI_aa ['ms'],aucI_aa ['auc_r']\n",
    "#             Xb,Yb,Mb,Lb      = aucI_bpt['xs'],aucI_bpt['ysr'],aucI_bpt['ms'],aucI_bpt['auc_r']            \n",
    "        \n",
    "#         elif i==5: # deletion/error\n",
    "#             title='$\\\\mathit{AUC-r}^{-}$'\n",
    "#             Xa,Ya,Ma,La      = aucD_aa ['xs'],aucD_aa ['ysr'],aucD_aa ['ms'],aucD_aa ['auc_r']\n",
    "#             Xb,Yb,Mb,Lb      = aucD_bpt['xs'],aucD_bpt['ysr'],aucD_bpt['ms'],aucD_bpt['auc_r']\n",
    "\n",
    "        \n",
    "\n",
    "#         ############  AUC_Adj_r\n",
    "\n",
    "\n",
    "#         elif i==6: # insertion/error\n",
    "#             title='$\\\\mathit{AUC-Adj-r}^{+}$'\n",
    "#             Xa,Ya,Ma,La      = aucI_aa ['xs'],aucI_aa ['y_adjr'],aucI_aa ['ms'],aucI_aa ['auc_adjr']\n",
    "#             Xb,Yb,Mb,Lb      = aucI_bpt['xs'],aucI_bpt['y_adjr'],aucI_bpt['ms'],aucI_bpt['auc_adjr']\n",
    "#         elif i==7: # deletion/error\n",
    "#             title='$\\\\mathit{AUC-Adj-r}^{-}$'\n",
    "#             Xa,Ya,Ma,La      = aucD_aa ['xs'],aucD_aa ['y_adjr'],aucD_aa ['ms'],aucD_aa ['auc_adjr']\n",
    "#             Xb,Yb,Mb,Lb      = aucD_bpt['xs'],aucD_bpt['y_adjr'],aucD_bpt['ms'],aucD_bpt['auc_adjr']\n",
    "            \n",
    "#         elif i==8: # IoU\n",
    "#             title='$\\\\mathit{AU}{\\!-\\!}\\\\mathit{IoU}$'\n",
    "#             Xa,Ya,Ma,La = auc_IoU_aa[0], auc_IoU_aa[1], None, auc_IoU_aa[4]\n",
    "#             Xb,Yb,Mb,Lb = auc_IoU_bpt[0], auc_IoU_bpt[1], None, auc_IoU_bpt[4]\n",
    "#             xma, yma = auc_IoU_aa[3], np.max(auc_IoU_aa[1])\n",
    "#             xmb, ymb = auc_IoU_bpt[3], np.max(auc_IoU_bpt[1])\n",
    "            \n",
    "#         # print(i,'  len(Xb): ',len(Xb),'  len(Yb): ', len(Yb), len(Xb)==len(Yb), '  len(Xa): ',len(Xa),'  len(Ya): ', len(Ya), len(Xa)==len(Ya))\n",
    "#     #     ymax = max(np.max(Ya), np.max(Yb))\n",
    "        \n",
    "#         Sa, Sb = ('\\\\textbf', '') if La<Lb else ('', '\\\\textbf')\n",
    "#         if i in [0,2,4,6, 8]:   Sa,Sb=Sb,Sa\n",
    "#         ax.plot(Xa, Ya, c='#2465a6', label=f'{Sa}{{AA}} {La:.4}')\n",
    "#         ax.fill_between(Xa, Ya, color='#2465a6', alpha=0.15, hatch='///')\n",
    "#         # ax.scatter(Xa, Ya, c='black', s=5)\n",
    "#         ax.plot(Xb, Yb, c='#9d2f4d', label=f'{Sb}{{BPT}} {Lb:.4}', alpha=0.80)\n",
    "#         ax.fill_between(Xb, Yb, color='#9d2f4d', alpha=0.15, hatch='\\\\\\\\\\\\')\n",
    "        \n",
    "#         if i==8:\n",
    "#             ax.scatter(xma, yma, s=40, color='blue')\n",
    "#             ax.scatter(xmb, ymb, s=40, color='red')\n",
    "\n",
    "#         if i < 4:\n",
    "#             ax.axhline(f_S, ls='--', c='grey', zorder=0)\n",
    "            \n",
    "#         ax.axhline(0, c='lightgrey', zorder=0)\n",
    "#         ax.legend(borderpad=0.2, labelspacing=0.1, loc='upper right' if i>=1 else 'lower right')#, bbox_to_anchor=(1,0))\n",
    "#         ax.set_title(title, fontsize=fontsize)\n",
    "    \n",
    "#     # axes[0].set_xlabel('\\% pixels inserted', fontsize=14)\n",
    "#     # axes[1].set_xlabel('\\% pixels deleted', fontsize=14)\n",
    "#     # axes[2].set_xlabel('\\% pixels inserted', fontsize=14)\n",
    "#     # axes[3].set_xlabel('\\% pixels deleted', fontsize=14)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     if save_fig:\n",
    "#         if path is not None:\n",
    "#             plt.savefig(f'{path}_five_metrics_2.{ext_type}', dpi=150, bbox_inches='tight', pad_inches=0.02)\n",
    "#         else:\n",
    "#             print('path is None')\n",
    "#     # plt.savefig(f'{path}/five_metrics_{background_type}_2.svg', dpi=150, bbox_inches='tight', pad_inches=0.02)\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('text',usetex=True)\n",
    "rc('text.latex', preamble='\\\\usepackage{color}')\n",
    "\n",
    "def fun_plot_performance(aucI, aucD, IoU,\n",
    "                         list_variants=['BPT-100', 'AA-100', 'LIME-100'],\n",
    "                         budget_set='100',\n",
    "                         path=None,\n",
    "                         file_name='',\n",
    "                         save_fig=True,\n",
    "                         fontsize=14,\n",
    "                         set_title=False,\n",
    "                         plot_lime=False,\n",
    "                         ttl=None,\n",
    "                         layout='row'  # 'row' or '2rows'\n",
    "                         ):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Order of plots (grouped by column for 2-row layout)\n",
    "    plot_defs = [\n",
    "        {'title': '$\\\\mathit{AUC}^{+}$',         'typee': 'auc',        'from': 'aucI'}, # 0\n",
    "        {'title': '$\\\\mathit{AUC}^{-}$',         'typee': 'auc',        'from': 'aucD'}, # 1\n",
    "        {'title': '$\\\\mathit{AUC}^{+}-clip$',     'typee': 'auc_clip',   'from': 'aucI'}, # 2\n",
    "        {'title': '$\\\\mathit{AUC}^{-}-clip$',     'typee': 'auc_clip',   'from': 'aucD'}, # 3\n",
    "        {'title': '$\\\\mathit{AUC^{+}-Adj}$',     'typee': 'auc_adj',    'from': 'aucI'}, # 4\n",
    "        {'title': '$\\\\mathit{AUC^{-}-Adj}$',     'typee': 'auc_adj',    'from': 'aucD'}, # 5\n",
    "        \n",
    "        {'title': '$\\\\mathit{AU}{\\!-\\!}\\\\mathit{IoU}$', 'typee': 'auc_iou', 'from': 'iou'}, # 6 \n",
    "        #####################################################################\n",
    "\n",
    "        {'title': '$\\\\mathit{AUC}^{+}-r$',       'typee': 'auc_r',      'from': 'aucI'}, # 7\n",
    "        {'title': '$\\\\mathit{AUC}^{-}-r$',       'typee': 'auc_r',      'from': 'aucD'}, # 8\n",
    "        {'title': '$\\\\mathit{AUC}^{+}-clip-r$', 'typee': 'auc_clip_r', 'from': 'aucI'}, # 9\n",
    "        {'title': '$\\\\mathit{AUC}^{-}-clip-r$', 'typee': 'auc_clip_r', 'from': 'aucD'}, # 10\n",
    "        {'title': '$\\\\mathit{AUC^{+}-Adj-r}$',   'typee': 'auc_adj_r',  'from': 'aucI'}, # 11\n",
    "        {'title': '$\\\\mathit{AUC^{-}-Adj-r}$',   'typee': 'auc_adj_r',  'from': 'aucD'}, # 12 \n",
    "        \n",
    "    ]\n",
    "    \n",
    "    # Reorder plot_defs for 2-row layout: interleaved columns\n",
    "    if layout == '2rows':\n",
    "        top = plot_defs[0::2]\n",
    "        bottom = plot_defs[1::2]\n",
    "        plot_defs = [None]*(len(top)+len(bottom))\n",
    "        plot_defs[::2] = top\n",
    "        plot_defs[1::2] = bottom\n",
    "\n",
    "    total_variant = len(plot_defs)\n",
    "\n",
    "    # Layout config\n",
    "    if layout == 'row':\n",
    "        nrows, ncols = 1, total_variant\n",
    "        fig_width, fig_height = 25, 2.5\n",
    "    elif layout == '2rows':\n",
    "        nrows, ncols = 2, int(np.ceil(total_variant / 2))\n",
    "        fig_width, fig_height = 16, 5\n",
    "    else:\n",
    "        raise ValueError(\"layout must be either 'row' or '2rows'\")\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(fig_width, fig_height))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Alias\n",
    "    aucI_aa = aucI[list_variants[0]]\n",
    "    aucD_aa = aucD[list_variants[0]]\n",
    "    auc_IoU_aa = IoU[list_variants[0]]\n",
    "\n",
    "    aucI_bpt = aucI[list_variants[1]]\n",
    "    aucD_bpt = aucD[list_variants[1]]\n",
    "    auc_IoU_bpt = IoU[list_variants[1]]\n",
    "\n",
    "    aucI_lime = aucI[list_variants[2]]\n",
    "    aucD_lime = aucD[list_variants[2]]\n",
    "    auc_IoU_lime = IoU[list_variants[2]]\n",
    "\n",
    "    def get_params_auc(auc_, typee):\n",
    "        return {\n",
    "            'auc':        (auc_['xs'], auc_['ys'],     auc_['ms'], auc_['auc']),\n",
    "            'auc_r':      (auc_['xs'], auc_['ysr'],    auc_['ms'], auc_['auc_r']),\n",
    "            'auc_adj':    (auc_['xs'], auc_['y_adj'],  auc_['ms'], auc_['auc_adj']),\n",
    "            'auc_adj_r':  (auc_['xs'], auc_['y_adjr'], auc_['ms'], auc_['auc_adjr']),\n",
    "            'auc_clip':   (auc_['xs'], auc_['y_clip'], auc_['ms'], auc_['auc_clip']),\n",
    "            'auc_clip_r': (auc_['xs'], auc_['y_clipr'],auc_['ms'], auc_['auc_clipr']),\n",
    "        }.get(typee, (None, None, None, None))\n",
    "\n",
    "    def get_params_iou(iou_, typee):\n",
    "        if typee == 'auc_iou':\n",
    "\n",
    "            # xmb, ymb = iou_[3], np.max(iou_[1])\n",
    "\n",
    "\n",
    "            Xa, Ya, Ma, La = iou_[0], iou_[1], None, iou_[4]\n",
    "            xma, yma = iou_[3], np.max(iou_[1])\n",
    "            return Xa, Ya, Ma, La, xma, yma\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "    for i, config in enumerate(plot_defs):\n",
    "        ax = axes[i]\n",
    "        title = config['title']\n",
    "        typee = config['typee']\n",
    "        source = config['from']\n",
    "\n",
    "        # Select correct dict\n",
    "        if source == 'aucI':\n",
    "            Xa, Ya, Ma, La = get_params_auc(aucI_aa, typee)\n",
    "            Xb, Yb, Mb, Lb = get_params_auc(aucI_bpt, typee)\n",
    "            Xl, Yl, Ml, Ll = get_params_auc(aucI_lime, typee)\n",
    "        elif source == 'aucD':\n",
    "            Xa, Ya, Ma, La = get_params_auc(aucD_aa, typee)\n",
    "            Xb, Yb, Mb, Lb = get_params_auc(aucD_bpt, typee)\n",
    "            Xl, Yl, Ml, Ll = get_params_auc(aucD_lime, typee)\n",
    "        elif source == 'iou':\n",
    "            Xa, Ya, Ma, La, xma, yma = get_params_iou(auc_IoU_aa,  typee)\n",
    "            Xb, Yb, Mb, Lb, xmb, ymb = get_params_iou(auc_IoU_bpt, typee)\n",
    "            Xl, Yl, Ml, Ll, xml, yml = get_params_iou(auc_IoU_lime,   typee)\n",
    "\n",
    "        # Boldness logic\n",
    "        Sa, Sb = ('\\\\textbf', '') if La < Lb else ('', '\\\\textbf')\n",
    "        if i in [0,2,4,6,8]: Sa, Sb = Sb, Sa\n",
    "\n",
    "        # Plot\n",
    "        ax.plot(Xa, Ya, c='#2465a6', label=f'{Sa}{{AA}} {La:.4f}')\n",
    "        ax.fill_between(Xa, Ya, color='#2465a6', alpha=0.15, hatch='///')\n",
    "        ##########\n",
    "        ax.plot(Xb, Yb, c='#9d2f4d', label=f'{Sb}{{BPT}} {Lb:.4f}', alpha=0.80)\n",
    "        ax.fill_between(Xb, Yb, color='#9d2f4d', alpha=0.15, hatch='\\\\\\\\\\\\')\n",
    "        ##########\n",
    "        if plot_lime:\n",
    "            ax.plot(Xl, Yl, c=\"#01B0A7\", label=f'{Sb}{{LM}} {Ll:.4f}', alpha=0.80)\n",
    "            ax.fill_between(Xl, Yl, color='#01B0A7', alpha=0.15, hatch='\\\\\\\\\\\\')\n",
    "\n",
    "\n",
    "        if typee == 'auc_iou':\n",
    "            ax.scatter(xma, yma, s=40, color='blue')\n",
    "            ax.scatter(xmb, ymb, s=40, color='red')\n",
    "\n",
    "        if i < 4:\n",
    "            ax.axhline(0.0, ls='--', c='grey', zorder=0)  # placeholder for f_S - f_0\n",
    "\n",
    "        ax.axhline(0, c='lightgrey', zorder=0)\n",
    "        ax.legend(borderpad=0.2, labelspacing=0.1, loc='upper right' if i>=1 else 'lower right')\n",
    "        ax.set_title(title, fontsize=fontsize)\n",
    "    axes[-1].imshow(I_A); axes[-1].set_xticks([]); axes[-1].set_yticks([])\n",
    "    axes[-1].set_title(ttl.split(\",\")[0])\n",
    "    if set_title:\n",
    "        plt.suptitle(f'{ttl}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_fig and path is not None:\n",
    "        plt.savefig(f'{path}/{file_name}_paired_auc_metrics.png', dpi=150, bbox_inches='tight', pad_inches=0.02)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24aa66c-0fb7-4d2d-ad66-7a2618d05e3d",
   "metadata": {},
   "source": [
    "# Save Plots for Figure 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c24d70-5188-41e3-b7ef-16551cb1a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_selected_results = False\n",
    "plot_selected_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_methods=['AA-500', 'BPT-500','LIME-500']\n",
    "selected_methods = methods_ls\n",
    "selected_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_type = 'full' if len(selected_methods)==len(methods_ls) else 'selected'\n",
    "exp_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94276246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_0 = shap_bpt_masked_model(np.zeros((1,128,128), dtype=bool))[0,0]\n",
    "# f_S = shap_bpt_masked_model(np.ones((1,128,128), dtype=bool))[0,0]\n",
    "# print(f_S, f_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9675a3-2fd5-4cc7-8f9f-de4fcbfe101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_fig         = True\n",
    "save_ext            = 'svg'\n",
    "plot_single_files   = False\n",
    "\n",
    "# a_type_selected_ls = ['crack','cut','hole','print']\n",
    "# img_id_selected_ls = [3,2,1]\n",
    "\n",
    "a_type_selected_ls = ['crack']\n",
    "img_id_selected_ls = [3]\n",
    "\n",
    "font_size = 24 if exp_type == 'selected' else 14\n",
    "if plot_selected_results:\n",
    "    results_path_paper_figures = os.path.join(results_path, 'selected')\n",
    "    os.makedirs(results_path_paper_figures,              exist_ok=True)\n",
    "\n",
    "if plot_selected_results:\n",
    "    for (a_type,img_id) in zip(a_type_selected_ls,img_id_selected_ls):\n",
    "        print('Anomaly Type: \\t',a_type,' Image: \\t',img_id)\n",
    "        load_image(anomaly_type=a_type, img_id=img_id)\n",
    "        f_0 = shap_bpt_masked_model(np.zeros((1,128,128), dtype=bool))[0,0]\n",
    "        f_S = shap_bpt_masked_model(np.ones((1,128,128), dtype=bool))[0,0]\n",
    "        get_anomaly_map_score()\n",
    "        ######################################################\n",
    "        heatmaps = {}\n",
    "        for n,_,funct in tqdm(methods, desc= 'Explanation'):\n",
    "            if n not in selected_methods:\n",
    "                continue\n",
    "            heatmaps[n] = funct()\n",
    "        ######################################################\n",
    "        aucD,aucI,IoU = {},{},{}\n",
    "        for n,_,funct in tqdm(methods, desc= 'Evaluation'): \n",
    "            if n not in selected_methods:\n",
    "                continue\n",
    "            aucD[n] = saliency_to_auc(shap_bpt_masked_model,heatmaps[n],f_S, f_0, predicted_cls=0, method='del', batch_size=batch_size)\n",
    "            aucI[n] = saliency_to_auc(shap_bpt_masked_model,heatmaps[n],f_S, f_0, predicted_cls=0, method='ins', batch_size=batch_size)\n",
    "            # IoU[n]  = calc_IoU_curve(ground_truth_final.flatten(), heatmaps[n].flatten())\n",
    "            IoU[n]  = calc_IoU_curve(y_true_flat, heatmaps[n].flatten())\n",
    "        ######################################################\n",
    "        fname=f'{results_path_paper_figures}/{a_type}_{img_id}_{exp_type}.{save_ext}'\n",
    "        \n",
    "        if exp_type == 'selected':\n",
    "            plot_figures_full_filtered(heatmaps,selected_methods=selected_methods,plot_recon=False,fname=fname,plot_colorbar=False,plot_title=False,\n",
    "                                  fontsize= font_size,text_x=15 ,text_y=40, destroy_fig=False)\n",
    "        else:\n",
    "            plot_figures_full_filtered(heatmaps,selected_methods=selected_methods,plot_recon=True,fname=fname,plot_colorbar=False,plot_title=False,\n",
    "                                  fontsize= font_size,text_x=15 ,text_y=40, destroy_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cbe036",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap_bpt_masked_model(np.zeros((1,128,128), dtype=bool))[0,0])\n",
    "print(shap_bpt_masked_model(np.ones((1,128,128), dtype=bool))[0,0])\n",
    "\n",
    "shap_bpt_masked_model(np.expand_dims(ground_truth[0], axis=0))\n",
    "# np.expand_dims(ground_truth[0], axis=0).shape\n",
    "\n",
    "predicted_fG = shap_bpt_masked_model(np.expand_dims(ground_truth[0], axis=0))[0]\n",
    "f_G = float(predicted_fG[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee87586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bg_values(f_masked,ground_truth,predicted_cls=0, verbose=False):\n",
    "    # global f_G, f_B\n",
    "    # evaluate the ground truth mask with the background replacement strategy for masking function\n",
    "    predicted_fG = f_masked(np.expand_dims(ground_truth[0], axis=0))[0]\n",
    "    f_G = float(predicted_fG[predicted_cls])\n",
    "    # print(class_names[predicted_cls], f_G, predicted_cls, f_G)\n",
    "    # print('softmax prob:', np_softmax(predicted_fG)[predicted_cls])\n",
    "\n",
    "    # evaluate the backgrounf (negative of the ground truth mask)\n",
    "    background_mask = np.logical_not(ground_truth)\n",
    "    predicted_fB = f_masked(np.expand_dims(background_mask, axis=0))[0]\n",
    "    f_B = float(predicted_fB[predicted_cls])\n",
    "    # print(class_names[predicted_cls], f_B, predicted_cls, f_B)\n",
    "    # print('softmax prob:', np_softmax(predicted_fB)[predicted_cls])\n",
    "\n",
    "    # print()\n",
    "    if verbose:\n",
    "        print('nu(S):  ', round(f_S, 4))\n",
    "        print('nu(G):  ', round(f_G, 4))\n",
    "        print('nu(S/G):', round(f_B, 4))\n",
    "        print('nu(0):  ', round(f_0, 4))\n",
    "    return f_G,f_B\n",
    "# f_G,f_B = get_bg_values(shap_bpt_masked_model,ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figures_full_filtered(heatmaps,selected_methods=selected_methods,plot_recon=False,fname=fname,plot_colorbar=False,plot_title=False,\n",
    "                                  fontsize= font_size,text_x=15 ,text_y=40, destroy_fig= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun_plot_performance(aucI,aucD,IoU,path=f'{results_path_paper_figures}/{a_type}_{img_id}_{exp_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_plot_performance(aucI,aucD,IoU,path=results_path, file_name=img_id,layout='2rows',\n",
    "                                     set_title=True,ttl=f'a_type: {a_type}, img_id: {img_id} exp_type: {exp_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6152b",
   "metadata": {},
   "source": [
    "## RUN SELECTED ON ALL IMAGES to Save SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f57420",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth,ground_truths = None,None\n",
    "union_ground_truths = []\n",
    "ground_truths = []\n",
    "brown_hair,black_hair,blond_hair = None,None,None\n",
    "Eyeglasses = None\n",
    "def load_ground_truth(intrested_class_lss,img_id=None, verbose=False):\n",
    "    global ground_truth,ground_truths,union_ground_truth,union_ground_truths\n",
    "    global brown_hair,Eyeglasses,anno_path\n",
    "\n",
    "    if verbose:\n",
    "        print('LAODING GT for ', intrested_class_lss)\n",
    "    if att_csv_celeba:\n",
    "        image_id = f'{img_id+1:06}.jpg'\n",
    "    else:\n",
    "        image_id = f'{img_id}.jpg'\n",
    "    union_ground_truths = {}\n",
    "    ground_truths = []\n",
    "    for mask_1 in intrested_class_lss:\n",
    "        ground_truths = []\n",
    "        if mask_1 == 'Smiling':\n",
    "            sub_masks = ['l_lip', 'mouth', 'u_lip']\n",
    "        elif mask_1=='Eyeglasses':\n",
    "            sub_masks = ['eye_g']\n",
    "            Eyeglasses = df_attr[df_attr.image_id==image_id]['Eyeglasses'].values[0]==1\n",
    "        #Black_Hair, Blond_Hair,Brown_Hair,Gray_Hair,Straight_Hair,Wavy_Hair\n",
    "        elif mask_1=='Brown_Hair':\n",
    "            brown_hair = df_attr[df_attr.image_id==image_id]['Brown_Hair'].values[0]==1\n",
    "            sub_masks = ['hair']\n",
    "        elif mask_1=='Black_Hair':\n",
    "            black_hair = df_attr[df_attr.image_id==image_id]['Black_Hair'].values[0]==1\n",
    "            sub_masks = ['hair']\n",
    "        elif mask_1=='Blond_Hair':\n",
    "            blond_hair = df_attr[df_attr.image_id==image_id]['Blond_Hair'].values[0]==1\n",
    "            sub_masks = ['hair']\n",
    "        elif mask_1=='Gray_Hair':\n",
    "            brown_hair = df_attr[df_attr.image_id==image_id]['Gray_Hair'].values[0]==1\n",
    "            sub_masks = ['hair']\n",
    "        elif mask_1=='Straight_Hair':\n",
    "            brown_hair = df_attr[df_attr.image_id==image_id]['Straight_Hair'].values[0]==1\n",
    "            sub_masks = ['hair']\n",
    "        elif mask_1=='Wavy_Hair':\n",
    "            brown_hair = df_attr[df_attr.image_id==image_id]['Wavy_Hair'].values[0]==1\n",
    "            sub_masks = ['hair']\n",
    "               \n",
    "        else:\n",
    "            sub_masks = [mask_1]\n",
    "        \n",
    "        # Loop over each sub-mask\n",
    "        for sub_mas in sub_masks:\n",
    "            \n",
    "            folder = find_folder(img_id, anno_pth)\n",
    "            anno_subpath = os.path.join(ds_anno_path,str(folder))\n",
    "            anno_filename = f'{os.path.join(anno_subpath, f\"{img_id:05}_{sub_mas}\")}.png'\n",
    "            #print('sub_masks:',sub_masks,anno_filename,os.path.exists(anno_filename))\n",
    "            # print(anno_filename,img_id,image_id,os.path.exists(anno_filename), brown_hair, Eyeglasses, df_attr[df_attr.image_id==image_id]['Eyeglasses'])\n",
    "            #if not os.path.exists(anno_filename) or not brown_hair or not Eyeglasses and load_positives_only:\n",
    "            if not os.path.exists(anno_filename):\n",
    "                ground_truth = np.zeros((224,224)).astype(int)\n",
    "            else:\n",
    "                #print('anno_subpath: \\t',anno_filename,img_id,mask_1)\n",
    "                ground_truth = cv2.imread(anno_filename, cv2.IMREAD_COLOR)[:, :, ::-1]\n",
    "                ground_truth = cv2.resize(ground_truth, [224, 224], interpolation=cv2.INTER_NEAREST)\n",
    "                ground_truth = ground_truth[:,:,0].astype(int)\n",
    "            ground_truths.append(ground_truth)\n",
    "        \n",
    "        # Calculate the union of the ground truths for the current mask\n",
    "        if len(ground_truths) > 0:\n",
    "            union_ground_truth = ground_truths[0]\n",
    "            for ground_truth in ground_truths[1:]:\n",
    "                union_ground_truth = cv2.bitwise_or(union_ground_truth, ground_truth)\n",
    "        else:\n",
    "            union_ground_truth = ground_truths[0]\n",
    "        \n",
    "        # Append the union ground truth to the list of all unions\n",
    "        # union_ground_truths.append(union_ground_truth)\n",
    "        union_ground_truths[mask_1] = union_ground_truth\n",
    "\n",
    "\n",
    "\n",
    "        # # evaluate the ground truth mask with the background replacement strategy for masking function\n",
    "        # predicted_fG = f_masked(np.expand_dims(ground_truth, axis=0))[0]\n",
    "        # f_G = float(predicted_fG[predicted_cls])\n",
    "        # print(class_names[predicted_cls], f_G, predicted_cls, f_G)\n",
    "        # print('softmax prob:', np_softmax(predicted_fG)[predicted_cls])\n",
    "\n",
    "        # # evaluate the backgrounf (negative of the ground truth mask)\n",
    "        # background_mask = np.logical_not(ground_truth)\n",
    "        # predicted_fB = f_masked(np.expand_dims(background_mask, axis=0))[0]\n",
    "        # f_B = float(predicted_fB[predicted_cls])\n",
    "        # print(class_names[predicted_cls], f_B, predicted_cls, f_B)\n",
    "        # print('softmax prob:', np_softmax(predicted_fB)[predicted_cls])\n",
    "\n",
    "        # print()\n",
    "        # print('nu(S):  ', round(f_S, 4))\n",
    "        # print('nu(G):  ', round(f_G, 4))\n",
    "        # print('nu(S/G):', round(f_B, 4))\n",
    "        # print('nu(0):  ', round(f_0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_G,f_B = get_bg_values(shap_bpt_masked_model,ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40cdabe-8a65-4974-ae22-4fbfa6056a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test_anomaly_types = 'anomalous' # all\n",
    "test_images_try_ls = count_cls[1:] # Discarding Non Anomolous Images\n",
    "\n",
    "if run_test_anomaly_types=='all':\n",
    "    anom_type = anomaly_types\n",
    "elif run_test_anomaly_types=='anomalous':\n",
    "    anom_type = anomaly_types_gt\n",
    "    # test_images_try_ls = test_images_try_ls[1:]\n",
    "font_size = 24 if exp_type == 'selected' else 14\n",
    "\n",
    "print(f'{\"Anomaly\": <{15}} {\"Image\": <{15}} {\"method\": <{10}} {\"anomaly_score\": <{15}} {\"max_IoU\": <{15}}')\n",
    "for a_type_id,a_type in enumerate(tqdm(anom_type, desc = 'anom_type')):\n",
    "    for img_id in tqdm(range(0,test_images_try_ls[a_type_id]), desc ='images'):\n",
    "        if a_type=='crack':\n",
    "            continue\n",
    "        if img_id>=3:\n",
    "            continue\n",
    "        fname=f'{results_path_paper_figures}/{a_type}_{img_id+1}_{exp_type}.{save_ext}'\n",
    "\n",
    "        print('Anomaly Type: \\t',a_type,' Image: \\t',img_id)\n",
    "        load_image(anomaly_type=a_type, img_id=img_id)\n",
    "        f_0 = shap_bpt_masked_model(np.zeros((1,128,128), dtype=bool))[0,0]\n",
    "        f_S = shap_bpt_masked_model(np.ones((1,128,128), dtype=bool))[0,0]\n",
    "        f_G,f_B = get_bg_values(shap_bpt_masked_model,ground_truth, verbose=True)\n",
    "        \n",
    "        get_anomaly_map_score()\n",
    "        heatmaps = {}\n",
    "        for n,_,funct in tqdm(methods, desc= 'Explanation'):\n",
    "            if n not in selected_methods:\n",
    "                continue\n",
    "            heatmaps[n] = funct()\n",
    "        aucD,aucI,IoU = {},{},{}\n",
    "        for n,_,funct in tqdm(methods, desc= 'Evaluation'): \n",
    "            if n not in selected_methods:\n",
    "                continue\n",
    "            aucD[n] = saliency_to_auc(shap_bpt_masked_model,heatmaps[n],f_S, f_0, predicted_cls=0, method='del', batch_size=batch_size)\n",
    "            aucI[n] = saliency_to_auc(shap_bpt_masked_model,heatmaps[n],f_S, f_0, predicted_cls=0, method='ins', batch_size=batch_size)\n",
    "            # IoU[n]  = ut.visualize.calc_IoU_curve(y_true_flat, heatmaps[n].flatten())\n",
    "            IoU[n]  = calc_IoU_curve(ground_truth[:,:,0].astype('bool').flatten(), heatmaps[n].flatten())\n",
    "        # plot_figures_full_filtered(heatmaps,selected_methods=selected_methods,fname=fname,plot_colorbar=False,plot_title=False,\n",
    "        #                            fontsize= font_size,text_x=15 ,text_y=40)\n",
    "        if exp_type == 'selected':\n",
    "            plot_figures_full_filtered(heatmaps,selected_methods=selected_methods,plot_recon=False,fname=fname,plot_colorbar=False,plot_title=False,\n",
    "                                  fontsize= font_size,text_x=15 ,text_y=40, destroy_fig=False)\n",
    "        else:\n",
    "            plot_figures_full_filtered(heatmaps,selected_methods=selected_methods,plot_recon=True,fname=fname,plot_colorbar=False,plot_title=False,\n",
    "                                  fontsize= font_size,text_x=15 ,text_y=40, destroy_fig=False)\n",
    "        fun_plot_performance(aucI,aucD,IoU,path=results_path, file_name=img_id,layout='2rows',\n",
    "                                     set_title=True,ttl=f'a_type: {a_type}, img_id: {img_id} exp_type: {exp_type}')\n",
    "        # fun_plot_performance(aucI,aucD,IoU,ext_type=save_ext, path=f'{results_path_paper_figures}/{a_type}_{img_id}_{exp_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ee67b1",
   "metadata": {},
   "source": [
    "## RUN FOR SELECTED EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_type = 'hole'\n",
    "img_id = 11\n",
    "\n",
    "load_image(anomaly_type=a_type, img_id=img_id)\n",
    "f_0 = shap_bpt_masked_model(np.zeros((1,128,128), dtype=bool))[0,0]\n",
    "f_S = shap_bpt_masked_model(np.ones((1,128,128), dtype=bool))[0,0]\n",
    "f_G,f_B = get_bg_values(shap_bpt_masked_model,ground_truth, verbose=True)\n",
    "\n",
    "get_anomaly_map_score()\n",
    "heatmaps = {}\n",
    "for n,_,funct in tqdm(methods, desc= 'Explanation'):\n",
    "    if n not in selected_methods:\n",
    "        continue\n",
    "    # print(f'Computing {n}')\n",
    "    st = datetime.now()\n",
    "    heatmaps[n] = funct()\n",
    "    print(f'Computed {n:<10} in  {format(datetime.now() - st):<10}')\n",
    "\n",
    "aucD,aucI,IoU = {},{},{}\n",
    "for n,_,funct in tqdm(methods, desc= 'Evaluation'): \n",
    "    if n not in selected_methods:\n",
    "        continue\n",
    "    \n",
    "    aucD[n] = saliency_to_auc(shap_bpt_masked_model,heatmaps[n],f_S, f_0, predicted_cls=0, method='del', batch_size=batch_size)\n",
    "    aucI[n] = saliency_to_auc(shap_bpt_masked_model,heatmaps[n],f_S, f_0, predicted_cls=0, method='ins', batch_size=batch_size)\n",
    "    # IoU[n]  = ut.visualize.calc_IoU_curve(y_true_flat, heatmaps[n].flatten())\n",
    "    IoU[n]  = calc_IoU_curve(ground_truth[:,:,0].astype('bool').flatten(), heatmaps[n].flatten())\n",
    "# plot_figures_full_filtered(heatmaps,selected_methods=selected_methods,fname=fname,plot_colorbar=False,plot_title=False,\n",
    "#                            fontsize= font_size,text_x=15 ,text_y=40)\n",
    "if exp_type == 'selected':\n",
    "    plot_figures_full_filtered(heatmaps,selected_methods=selected_methods,plot_recon=False,fname=fname,plot_colorbar=False,plot_title=False,\n",
    "                            fontsize= font_size,text_x=15 ,text_y=40, destroy_fig=False)\n",
    "else:\n",
    "    plot_figures_full_filtered(heatmaps,selected_methods=selected_methods,plot_recon=True,fname=fname,plot_colorbar=False,plot_title=False,\n",
    "                            fontsize= font_size,text_x=15 ,text_y=40, destroy_fig=False)\n",
    "fun_plot_performance(aucI,aucD,IoU,path=results_path, file_name=img_id,layout='2rows',\n",
    "                                set_title=True,ttl=f'a_type: {a_type}, img_id: {img_id} exp_type: {exp_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6408d-c90f-4c97-b52b-a007bfd719c8",
   "metadata": {},
   "source": [
    "# Run Full Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028a481-b64e-4123-ac3f-a9b55d03b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_full_set = True\n",
    "# run_full_set = False\n",
    "\n",
    "exp_name = 'csv_exp_E6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4f88d-086c-478d-baa2-3b1400fafce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(ut)\n",
    "if run_full_set:\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    plot_IoU            = True\n",
    "    save_figs           = True\n",
    "    destroy_fig         = True\n",
    "    plot_summary        = False\n",
    "    verbose             = True\n",
    "    verbose_print       = False\n",
    "    num_samples         = 500\n",
    "    batch_size          = 200\n",
    "    target_segs         = 100\n",
    "    fontsize            = 14\n",
    "    mask_types          = ['blend_2']\n",
    "    postfix_csv = f'{DS_name}_{len(methods)}'\n",
    "    csv_filename = f'{path_csv}/{exp_name}_testresults_{postfix_csv}_BPT_new_eval.csv'\n",
    "    print('csv_filename: ', csv_filename)\n",
    "    print('anomaly types in test set:\\t',anomaly_types_gt)\n",
    "    test_images_try_ls = count_cls[1:] # Discarding Non Anomolous Images\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.6, pad=0.2)\n",
    "    total_iterations = len(methods) * sum(test_images_try_ls)\n",
    "    pbar = tqdm(desc=f\"Progress\", total=total_iterations)\n",
    "    st_full       = time.time()\n",
    "\n",
    "    run_test_anomaly_types = 'anomalous' # all\n",
    "    if run_test_anomaly_types=='all':\n",
    "        anom_type = anomaly_types\n",
    "    elif run_test_anomaly_types=='anomalous':\n",
    "        anom_type = anomaly_types_gt\n",
    "        # test_images_try_ls = test_images_try_ls[1:]\n",
    "    if verbose_print:    \n",
    "        print(f'{\"Anomaly\": <{15}} {\"Image\": <{15}} {\"method\": <{10}} {\"anomaly_score\": <{15}} {\"max_IoU\": <{15}}')\n",
    "    results=[]\n",
    "    for a_type_id,a_type in enumerate(anom_type):\n",
    "        for img_id in range(0,test_images_try_ls[a_type_id]):\n",
    "            \n",
    "            fig,axes = plt.subplots(1, len(methods)+4, figsize=(15, 3))\n",
    "            \n",
    "            time_start = time.time()\n",
    "            results_subpath_cls = os.path.join(results_subs,str(a_type))\n",
    "            os.makedirs(results_subpath_cls,               exist_ok=True)\n",
    "            st_load = time.time()\n",
    "            load_image(anomaly_type=a_type, img_id=img_id)\n",
    "            get_anomaly_map_score()\n",
    "            f_0 = shap_bpt_masked_model(np.zeros((1,128,128), dtype=bool))[0,0]\n",
    "            f_S = shap_bpt_masked_model(np.ones((1,128,128), dtype=bool))[0,0]\n",
    "\n",
    "            f_G,f_B = get_bg_values(shap_bpt_masked_model,ground_truth)\n",
    "\n",
    "            anomaly_score_val = score_function(np.array([I_A]))[0][0]\n",
    "            time_load = time.time()-st_load\n",
    "            \n",
    "            AM_roc_score      = 0.0 if a_type=='good' else sklearn.metrics.roc_auc_score(y_true_flat, predicted_flat)\n",
    "            \n",
    "            axes[0].imshow(I_A)\n",
    "            axes[1].imshow(R_A)\n",
    "            axes[2].imshow(anomaly_map, vmin=-am_max, vmax=am_max, cmap = shap_bpt.shapley_values_colormap)\n",
    "            contoured_image = draw_plot_gt(I_A,ground_truth)\n",
    "            axes[-1].imshow(contoured_image)\n",
    "            for mask_type_id,mask_type in enumerate(mask_types):\n",
    "                get_mask(mask_type=mask_type)\n",
    "                mask_ttl = f'{mask_tp},k:{num_samples}'\n",
    "                heatmaps,aucD,aucI,IoU = {},{},{},{}\n",
    "                time_exp = {}\n",
    "                for n,_,funct in tqdm(methods, leave=False, desc = 'Explanations'):\n",
    "                    data={}\n",
    "                    st = time.time()\n",
    "                    heatmaps[n] = funct()\n",
    "                    time_exp[n] = time.time()-st\n",
    "                    #################    aucD\n",
    "                    st = time.time()\n",
    "                    aucD[n] = saliency_to_auc(shap_bpt_masked_model,heatmaps[n],f_S, f_0, predicted_cls=0, method='del', batch_size=batch_size)\n",
    "            \n",
    "                    time_aucD = time.time()-st\n",
    "                    #################    aucI\n",
    "                    st = time.time()\n",
    "                    aucI[n] = saliency_to_auc(shap_bpt_masked_model,heatmaps[n],f_S, f_0, predicted_cls=0, method='ins', batch_size=batch_size)\n",
    "            \n",
    "                    time_aucI = time.time()-st\n",
    "                    if n=='LIME':\n",
    "                        cv_beta = ut.Explanation.get_CV_beta(beta)\n",
    "                        auroc       = 0.0 if a_type=='good' else sklearn.metrics.roc_auc_score(y_true_flat, heatmaps[n].flatten())\n",
    "                        LIME_roc_abs_score    = 0.0 if a_type=='good' else sklearn.metrics.roc_auc_score(y_true_flat, np.abs(heatmaps[n].flatten()))\n",
    "                        \n",
    "                        heatmap_gs1 = gaussian_filter(heatmap_lime, sigma=1)\n",
    "                        heatmap_gs2 = gaussian_filter(heatmap_lime, sigma=2)\n",
    "\n",
    "                    else:\n",
    "                        auroc,auroc_gs1,auroc_gs2 = 0,0,0\n",
    "                    # IoU[n] =ut.visualize.calc_IoU_curve(y_true_flat, heatmaps[n].flatten())\n",
    "                    # IoU[n]  = ut.visualize.calc_IoU_curve(y_true_flat, heatmaps[n].flatten())\n",
    "                    st = time.time()\n",
    "                    IoU[n]  = calc_IoU_curve(ground_truth[:,:,0].astype('bool').flatten(), heatmaps[n].flatten())\n",
    "                    time_IoU = time.time()-st\n",
    "                    if verbose_print:\n",
    "                        print(f\"{a_type: <{15}} {img_id: <{15}} {n: <{10}} {am_max: <{15.4}} {np.max(IoU[n]['Y']): <{15.4}}\")\n",
    "                    data = {\n",
    "                            'a_type_id'         :  a_type_id,\n",
    "                            'a_type'            :  a_type,\n",
    "                            'img_no'            :  img_id,\n",
    "                            'mask_type'         :  mask_type,\n",
    "                            'target_segs'       :  target_segs,\n",
    "                            'num_samples'       :  num_samples,\n",
    "                            #------------------------------------------------------------------------------------------------#\n",
    "                            'anomaly_score'     :  am_max,\n",
    "                            'anomaly_score_val' :  anomaly_score_val,\n",
    "                            'AM_roc_score'      :  AM_roc_score,\n",
    "                            'auroc'             :  auroc,\n",
    "                            #--------------------------------\n",
    "                            'max_heatmap'       :  np.max(heatmaps[n]),\n",
    "                            #------------------------------------------------------------------------------------------------#\n",
    "                            'f_S'               : f_S,\n",
    "                            'f_0'               : f_0,\n",
    "                            'f_G'               : f_B,\n",
    "                            'f_B'               : f_G,\n",
    "                            'delta_f'           : f_S-f_0,\n",
    "                            'f_T'               : np.sum(heatmaps[n][0]),\n",
    "                            'f_N'               : len(np.unique(heatmaps[n][0])),           ## UNIQUE PATCHES IN EXPLANATION\n",
    "                            #------------------------------------------------------------------------------------------------#\n",
    "                            'method'            :  n,\n",
    "                            #--------------------------------\n",
    "                            'aucI_pred'         : aucI[n]['auc'],\n",
    "                            'aucD_pred'         : aucD[n]['auc'],\n",
    "                            #--------------------------------\n",
    "                            'aucI_r'            : aucI[n]['auc_r'],\n",
    "                            'aucD_r'            : aucD[n]['auc_r'],\n",
    "                            #--------------------------------\n",
    "                            'aucI_adj'          : aucI[n]['auc_adj'],\n",
    "                            'aucD_adj'          : aucD[n]['auc_adj'],\n",
    "                            #--------------------------------\n",
    "                            'aucI_adj_r'        : aucI[n]['auc_adjr'],\n",
    "                            'aucD_adj_r'        : aucD[n]['auc_adjr'],\n",
    "                            #--------------------------------\n",
    "                            'aucI_clip'         : aucI[n]['auc_clip'], \n",
    "                            'aucI_clipr'        : aucI[n]['auc_clipr'],\n",
    "                            #--------------------------------\n",
    "                            'aucD_clip'         : aucD[n]['auc_clip'], \n",
    "                            'aucD_clipr'        : aucD[n]['auc_clipr'],\n",
    "                            #--------------------------------\n",
    "                            'threshold'         : IoU[n][2],\n",
    "                            'best_point'        : IoU[n][3],\n",
    "                            'max_IoU'           : np.max(IoU[n][1]),\n",
    "                            'au_IoU'            : IoU[n][4],\n",
    "                            #------------------------------------------------------------------------------------------------#\n",
    "                            'time_exp'          : time_exp[n],\n",
    "                            'time_aucI'         : time_aucI,\n",
    "                            'time_aucD'         : time_aucD,\n",
    "                            'time_IoU'          : time_IoU,\n",
    "                            'time_total'        : time_load+time_exp[n]+time_aucI+time_aucD+time_IoU,\n",
    "                            #------------------------------------------------------------------------------------------------#\n",
    "                            \n",
    "                            }\n",
    "                    results.append(data)\n",
    "                    df = pd.DataFrame(results)\n",
    "                    df.to_csv(csv_filename, sep=',')\n",
    "                    pbar.update(1)\n",
    "                if verbose_print:\n",
    "                    print('-'*120)\n",
    "                for n_id,(n,_,funct) in enumerate(methods):\n",
    "                    ax = axes[n_id+3]\n",
    "                    maxval = np.max(np.abs(heatmaps[n]))\n",
    "                    heatmap_clr_bar = ax.imshow(heatmaps[n], cmap=shap_bpt.shapley_values_colormap, vmin=-maxval, vmax=maxval)\n",
    "                    marked_h = mark_boundaries(np.tile((255,255,255,0), (heatmaps[n].shape[0],heatmaps[n].shape[1],1)), ground_truth[:,:,0], \n",
    "                             mode='thick', color=(0,0,0,1))\n",
    "                    ax.imshow(marked_h)\n",
    "                for ax in axes.flatten(): ax.set_xticks([]) ; ax.set_yticks([])\n",
    "                plt.subplots_adjust(wspace=0.05,hspace=0.05)\n",
    "                if save_figs:\n",
    "                    # plt.savefig(f'{results_subpath_cls}/{a_type}_{img_id}_{epochs}_{mask_type}.{selected_ext}',dpi=250, transparent=True, bbox_inches = 'tight')\n",
    "                    plt.savefig(f'{results_subpath_cls}/{img_id}_heatmaps_{a_type}_{img_id}_{epochs}_{mask_type}.png',dpi=150, transparent=True, bbox_inches = 'tight')\n",
    "                if destroy_fig:\n",
    "                        plt.close(fig)\n",
    "                plt.show()\n",
    "                if plot_IoU:\n",
    "                    fig,axes = plt.subplots(1, len(methods)+4, figsize=(15, 3))\n",
    "                    axes[0].imshow(I_A)\n",
    "                    axes[1].imshow(R_A)\n",
    "                    axes[2].imshow(anomaly_map, vmin=-am_max, vmax=am_max, cmap = shap_bpt.shapley_values_colormap)\n",
    "                    axes[-1].imshow(contoured_image)\n",
    "                    for n_id,(n,_,funct) in enumerate(methods):\n",
    "                        ax = axes[n_id+3]\n",
    "                        max___iou = IoU[n][2]\n",
    "                        IoU__Y =  np.max(IoU[n][1])\n",
    "                        img, max_IoU, name = vis_IoU(heatmaps[n],max___iou , ground_truth[:, :, 0] != 0), IoU__Y, f'{n}'\n",
    "                        # img, max_IoU, name = ut.visualize.vis_IoU(heatmaps[n], IoU[n]['max_IoU_old'],ground_truth[:,:,0]!=0),np.max(IoU[n]['Y']), f'{n}'\n",
    "                        \n",
    "                        ax.imshow(img)\n",
    "                        ax.text(10,30, f\"IoU:{max_IoU:.3}\", fontsize=fontsize-2, bbox=props,weight='bold')\n",
    "                    \n",
    "                    for ax in axes.flatten():  ax.set_xticks([]) ; ax.set_yticks([])\n",
    "                    plt.subplots_adjust(wspace=0.05,hspace=0.05)\n",
    "                    if save_figs:\n",
    "                        # plt.savefig(f'{results_subpath_cls}/{a_type}_{img_id}_{epochs}_{mask_type}.{selected_ext}',dpi=250, transparent=True, bbox_inches = 'tight')\n",
    "                        plt.savefig(f'{results_subpath_cls}/{img_id}_IoU_{a_type}_{img_id}_{epochs}_{mask_type}.png',dpi=250, transparent=True, bbox_inches = 'tight')\n",
    "                    if destroy_fig:\n",
    "                        plt.close(fig)\n",
    "                    plt.show()\n",
    "    time_full = time.time()-st_full\n",
    "    end_time = datetime.now()\n",
    "    print(f\"Time for test is :, {time_full}\\n\")\n",
    "    print(f\"Duration: {format(end_time - start_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Duration: {format(end_time - start_time)}\")\n",
    "print(f'FILE SAVED AT {csv_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ba44f-6fdf-4416-8fcd-4ca022b51a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if run_full_set:\n",
    "print(df.method.unique())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9dbb45",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
